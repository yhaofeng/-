{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sulfur_content_of_raw_material</th>\n",
       "      <th>RON_of_raw_material</th>\n",
       "      <th>Saturated_hydrocarbon</th>\n",
       "      <th>olefin</th>\n",
       "      <th>Bromine</th>\n",
       "      <th>density</th>\n",
       "      <th>Substitute_coke</th>\n",
       "      <th>Substitute_S</th>\n",
       "      <th>Regenerated_coke</th>\n",
       "      <th>Regenerated_S</th>\n",
       "      <th>...</th>\n",
       "      <th>S-ZORB.CAL_1.CANGLIANG.PV</th>\n",
       "      <th>S-ZORB.FT_1006.DACA.PV</th>\n",
       "      <th>S-ZORB.FT_5204.DACA.PV</th>\n",
       "      <th>S-ZORB.FT_1006.TOTALIZERA.PV</th>\n",
       "      <th>S-ZORB.FT_5204.TOTALIZERA.PV</th>\n",
       "      <th>S-ZORB.FT_1503.DACA.PV</th>\n",
       "      <th>S-ZORB.FT_1503.TOTALIZERA.PV</th>\n",
       "      <th>S-ZORB.FT_1504.DACA.PV</th>\n",
       "      <th>S-ZORB.FT_1504.TOTALIZERA.PV</th>\n",
       "      <th>S-ZORB.PC_1001A.PV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188.0</td>\n",
       "      <td>90.6</td>\n",
       "      <td>53.23</td>\n",
       "      <td>24.40</td>\n",
       "      <td>61.49</td>\n",
       "      <td>726.09</td>\n",
       "      <td>2.32</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1.84</td>\n",
       "      <td>5.98</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0454</td>\n",
       "      <td>6368.7470</td>\n",
       "      <td>233.3108</td>\n",
       "      <td>83086802.0</td>\n",
       "      <td>832503.795</td>\n",
       "      <td>2216.4094</td>\n",
       "      <td>39063124.5</td>\n",
       "      <td>1840.1447</td>\n",
       "      <td>39608757.0</td>\n",
       "      <td>0.3533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>52.30</td>\n",
       "      <td>26.40</td>\n",
       "      <td>61.88</td>\n",
       "      <td>731.30</td>\n",
       "      <td>2.37</td>\n",
       "      <td>7.34</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4.38</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0260</td>\n",
       "      <td>6360.6453</td>\n",
       "      <td>242.3692</td>\n",
       "      <td>82318954.0</td>\n",
       "      <td>803462.665</td>\n",
       "      <td>2370.5874</td>\n",
       "      <td>38810581.5</td>\n",
       "      <td>1641.7326</td>\n",
       "      <td>39389299.0</td>\n",
       "      <td>0.3545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>177.0</td>\n",
       "      <td>90.7</td>\n",
       "      <td>52.30</td>\n",
       "      <td>26.31</td>\n",
       "      <td>61.72</td>\n",
       "      <td>729.61</td>\n",
       "      <td>2.43</td>\n",
       "      <td>7.27</td>\n",
       "      <td>1.89</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9647</td>\n",
       "      <td>6504.9649</td>\n",
       "      <td>233.0769</td>\n",
       "      <td>82012004.0</td>\n",
       "      <td>791925.055</td>\n",
       "      <td>2326.4654</td>\n",
       "      <td>38693812.0</td>\n",
       "      <td>1600.6758</td>\n",
       "      <td>39312616.5</td>\n",
       "      <td>0.3502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159.0</td>\n",
       "      <td>90.4</td>\n",
       "      <td>52.30</td>\n",
       "      <td>26.10</td>\n",
       "      <td>61.33</td>\n",
       "      <td>725.40</td>\n",
       "      <td>3.08</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4.67</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0390</td>\n",
       "      <td>6506.8250</td>\n",
       "      <td>238.3499</td>\n",
       "      <td>81231373.5</td>\n",
       "      <td>762863.810</td>\n",
       "      <td>2495.2236</td>\n",
       "      <td>38410862.5</td>\n",
       "      <td>1563.7122</td>\n",
       "      <td>39120204.5</td>\n",
       "      <td>0.3539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173.0</td>\n",
       "      <td>89.6</td>\n",
       "      <td>52.24</td>\n",
       "      <td>26.67</td>\n",
       "      <td>61.33</td>\n",
       "      <td>725.43</td>\n",
       "      <td>2.45</td>\n",
       "      <td>6.58</td>\n",
       "      <td>0.83</td>\n",
       "      <td>4.52</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9869</td>\n",
       "      <td>6560.2423</td>\n",
       "      <td>236.5762</td>\n",
       "      <td>80915707.5</td>\n",
       "      <td>751362.300</td>\n",
       "      <td>2807.7891</td>\n",
       "      <td>38283000.0</td>\n",
       "      <td>1554.3574</td>\n",
       "      <td>39045953.5</td>\n",
       "      <td>0.3581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sulfur_content_of_raw_material  RON_of_raw_material  Saturated_hydrocarbon  \\\n",
       "0                           188.0                 90.6                  53.23   \n",
       "1                           169.0                 90.5                  52.30   \n",
       "2                           177.0                 90.7                  52.30   \n",
       "3                           159.0                 90.4                  52.30   \n",
       "4                           173.0                 89.6                  52.24   \n",
       "\n",
       "   olefin  Bromine  density  Substitute_coke  Substitute_S  Regenerated_coke  \\\n",
       "0   24.40    61.49   726.09             2.32          7.30              1.84   \n",
       "1   26.40    61.88   731.30             2.37          7.34              0.55   \n",
       "2   26.31    61.72   729.61             2.43          7.27              1.89   \n",
       "3   26.10    61.33   725.40             3.08          7.35              0.98   \n",
       "4   26.67    61.33   725.43             2.45          6.58              0.83   \n",
       "\n",
       "   Regenerated_S  ...  S-ZORB.CAL_1.CANGLIANG.PV  S-ZORB.FT_1006.DACA.PV  \\\n",
       "0           5.98  ...                     2.0454               6368.7470   \n",
       "1           4.38  ...                     2.0260               6360.6453   \n",
       "2           5.82  ...                     1.9647               6504.9649   \n",
       "3           4.67  ...                     2.0390               6506.8250   \n",
       "4           4.52  ...                     1.9869               6560.2423   \n",
       "\n",
       "   S-ZORB.FT_5204.DACA.PV  S-ZORB.FT_1006.TOTALIZERA.PV  \\\n",
       "0                233.3108                    83086802.0   \n",
       "1                242.3692                    82318954.0   \n",
       "2                233.0769                    82012004.0   \n",
       "3                238.3499                    81231373.5   \n",
       "4                236.5762                    80915707.5   \n",
       "\n",
       "   S-ZORB.FT_5204.TOTALIZERA.PV  S-ZORB.FT_1503.DACA.PV  \\\n",
       "0                    832503.795               2216.4094   \n",
       "1                    803462.665               2370.5874   \n",
       "2                    791925.055               2326.4654   \n",
       "3                    762863.810               2495.2236   \n",
       "4                    751362.300               2807.7891   \n",
       "\n",
       "   S-ZORB.FT_1503.TOTALIZERA.PV  S-ZORB.FT_1504.DACA.PV  \\\n",
       "0                    39063124.5               1840.1447   \n",
       "1                    38810581.5               1641.7326   \n",
       "2                    38693812.0               1600.6758   \n",
       "3                    38410862.5               1563.7122   \n",
       "4                    38283000.0               1554.3574   \n",
       "\n",
       "   S-ZORB.FT_1504.TOTALIZERA.PV  S-ZORB.PC_1001A.PV  \n",
       "0                    39608757.0              0.3533  \n",
       "1                    39389299.0              0.3545  \n",
       "2                    39312616.5              0.3502  \n",
       "3                    39120204.5              0.3539  \n",
       "4                    39045953.5              0.3581  \n",
       "\n",
       "[5 rows x 354 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('independent_variable.csv')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('dependent_variable.csv').values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.653367\tvalid_1's l2: 0.567413\n",
      "[50]\ttraining's l2: 0.433529\tvalid_1's l2: 0.379083\n",
      "[75]\ttraining's l2: 0.300202\tvalid_1's l2: 0.267159\n",
      "[100]\ttraining's l2: 0.216995\tvalid_1's l2: 0.196481\n",
      "[125]\ttraining's l2: 0.156562\tvalid_1's l2: 0.147873\n",
      "[150]\ttraining's l2: 0.118572\tvalid_1's l2: 0.116816\n",
      "[175]\ttraining's l2: 0.0946077\tvalid_1's l2: 0.0974379\n",
      "[200]\ttraining's l2: 0.0771785\tvalid_1's l2: 0.0840825\n",
      "[225]\ttraining's l2: 0.0656658\tvalid_1's l2: 0.0756431\n",
      "[250]\ttraining's l2: 0.057517\tvalid_1's l2: 0.0700732\n",
      "[275]\ttraining's l2: 0.0512845\tvalid_1's l2: 0.0669741\n",
      "[300]\ttraining's l2: 0.0469252\tvalid_1's l2: 0.0645268\n",
      "[325]\ttraining's l2: 0.0435855\tvalid_1's l2: 0.0632908\n",
      "[350]\ttraining's l2: 0.0407063\tvalid_1's l2: 0.0622546\n",
      "[375]\ttraining's l2: 0.0378894\tvalid_1's l2: 0.0606776\n",
      "[400]\ttraining's l2: 0.0354574\tvalid_1's l2: 0.0597145\n",
      "[425]\ttraining's l2: 0.033168\tvalid_1's l2: 0.0588564\n",
      "[450]\ttraining's l2: 0.0312001\tvalid_1's l2: 0.0578097\n",
      "[475]\ttraining's l2: 0.0296537\tvalid_1's l2: 0.0579317\n",
      "[500]\ttraining's l2: 0.0279204\tvalid_1's l2: 0.0577345\n",
      "[525]\ttraining's l2: 0.0264304\tvalid_1's l2: 0.0572892\n",
      "[550]\ttraining's l2: 0.0251973\tvalid_1's l2: 0.0569431\n",
      "[575]\ttraining's l2: 0.0239562\tvalid_1's l2: 0.0563351\n",
      "[600]\ttraining's l2: 0.0225502\tvalid_1's l2: 0.0560162\n",
      "[625]\ttraining's l2: 0.0213385\tvalid_1's l2: 0.0557996\n",
      "[650]\ttraining's l2: 0.0204385\tvalid_1's l2: 0.0557733\n",
      "[675]\ttraining's l2: 0.019461\tvalid_1's l2: 0.0555453\n",
      "[700]\ttraining's l2: 0.0185115\tvalid_1's l2: 0.0555454\n",
      "[725]\ttraining's l2: 0.0174977\tvalid_1's l2: 0.055375\n",
      "[750]\ttraining's l2: 0.0166758\tvalid_1's l2: 0.0550441\n",
      "[775]\ttraining's l2: 0.0159799\tvalid_1's l2: 0.0546312\n",
      "[800]\ttraining's l2: 0.0152116\tvalid_1's l2: 0.0544442\n",
      "[825]\ttraining's l2: 0.0143574\tvalid_1's l2: 0.0546807\n",
      "[850]\ttraining's l2: 0.0136127\tvalid_1's l2: 0.0543576\n",
      "[875]\ttraining's l2: 0.0129421\tvalid_1's l2: 0.054301\n",
      "[900]\ttraining's l2: 0.0123101\tvalid_1's l2: 0.0541987\n",
      "[925]\ttraining's l2: 0.0117971\tvalid_1's l2: 0.054291\n",
      "[950]\ttraining's l2: 0.0112651\tvalid_1's l2: 0.0543155\n",
      "[975]\ttraining's l2: 0.0107944\tvalid_1's l2: 0.0540832\n",
      "[1000]\ttraining's l2: 0.0102768\tvalid_1's l2: 0.0538223\n",
      "[1025]\ttraining's l2: 0.00989793\tvalid_1's l2: 0.0539647\n",
      "[1050]\ttraining's l2: 0.00961899\tvalid_1's l2: 0.0541343\n",
      "[1075]\ttraining's l2: 0.00919767\tvalid_1's l2: 0.0543795\n",
      "[1100]\ttraining's l2: 0.00879457\tvalid_1's l2: 0.054284\n",
      "[1125]\ttraining's l2: 0.00843606\tvalid_1's l2: 0.0543501\n",
      "[1150]\ttraining's l2: 0.00812424\tvalid_1's l2: 0.0543979\n",
      "[1175]\ttraining's l2: 0.00776934\tvalid_1's l2: 0.0543172\n",
      "[1200]\ttraining's l2: 0.0074631\tvalid_1's l2: 0.0537827\n",
      "[1225]\ttraining's l2: 0.0071932\tvalid_1's l2: 0.0537285\n",
      "[1250]\ttraining's l2: 0.0069572\tvalid_1's l2: 0.0539082\n",
      "[1275]\ttraining's l2: 0.00680901\tvalid_1's l2: 0.0541056\n",
      "[1300]\ttraining's l2: 0.00659296\tvalid_1's l2: 0.0540616\n",
      "[1325]\ttraining's l2: 0.00628963\tvalid_1's l2: 0.0540645\n",
      "[1350]\ttraining's l2: 0.00606852\tvalid_1's l2: 0.0540594\n",
      "[1375]\ttraining's l2: 0.00584577\tvalid_1's l2: 0.0537755\n",
      "[1400]\ttraining's l2: 0.00560095\tvalid_1's l2: 0.0537107\n",
      "[1425]\ttraining's l2: 0.00542167\tvalid_1's l2: 0.0535274\n",
      "[1450]\ttraining's l2: 0.00523125\tvalid_1's l2: 0.053523\n",
      "[1475]\ttraining's l2: 0.00503613\tvalid_1's l2: 0.0531753\n",
      "[1500]\ttraining's l2: 0.00494584\tvalid_1's l2: 0.0531383\n",
      "[1525]\ttraining's l2: 0.00480471\tvalid_1's l2: 0.0531266\n",
      "[1550]\ttraining's l2: 0.00460003\tvalid_1's l2: 0.0530918\n",
      "[1575]\ttraining's l2: 0.00444833\tvalid_1's l2: 0.0529628\n",
      "[1600]\ttraining's l2: 0.00427862\tvalid_1's l2: 0.0529661\n",
      "[1625]\ttraining's l2: 0.00408237\tvalid_1's l2: 0.0531288\n",
      "[1650]\ttraining's l2: 0.00393938\tvalid_1's l2: 0.0531965\n",
      "[1675]\ttraining's l2: 0.00383022\tvalid_1's l2: 0.0530581\n",
      "[1700]\ttraining's l2: 0.00372173\tvalid_1's l2: 0.0532006\n",
      "[1725]\ttraining's l2: 0.00361807\tvalid_1's l2: 0.0532221\n",
      "[1750]\ttraining's l2: 0.00355221\tvalid_1's l2: 0.0532517\n",
      "[1775]\ttraining's l2: 0.0034397\tvalid_1's l2: 0.0531634\n",
      "[1800]\ttraining's l2: 0.00333126\tvalid_1's l2: 0.0531276\n",
      "[1825]\ttraining's l2: 0.00323972\tvalid_1's l2: 0.0531057\n",
      "[1850]\ttraining's l2: 0.00315594\tvalid_1's l2: 0.0530955\n",
      "[1875]\ttraining's l2: 0.00307205\tvalid_1's l2: 0.0530967\n",
      "[1900]\ttraining's l2: 0.00299269\tvalid_1's l2: 0.0530696\n",
      "[1925]\ttraining's l2: 0.00289718\tvalid_1's l2: 0.0531491\n",
      "[1950]\ttraining's l2: 0.00283346\tvalid_1's l2: 0.0531063\n",
      "[1975]\ttraining's l2: 0.00277503\tvalid_1's l2: 0.0530087\n",
      "[2000]\ttraining's l2: 0.00270954\tvalid_1's l2: 0.052904\n",
      "[2025]\ttraining's l2: 0.00263842\tvalid_1's l2: 0.0528785\n",
      "[2050]\ttraining's l2: 0.00255533\tvalid_1's l2: 0.0530066\n",
      "[2075]\ttraining's l2: 0.00249562\tvalid_1's l2: 0.0529984\n",
      "[2100]\ttraining's l2: 0.00244388\tvalid_1's l2: 0.0530306\n",
      "[2125]\ttraining's l2: 0.00236778\tvalid_1's l2: 0.0531187\n",
      "[2150]\ttraining's l2: 0.00229102\tvalid_1's l2: 0.0531085\n",
      "[2175]\ttraining's l2: 0.0022413\tvalid_1's l2: 0.0531217\n",
      "[2200]\ttraining's l2: 0.00219839\tvalid_1's l2: 0.0530713\n",
      "[2225]\ttraining's l2: 0.00216893\tvalid_1's l2: 0.0531401\n",
      "[2250]\ttraining's l2: 0.00212616\tvalid_1's l2: 0.053174\n",
      "[2275]\ttraining's l2: 0.00206894\tvalid_1's l2: 0.0532045\n",
      "[2300]\ttraining's l2: 0.0020266\tvalid_1's l2: 0.0532069\n",
      "[2325]\ttraining's l2: 0.00198698\tvalid_1's l2: 0.0533189\n",
      "[2350]\ttraining's l2: 0.00194259\tvalid_1's l2: 0.053361\n",
      "[2375]\ttraining's l2: 0.00189389\tvalid_1's l2: 0.0533119\n",
      "[2400]\ttraining's l2: 0.00185152\tvalid_1's l2: 0.0533735\n",
      "[2425]\ttraining's l2: 0.00181374\tvalid_1's l2: 0.0534392\n",
      "[2450]\ttraining's l2: 0.00178907\tvalid_1's l2: 0.0533862\n",
      "[2475]\ttraining's l2: 0.00176503\tvalid_1's l2: 0.0533841\n",
      "[2500]\ttraining's l2: 0.00172115\tvalid_1's l2: 0.0534347\n",
      "[2525]\ttraining's l2: 0.00167177\tvalid_1's l2: 0.0535495\n",
      "[2550]\ttraining's l2: 0.00162082\tvalid_1's l2: 0.0536305\n",
      "[2575]\ttraining's l2: 0.001574\tvalid_1's l2: 0.0537059\n",
      "[2600]\ttraining's l2: 0.00154741\tvalid_1's l2: 0.053667\n",
      "[2625]\ttraining's l2: 0.00151256\tvalid_1's l2: 0.0536294\n",
      "[2650]\ttraining's l2: 0.00147902\tvalid_1's l2: 0.0535558\n",
      "[2675]\ttraining's l2: 0.00146177\tvalid_1's l2: 0.0535825\n",
      "[2700]\ttraining's l2: 0.00144568\tvalid_1's l2: 0.0535149\n",
      "[2725]\ttraining's l2: 0.00142111\tvalid_1's l2: 0.05347\n",
      "[2750]\ttraining's l2: 0.00139443\tvalid_1's l2: 0.053424\n",
      "[2775]\ttraining's l2: 0.00136377\tvalid_1's l2: 0.0534036\n",
      "[2800]\ttraining's l2: 0.00134084\tvalid_1's l2: 0.0533799\n",
      "[2825]\ttraining's l2: 0.00131528\tvalid_1's l2: 0.0533002\n",
      "[2850]\ttraining's l2: 0.00129075\tvalid_1's l2: 0.0532791\n",
      "[2875]\ttraining's l2: 0.00125329\tvalid_1's l2: 0.0534117\n",
      "[2900]\ttraining's l2: 0.00123417\tvalid_1's l2: 0.0534233\n",
      "[2925]\ttraining's l2: 0.00122041\tvalid_1's l2: 0.0534429\n",
      "[2950]\ttraining's l2: 0.00120582\tvalid_1's l2: 0.0534494\n",
      "[2975]\ttraining's l2: 0.00118829\tvalid_1's l2: 0.0534452\n",
      "[3000]\ttraining's l2: 0.00116491\tvalid_1's l2: 0.0534123\n",
      "Early stopping, best iteration is:\n",
      "[2017]\ttraining's l2: 0.00265663\tvalid_1's l2: 0.0528489\n"
     ]
    }
   ],
   "source": [
    "param = {'boosting_type':'gbdt',\n",
    "         'objective' : 'regression', #任务类型\n",
    "         'metric' : 'mse', #评估指标\n",
    "         'learning_rate' : 0.01, #学习率\n",
    "         'max_depth' : 20, #树的最大深度\n",
    "         'feature_fraction':0.8, #设置在每次迭代中使用特征的比例\n",
    "         'bagging_fraction': 0.8, #样本采样比例\n",
    "         'bagging_freq': 8, #bagging的次数\n",
    "         'lambda_l1': 0.3, #L1正则\n",
    "          'lambda_l2': 0, #L2正则\n",
    "        }\n",
    "trn_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "model = lgb.train(param,trn_data,valid_sets=[trn_data,val_data],\\\n",
    "                  num_boost_round = 100000,early_stopping_rounds=1000,verbose_eval=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过交叉验证方法计算各特征的重要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(cv,x,y,param):\n",
    "    folds = KFold(n_splits=cv,shuffle=True,random_state=15)\n",
    "    oof = np.zeros(X_train.shape[0])\n",
    "    feature_names = x.columns\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'column': feature_names,\n",
    "        'importance': np.zeros(len(feature_names)),\n",
    "    })\n",
    "    for fold_,(trn_idx,val_idx) in enumerate(folds.split(x,y)):\n",
    "        print('fold {}'.format(fold_))\n",
    "        trn_data = lgb.Dataset(x.iloc[trn_idx,:],\n",
    "                               label=y[trn_idx],\n",
    "                               )\n",
    "        val_data = lgb.Dataset(x.iloc[val_idx,:],\n",
    "                               label=y[val_idx],\n",
    "                               )\n",
    "        model = lgb.train(param,trn_data,valid_sets=[trn_data,val_data],\\\n",
    "                  num_boost_round = 100000,early_stopping_rounds=1000,verbose_eval=25)\n",
    "        feature_importance['importance'] += model.feature_importance()\n",
    "    feature_importance['importance'] /= cv\n",
    "    return feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'boosting_type':'gbdt',\n",
    "         'objective' : 'regression', #任务类型\n",
    "         'metric' : 'mse', #评估指标\n",
    "         'learning_rate' : 0.01, #学习率\n",
    "         'max_depth' : 20, #树的最大深度\n",
    "         'feature_fraction':0.8, #设置在每次迭代中使用特征的比例\n",
    "         'bagging_fraction': 0.8, #样本采样比例\n",
    "         'bagging_freq': 8, #bagging的次数\n",
    "         'lambda_l1': 0.3, #L1正则\n",
    "          'lambda_l2': 0, #L2正则\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.61506\tvalid_1's l2: 0.957861\n",
      "[50]\ttraining's l2: 0.417935\tvalid_1's l2: 0.682142\n",
      "[75]\ttraining's l2: 0.294822\tvalid_1's l2: 0.514004\n",
      "[100]\ttraining's l2: 0.217287\tvalid_1's l2: 0.402598\n",
      "[125]\ttraining's l2: 0.165185\tvalid_1's l2: 0.324817\n",
      "[150]\ttraining's l2: 0.131481\tvalid_1's l2: 0.270882\n",
      "[175]\ttraining's l2: 0.108024\tvalid_1's l2: 0.232383\n",
      "[200]\ttraining's l2: 0.0919636\tvalid_1's l2: 0.20534\n",
      "[225]\ttraining's l2: 0.0807134\tvalid_1's l2: 0.184547\n",
      "[250]\ttraining's l2: 0.0714235\tvalid_1's l2: 0.168263\n",
      "[275]\ttraining's l2: 0.0647425\tvalid_1's l2: 0.157094\n",
      "[300]\ttraining's l2: 0.0593374\tvalid_1's l2: 0.148553\n",
      "[325]\ttraining's l2: 0.054878\tvalid_1's l2: 0.141631\n",
      "[350]\ttraining's l2: 0.0511723\tvalid_1's l2: 0.135954\n",
      "[375]\ttraining's l2: 0.048006\tvalid_1's l2: 0.133024\n",
      "[400]\ttraining's l2: 0.0452098\tvalid_1's l2: 0.131582\n",
      "[425]\ttraining's l2: 0.042988\tvalid_1's l2: 0.129163\n",
      "[450]\ttraining's l2: 0.0407043\tvalid_1's l2: 0.12733\n",
      "[475]\ttraining's l2: 0.0386066\tvalid_1's l2: 0.12456\n",
      "[500]\ttraining's l2: 0.0365517\tvalid_1's l2: 0.123706\n",
      "[525]\ttraining's l2: 0.034492\tvalid_1's l2: 0.120963\n",
      "[550]\ttraining's l2: 0.0327297\tvalid_1's l2: 0.119439\n",
      "[575]\ttraining's l2: 0.0312013\tvalid_1's l2: 0.117981\n",
      "[600]\ttraining's l2: 0.0297307\tvalid_1's l2: 0.116708\n",
      "[625]\ttraining's l2: 0.0282296\tvalid_1's l2: 0.115665\n",
      "[650]\ttraining's l2: 0.0269857\tvalid_1's l2: 0.114815\n",
      "[675]\ttraining's l2: 0.0257101\tvalid_1's l2: 0.113285\n",
      "[700]\ttraining's l2: 0.0246429\tvalid_1's l2: 0.112273\n",
      "[725]\ttraining's l2: 0.023506\tvalid_1's l2: 0.112056\n",
      "[750]\ttraining's l2: 0.0221208\tvalid_1's l2: 0.111575\n",
      "[775]\ttraining's l2: 0.0211423\tvalid_1's l2: 0.110955\n",
      "[800]\ttraining's l2: 0.0201409\tvalid_1's l2: 0.110243\n",
      "[825]\ttraining's l2: 0.0194221\tvalid_1's l2: 0.110313\n",
      "[850]\ttraining's l2: 0.0187213\tvalid_1's l2: 0.109629\n",
      "[875]\ttraining's l2: 0.0178865\tvalid_1's l2: 0.10969\n",
      "[900]\ttraining's l2: 0.0173288\tvalid_1's l2: 0.109059\n",
      "[925]\ttraining's l2: 0.0167295\tvalid_1's l2: 0.109083\n",
      "[950]\ttraining's l2: 0.0160422\tvalid_1's l2: 0.109068\n",
      "[975]\ttraining's l2: 0.0154465\tvalid_1's l2: 0.108536\n",
      "[1000]\ttraining's l2: 0.0150091\tvalid_1's l2: 0.108628\n",
      "[1025]\ttraining's l2: 0.0143709\tvalid_1's l2: 0.109106\n",
      "[1050]\ttraining's l2: 0.0138989\tvalid_1's l2: 0.108241\n",
      "[1075]\ttraining's l2: 0.0133651\tvalid_1's l2: 0.107712\n",
      "[1100]\ttraining's l2: 0.0129103\tvalid_1's l2: 0.107662\n",
      "[1125]\ttraining's l2: 0.012425\tvalid_1's l2: 0.107825\n",
      "[1150]\ttraining's l2: 0.0120388\tvalid_1's l2: 0.108215\n",
      "[1175]\ttraining's l2: 0.0117065\tvalid_1's l2: 0.107699\n",
      "[1200]\ttraining's l2: 0.0113747\tvalid_1's l2: 0.107834\n",
      "[1225]\ttraining's l2: 0.0109859\tvalid_1's l2: 0.107979\n",
      "[1250]\ttraining's l2: 0.0106397\tvalid_1's l2: 0.107773\n",
      "[1275]\ttraining's l2: 0.0103005\tvalid_1's l2: 0.107311\n",
      "[1300]\ttraining's l2: 0.00999799\tvalid_1's l2: 0.106455\n",
      "[1325]\ttraining's l2: 0.00962309\tvalid_1's l2: 0.107007\n",
      "[1350]\ttraining's l2: 0.00936574\tvalid_1's l2: 0.10707\n",
      "[1375]\ttraining's l2: 0.00910449\tvalid_1's l2: 0.106489\n",
      "[1400]\ttraining's l2: 0.00891614\tvalid_1's l2: 0.106593\n",
      "[1425]\ttraining's l2: 0.00864362\tvalid_1's l2: 0.10626\n",
      "[1450]\ttraining's l2: 0.00840641\tvalid_1's l2: 0.105866\n",
      "[1475]\ttraining's l2: 0.0081617\tvalid_1's l2: 0.105777\n",
      "[1500]\ttraining's l2: 0.00799208\tvalid_1's l2: 0.105504\n",
      "[1525]\ttraining's l2: 0.00776926\tvalid_1's l2: 0.105255\n",
      "[1550]\ttraining's l2: 0.00751175\tvalid_1's l2: 0.105214\n",
      "[1575]\ttraining's l2: 0.00726058\tvalid_1's l2: 0.105224\n",
      "[1600]\ttraining's l2: 0.00706404\tvalid_1's l2: 0.104721\n",
      "[1625]\ttraining's l2: 0.00679609\tvalid_1's l2: 0.104563\n",
      "[1650]\ttraining's l2: 0.00662038\tvalid_1's l2: 0.104341\n",
      "[1675]\ttraining's l2: 0.00645015\tvalid_1's l2: 0.103916\n",
      "[1700]\ttraining's l2: 0.00631666\tvalid_1's l2: 0.103758\n",
      "[1725]\ttraining's l2: 0.00616774\tvalid_1's l2: 0.103754\n",
      "[1750]\ttraining's l2: 0.00600046\tvalid_1's l2: 0.103927\n",
      "[1775]\ttraining's l2: 0.00575134\tvalid_1's l2: 0.104097\n",
      "[1800]\ttraining's l2: 0.00561485\tvalid_1's l2: 0.103917\n",
      "[1825]\ttraining's l2: 0.00547307\tvalid_1's l2: 0.10376\n",
      "[1850]\ttraining's l2: 0.00534474\tvalid_1's l2: 0.103722\n",
      "[1875]\ttraining's l2: 0.00520051\tvalid_1's l2: 0.103622\n",
      "[1900]\ttraining's l2: 0.0050546\tvalid_1's l2: 0.103606\n",
      "[1925]\ttraining's l2: 0.00492376\tvalid_1's l2: 0.103416\n",
      "[1950]\ttraining's l2: 0.00480755\tvalid_1's l2: 0.103244\n",
      "[1975]\ttraining's l2: 0.00470134\tvalid_1's l2: 0.103168\n",
      "[2000]\ttraining's l2: 0.00460172\tvalid_1's l2: 0.103073\n",
      "[2025]\ttraining's l2: 0.00450396\tvalid_1's l2: 0.10304\n",
      "[2050]\ttraining's l2: 0.00442741\tvalid_1's l2: 0.102971\n",
      "[2075]\ttraining's l2: 0.00433035\tvalid_1's l2: 0.102815\n",
      "[2100]\ttraining's l2: 0.0042387\tvalid_1's l2: 0.10292\n",
      "[2125]\ttraining's l2: 0.00414165\tvalid_1's l2: 0.10329\n",
      "[2150]\ttraining's l2: 0.00409449\tvalid_1's l2: 0.103392\n",
      "[2175]\ttraining's l2: 0.00400843\tvalid_1's l2: 0.103352\n",
      "[2200]\ttraining's l2: 0.00392281\tvalid_1's l2: 0.103571\n",
      "[2225]\ttraining's l2: 0.00386642\tvalid_1's l2: 0.1035\n",
      "[2250]\ttraining's l2: 0.00376082\tvalid_1's l2: 0.103545\n",
      "[2275]\ttraining's l2: 0.00366464\tvalid_1's l2: 0.103454\n",
      "[2300]\ttraining's l2: 0.003614\tvalid_1's l2: 0.103431\n",
      "[2325]\ttraining's l2: 0.00353998\tvalid_1's l2: 0.103276\n",
      "[2350]\ttraining's l2: 0.0034848\tvalid_1's l2: 0.103261\n",
      "[2375]\ttraining's l2: 0.00342696\tvalid_1's l2: 0.103054\n",
      "[2400]\ttraining's l2: 0.00336989\tvalid_1's l2: 0.103029\n",
      "[2425]\ttraining's l2: 0.003301\tvalid_1's l2: 0.103013\n",
      "[2450]\ttraining's l2: 0.00324803\tvalid_1's l2: 0.10304\n",
      "[2475]\ttraining's l2: 0.00317701\tvalid_1's l2: 0.102978\n",
      "[2500]\ttraining's l2: 0.00312129\tvalid_1's l2: 0.102912\n",
      "[2525]\ttraining's l2: 0.00307849\tvalid_1's l2: 0.102979\n",
      "[2550]\ttraining's l2: 0.00302506\tvalid_1's l2: 0.102921\n",
      "[2575]\ttraining's l2: 0.00297446\tvalid_1's l2: 0.102854\n",
      "[2600]\ttraining's l2: 0.0029288\tvalid_1's l2: 0.102776\n",
      "[2625]\ttraining's l2: 0.00288678\tvalid_1's l2: 0.102901\n",
      "[2650]\ttraining's l2: 0.00283882\tvalid_1's l2: 0.102786\n",
      "[2675]\ttraining's l2: 0.00278291\tvalid_1's l2: 0.10283\n",
      "[2700]\ttraining's l2: 0.00272741\tvalid_1's l2: 0.102879\n",
      "[2725]\ttraining's l2: 0.00268261\tvalid_1's l2: 0.102901\n",
      "[2750]\ttraining's l2: 0.00265581\tvalid_1's l2: 0.102822\n",
      "[2775]\ttraining's l2: 0.00262335\tvalid_1's l2: 0.102904\n",
      "[2800]\ttraining's l2: 0.00258539\tvalid_1's l2: 0.102841\n",
      "[2825]\ttraining's l2: 0.00255164\tvalid_1's l2: 0.102694\n",
      "[2850]\ttraining's l2: 0.00252273\tvalid_1's l2: 0.102695\n",
      "[2875]\ttraining's l2: 0.00249368\tvalid_1's l2: 0.102493\n",
      "[2900]\ttraining's l2: 0.00244995\tvalid_1's l2: 0.102512\n",
      "[2925]\ttraining's l2: 0.00242072\tvalid_1's l2: 0.102537\n",
      "[2950]\ttraining's l2: 0.00239254\tvalid_1's l2: 0.102564\n",
      "[2975]\ttraining's l2: 0.00236478\tvalid_1's l2: 0.10245\n",
      "[3000]\ttraining's l2: 0.00234187\tvalid_1's l2: 0.102414\n",
      "[3025]\ttraining's l2: 0.00231706\tvalid_1's l2: 0.102449\n",
      "[3050]\ttraining's l2: 0.00228208\tvalid_1's l2: 0.102228\n",
      "[3075]\ttraining's l2: 0.00225258\tvalid_1's l2: 0.10221\n",
      "[3100]\ttraining's l2: 0.00222371\tvalid_1's l2: 0.102328\n",
      "[3125]\ttraining's l2: 0.00220113\tvalid_1's l2: 0.102388\n",
      "[3150]\ttraining's l2: 0.00217857\tvalid_1's l2: 0.102291\n",
      "[3175]\ttraining's l2: 0.00215828\tvalid_1's l2: 0.102295\n",
      "[3200]\ttraining's l2: 0.00213262\tvalid_1's l2: 0.102375\n",
      "[3225]\ttraining's l2: 0.00211579\tvalid_1's l2: 0.102505\n",
      "[3250]\ttraining's l2: 0.00208558\tvalid_1's l2: 0.10252\n",
      "[3275]\ttraining's l2: 0.00206497\tvalid_1's l2: 0.102468\n",
      "[3300]\ttraining's l2: 0.00202386\tvalid_1's l2: 0.102502\n",
      "[3325]\ttraining's l2: 0.00200317\tvalid_1's l2: 0.102538\n",
      "[3350]\ttraining's l2: 0.0019825\tvalid_1's l2: 0.102655\n",
      "[3375]\ttraining's l2: 0.00195784\tvalid_1's l2: 0.102775\n",
      "[3400]\ttraining's l2: 0.00192925\tvalid_1's l2: 0.102791\n",
      "[3425]\ttraining's l2: 0.0019114\tvalid_1's l2: 0.102746\n",
      "[3450]\ttraining's l2: 0.00188627\tvalid_1's l2: 0.10263\n",
      "[3475]\ttraining's l2: 0.00187306\tvalid_1's l2: 0.102557\n",
      "[3500]\ttraining's l2: 0.00184621\tvalid_1's l2: 0.102529\n",
      "[3525]\ttraining's l2: 0.00183059\tvalid_1's l2: 0.102592\n",
      "[3550]\ttraining's l2: 0.00180725\tvalid_1's l2: 0.102479\n",
      "[3575]\ttraining's l2: 0.00179053\tvalid_1's l2: 0.102439\n",
      "[3600]\ttraining's l2: 0.00176105\tvalid_1's l2: 0.102363\n",
      "[3625]\ttraining's l2: 0.00173946\tvalid_1's l2: 0.102419\n",
      "[3650]\ttraining's l2: 0.00171325\tvalid_1's l2: 0.10232\n",
      "[3675]\ttraining's l2: 0.00168994\tvalid_1's l2: 0.102334\n",
      "[3700]\ttraining's l2: 0.00166923\tvalid_1's l2: 0.102333\n",
      "[3725]\ttraining's l2: 0.00165476\tvalid_1's l2: 0.102366\n",
      "[3750]\ttraining's l2: 0.0016312\tvalid_1's l2: 0.102317\n",
      "[3775]\ttraining's l2: 0.00161898\tvalid_1's l2: 0.102353\n",
      "[3800]\ttraining's l2: 0.00159826\tvalid_1's l2: 0.102395\n",
      "[3825]\ttraining's l2: 0.00158477\tvalid_1's l2: 0.10243\n",
      "[3850]\ttraining's l2: 0.00156962\tvalid_1's l2: 0.102351\n",
      "[3875]\ttraining's l2: 0.00155554\tvalid_1's l2: 0.102323\n",
      "[3900]\ttraining's l2: 0.00154469\tvalid_1's l2: 0.102304\n",
      "[3925]\ttraining's l2: 0.00153411\tvalid_1's l2: 0.102271\n",
      "[3950]\ttraining's l2: 0.00151557\tvalid_1's l2: 0.102266\n",
      "[3975]\ttraining's l2: 0.00150872\tvalid_1's l2: 0.102301\n",
      "[4000]\ttraining's l2: 0.00149568\tvalid_1's l2: 0.102295\n",
      "[4025]\ttraining's l2: 0.0014878\tvalid_1's l2: 0.102281\n",
      "[4050]\ttraining's l2: 0.00147145\tvalid_1's l2: 0.102184\n",
      "[4075]\ttraining's l2: 0.00146547\tvalid_1's l2: 0.102155\n",
      "[4100]\ttraining's l2: 0.00144845\tvalid_1's l2: 0.102227\n",
      "[4125]\ttraining's l2: 0.00144232\tvalid_1's l2: 0.10223\n",
      "[4150]\ttraining's l2: 0.001432\tvalid_1's l2: 0.102218\n",
      "[4175]\ttraining's l2: 0.00142237\tvalid_1's l2: 0.102158\n",
      "[4200]\ttraining's l2: 0.00140962\tvalid_1's l2: 0.102109\n",
      "[4225]\ttraining's l2: 0.00140008\tvalid_1's l2: 0.102117\n",
      "[4250]\ttraining's l2: 0.00138705\tvalid_1's l2: 0.102139\n",
      "[4275]\ttraining's l2: 0.00137847\tvalid_1's l2: 0.102163\n",
      "[4300]\ttraining's l2: 0.001369\tvalid_1's l2: 0.102228\n",
      "[4325]\ttraining's l2: 0.0013553\tvalid_1's l2: 0.10223\n",
      "[4350]\ttraining's l2: 0.00134117\tvalid_1's l2: 0.102251\n",
      "[4375]\ttraining's l2: 0.00133459\tvalid_1's l2: 0.10229\n",
      "[4400]\ttraining's l2: 0.0013202\tvalid_1's l2: 0.102281\n",
      "[4425]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4450]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4475]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4500]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4525]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4550]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4575]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4600]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4625]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4650]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4675]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4700]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4725]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4750]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4775]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4800]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4825]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4850]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4875]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4900]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4925]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4950]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[4975]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[5000]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[5025]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[5050]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[5075]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[5100]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[5125]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[5150]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[5175]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "[5200]\ttraining's l2: 0.00131312\tvalid_1's l2: 0.102276\n",
      "Early stopping, best iteration is:\n",
      "[4215]\ttraining's l2: 0.00140463\tvalid_1's l2: 0.102108\n",
      "fold 1\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.651244\tvalid_1's l2: 0.771882\n",
      "[50]\ttraining's l2: 0.445126\tvalid_1's l2: 0.515188\n",
      "[75]\ttraining's l2: 0.316286\tvalid_1's l2: 0.361996\n",
      "[100]\ttraining's l2: 0.236322\tvalid_1's l2: 0.274326\n",
      "[125]\ttraining's l2: 0.175671\tvalid_1's l2: 0.2136\n",
      "[150]\ttraining's l2: 0.140344\tvalid_1's l2: 0.177336\n",
      "[175]\ttraining's l2: 0.115891\tvalid_1's l2: 0.152529\n",
      "[200]\ttraining's l2: 0.0978122\tvalid_1's l2: 0.135016\n",
      "[225]\ttraining's l2: 0.0841404\tvalid_1's l2: 0.12748\n",
      "[250]\ttraining's l2: 0.0742826\tvalid_1's l2: 0.121594\n",
      "[275]\ttraining's l2: 0.0678965\tvalid_1's l2: 0.118228\n",
      "[300]\ttraining's l2: 0.0619045\tvalid_1's l2: 0.119416\n",
      "[325]\ttraining's l2: 0.0570455\tvalid_1's l2: 0.119999\n",
      "[350]\ttraining's l2: 0.052143\tvalid_1's l2: 0.1193\n",
      "[375]\ttraining's l2: 0.0485452\tvalid_1's l2: 0.119873\n",
      "[400]\ttraining's l2: 0.0459148\tvalid_1's l2: 0.11874\n",
      "[425]\ttraining's l2: 0.0430989\tvalid_1's l2: 0.120718\n",
      "[450]\ttraining's l2: 0.0407378\tvalid_1's l2: 0.122641\n",
      "[475]\ttraining's l2: 0.038717\tvalid_1's l2: 0.12239\n",
      "[500]\ttraining's l2: 0.0361166\tvalid_1's l2: 0.123227\n",
      "[525]\ttraining's l2: 0.0338302\tvalid_1's l2: 0.123592\n",
      "[550]\ttraining's l2: 0.032344\tvalid_1's l2: 0.124463\n",
      "[575]\ttraining's l2: 0.0306285\tvalid_1's l2: 0.12273\n",
      "[600]\ttraining's l2: 0.0289064\tvalid_1's l2: 0.122813\n",
      "[625]\ttraining's l2: 0.0272942\tvalid_1's l2: 0.124504\n",
      "[650]\ttraining's l2: 0.0260335\tvalid_1's l2: 0.124622\n",
      "[675]\ttraining's l2: 0.0249033\tvalid_1's l2: 0.124585\n",
      "[700]\ttraining's l2: 0.0237642\tvalid_1's l2: 0.124393\n",
      "[725]\ttraining's l2: 0.0226821\tvalid_1's l2: 0.124156\n",
      "[750]\ttraining's l2: 0.0215472\tvalid_1's l2: 0.124709\n",
      "[775]\ttraining's l2: 0.0206569\tvalid_1's l2: 0.125359\n",
      "[800]\ttraining's l2: 0.0197585\tvalid_1's l2: 0.126229\n",
      "[825]\ttraining's l2: 0.0190278\tvalid_1's l2: 0.126264\n",
      "[850]\ttraining's l2: 0.0181931\tvalid_1's l2: 0.126644\n",
      "[875]\ttraining's l2: 0.0172301\tvalid_1's l2: 0.127822\n",
      "[900]\ttraining's l2: 0.0167006\tvalid_1's l2: 0.128513\n",
      "[925]\ttraining's l2: 0.0160619\tvalid_1's l2: 0.129674\n",
      "[950]\ttraining's l2: 0.015403\tvalid_1's l2: 0.129913\n",
      "[975]\ttraining's l2: 0.0149387\tvalid_1's l2: 0.129683\n",
      "[1000]\ttraining's l2: 0.0142812\tvalid_1's l2: 0.131422\n",
      "[1025]\ttraining's l2: 0.0135807\tvalid_1's l2: 0.132304\n",
      "[1050]\ttraining's l2: 0.0130818\tvalid_1's l2: 0.133176\n",
      "[1075]\ttraining's l2: 0.0126738\tvalid_1's l2: 0.13254\n",
      "[1100]\ttraining's l2: 0.0122287\tvalid_1's l2: 0.132694\n",
      "[1125]\ttraining's l2: 0.0117362\tvalid_1's l2: 0.132985\n",
      "[1150]\ttraining's l2: 0.0114395\tvalid_1's l2: 0.133416\n",
      "[1175]\ttraining's l2: 0.0111039\tvalid_1's l2: 0.13422\n",
      "[1200]\ttraining's l2: 0.0106908\tvalid_1's l2: 0.134418\n",
      "[1225]\ttraining's l2: 0.0104297\tvalid_1's l2: 0.134445\n",
      "[1250]\ttraining's l2: 0.0099648\tvalid_1's l2: 0.1355\n",
      "[1275]\ttraining's l2: 0.009568\tvalid_1's l2: 0.136238\n",
      "Early stopping, best iteration is:\n",
      "[277]\ttraining's l2: 0.067334\tvalid_1's l2: 0.118199\n",
      "fold 2\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.634223\tvalid_1's l2: 0.865567\n",
      "[50]\ttraining's l2: 0.432686\tvalid_1's l2: 0.627881\n",
      "[75]\ttraining's l2: 0.304321\tvalid_1's l2: 0.479167\n",
      "[100]\ttraining's l2: 0.224252\tvalid_1's l2: 0.381411\n",
      "[125]\ttraining's l2: 0.16756\tvalid_1's l2: 0.308406\n",
      "[150]\ttraining's l2: 0.131652\tvalid_1's l2: 0.262882\n",
      "[175]\ttraining's l2: 0.108391\tvalid_1's l2: 0.233208\n",
      "[200]\ttraining's l2: 0.0910382\tvalid_1's l2: 0.205361\n",
      "[225]\ttraining's l2: 0.0788051\tvalid_1's l2: 0.188935\n",
      "[250]\ttraining's l2: 0.0694913\tvalid_1's l2: 0.174212\n",
      "[275]\ttraining's l2: 0.0625413\tvalid_1's l2: 0.163699\n",
      "[300]\ttraining's l2: 0.0578845\tvalid_1's l2: 0.160782\n",
      "[325]\ttraining's l2: 0.0534192\tvalid_1's l2: 0.154458\n",
      "[350]\ttraining's l2: 0.0497374\tvalid_1's l2: 0.152292\n",
      "[375]\ttraining's l2: 0.046456\tvalid_1's l2: 0.148404\n",
      "[400]\ttraining's l2: 0.0433148\tvalid_1's l2: 0.147394\n",
      "[425]\ttraining's l2: 0.041227\tvalid_1's l2: 0.146422\n",
      "[450]\ttraining's l2: 0.039098\tvalid_1's l2: 0.146266\n",
      "[475]\ttraining's l2: 0.0369386\tvalid_1's l2: 0.144054\n",
      "[500]\ttraining's l2: 0.0351573\tvalid_1's l2: 0.141997\n",
      "[525]\ttraining's l2: 0.0330126\tvalid_1's l2: 0.142017\n",
      "[550]\ttraining's l2: 0.0314497\tvalid_1's l2: 0.141589\n",
      "[575]\ttraining's l2: 0.0298189\tvalid_1's l2: 0.141387\n",
      "[600]\ttraining's l2: 0.0283024\tvalid_1's l2: 0.139713\n",
      "[625]\ttraining's l2: 0.0265872\tvalid_1's l2: 0.137374\n",
      "[650]\ttraining's l2: 0.0252106\tvalid_1's l2: 0.136699\n",
      "[675]\ttraining's l2: 0.0241791\tvalid_1's l2: 0.136925\n",
      "[700]\ttraining's l2: 0.0233519\tvalid_1's l2: 0.137128\n",
      "[725]\ttraining's l2: 0.0223449\tvalid_1's l2: 0.137193\n",
      "[750]\ttraining's l2: 0.0213638\tvalid_1's l2: 0.136446\n",
      "[775]\ttraining's l2: 0.0207424\tvalid_1's l2: 0.133455\n",
      "[800]\ttraining's l2: 0.0197094\tvalid_1's l2: 0.133567\n",
      "[825]\ttraining's l2: 0.0189578\tvalid_1's l2: 0.135021\n",
      "[850]\ttraining's l2: 0.0180857\tvalid_1's l2: 0.135931\n",
      "[875]\ttraining's l2: 0.0173953\tvalid_1's l2: 0.134735\n",
      "[900]\ttraining's l2: 0.0163954\tvalid_1's l2: 0.134199\n",
      "[925]\ttraining's l2: 0.0157706\tvalid_1's l2: 0.133951\n",
      "[950]\ttraining's l2: 0.0153212\tvalid_1's l2: 0.134836\n",
      "[975]\ttraining's l2: 0.0146852\tvalid_1's l2: 0.13528\n",
      "[1000]\ttraining's l2: 0.01401\tvalid_1's l2: 0.1341\n",
      "[1025]\ttraining's l2: 0.0134038\tvalid_1's l2: 0.134187\n",
      "[1050]\ttraining's l2: 0.0128503\tvalid_1's l2: 0.134488\n",
      "[1075]\ttraining's l2: 0.0124704\tvalid_1's l2: 0.134326\n",
      "[1100]\ttraining's l2: 0.0120307\tvalid_1's l2: 0.133774\n",
      "[1125]\ttraining's l2: 0.0115408\tvalid_1's l2: 0.132612\n",
      "[1150]\ttraining's l2: 0.0110415\tvalid_1's l2: 0.132372\n",
      "[1175]\ttraining's l2: 0.0106594\tvalid_1's l2: 0.13185\n",
      "[1200]\ttraining's l2: 0.0103201\tvalid_1's l2: 0.132036\n",
      "[1225]\ttraining's l2: 0.0100463\tvalid_1's l2: 0.131613\n",
      "[1250]\ttraining's l2: 0.00969625\tvalid_1's l2: 0.131246\n",
      "[1275]\ttraining's l2: 0.00928227\tvalid_1's l2: 0.131836\n",
      "[1300]\ttraining's l2: 0.00899941\tvalid_1's l2: 0.131859\n",
      "[1325]\ttraining's l2: 0.00868871\tvalid_1's l2: 0.132276\n",
      "[1350]\ttraining's l2: 0.0085062\tvalid_1's l2: 0.132134\n",
      "[1375]\ttraining's l2: 0.00819028\tvalid_1's l2: 0.131946\n",
      "[1400]\ttraining's l2: 0.00793896\tvalid_1's l2: 0.131727\n",
      "[1425]\ttraining's l2: 0.00767925\tvalid_1's l2: 0.131113\n",
      "[1450]\ttraining's l2: 0.00732794\tvalid_1's l2: 0.131265\n",
      "[1475]\ttraining's l2: 0.0071224\tvalid_1's l2: 0.131688\n",
      "[1500]\ttraining's l2: 0.0069221\tvalid_1's l2: 0.13132\n",
      "[1525]\ttraining's l2: 0.00674318\tvalid_1's l2: 0.130712\n",
      "[1550]\ttraining's l2: 0.00654822\tvalid_1's l2: 0.130851\n",
      "[1575]\ttraining's l2: 0.00630764\tvalid_1's l2: 0.130633\n",
      "[1600]\ttraining's l2: 0.00620276\tvalid_1's l2: 0.131101\n",
      "[1625]\ttraining's l2: 0.00600159\tvalid_1's l2: 0.13118\n",
      "[1650]\ttraining's l2: 0.00585566\tvalid_1's l2: 0.130899\n",
      "[1675]\ttraining's l2: 0.0056738\tvalid_1's l2: 0.131056\n",
      "[1700]\ttraining's l2: 0.00548653\tvalid_1's l2: 0.130724\n",
      "[1725]\ttraining's l2: 0.00537727\tvalid_1's l2: 0.130758\n",
      "[1750]\ttraining's l2: 0.00522478\tvalid_1's l2: 0.130914\n",
      "[1775]\ttraining's l2: 0.00508267\tvalid_1's l2: 0.130477\n",
      "[1800]\ttraining's l2: 0.00494273\tvalid_1's l2: 0.130184\n",
      "[1825]\ttraining's l2: 0.0047554\tvalid_1's l2: 0.130063\n",
      "[1850]\ttraining's l2: 0.00463547\tvalid_1's l2: 0.130305\n",
      "[1875]\ttraining's l2: 0.00452964\tvalid_1's l2: 0.130421\n",
      "[1900]\ttraining's l2: 0.00442548\tvalid_1's l2: 0.129962\n",
      "[1925]\ttraining's l2: 0.00427483\tvalid_1's l2: 0.129809\n",
      "[1950]\ttraining's l2: 0.00415202\tvalid_1's l2: 0.129613\n",
      "[1975]\ttraining's l2: 0.00406244\tvalid_1's l2: 0.129931\n",
      "[2000]\ttraining's l2: 0.00398863\tvalid_1's l2: 0.130101\n",
      "[2025]\ttraining's l2: 0.00386445\tvalid_1's l2: 0.13024\n",
      "[2050]\ttraining's l2: 0.00375436\tvalid_1's l2: 0.129831\n",
      "[2075]\ttraining's l2: 0.00366283\tvalid_1's l2: 0.129573\n",
      "[2100]\ttraining's l2: 0.00357416\tvalid_1's l2: 0.129486\n",
      "[2125]\ttraining's l2: 0.00350901\tvalid_1's l2: 0.129347\n",
      "[2150]\ttraining's l2: 0.00341578\tvalid_1's l2: 0.12936\n",
      "[2175]\ttraining's l2: 0.00331491\tvalid_1's l2: 0.1294\n",
      "[2200]\ttraining's l2: 0.00321233\tvalid_1's l2: 0.129473\n",
      "[2225]\ttraining's l2: 0.00314819\tvalid_1's l2: 0.129092\n",
      "[2250]\ttraining's l2: 0.00308693\tvalid_1's l2: 0.129148\n",
      "[2275]\ttraining's l2: 0.00300467\tvalid_1's l2: 0.129178\n",
      "[2300]\ttraining's l2: 0.0029296\tvalid_1's l2: 0.129078\n",
      "[2325]\ttraining's l2: 0.00285129\tvalid_1's l2: 0.128996\n",
      "[2350]\ttraining's l2: 0.00279403\tvalid_1's l2: 0.128985\n",
      "[2375]\ttraining's l2: 0.00274333\tvalid_1's l2: 0.12917\n",
      "[2400]\ttraining's l2: 0.00270877\tvalid_1's l2: 0.129153\n",
      "[2425]\ttraining's l2: 0.00265182\tvalid_1's l2: 0.128952\n",
      "[2450]\ttraining's l2: 0.00258217\tvalid_1's l2: 0.128999\n",
      "[2475]\ttraining's l2: 0.00252386\tvalid_1's l2: 0.12904\n",
      "[2500]\ttraining's l2: 0.00245602\tvalid_1's l2: 0.12897\n",
      "[2525]\ttraining's l2: 0.00240581\tvalid_1's l2: 0.128944\n",
      "[2550]\ttraining's l2: 0.00235452\tvalid_1's l2: 0.129246\n",
      "[2575]\ttraining's l2: 0.00231383\tvalid_1's l2: 0.129097\n",
      "[2600]\ttraining's l2: 0.0022504\tvalid_1's l2: 0.129046\n",
      "[2625]\ttraining's l2: 0.00221495\tvalid_1's l2: 0.129001\n",
      "[2650]\ttraining's l2: 0.00218602\tvalid_1's l2: 0.129065\n",
      "[2675]\ttraining's l2: 0.00213907\tvalid_1's l2: 0.129119\n",
      "[2700]\ttraining's l2: 0.00210823\tvalid_1's l2: 0.129079\n",
      "[2725]\ttraining's l2: 0.00205946\tvalid_1's l2: 0.129016\n",
      "[2750]\ttraining's l2: 0.00201542\tvalid_1's l2: 0.128704\n",
      "[2775]\ttraining's l2: 0.00200047\tvalid_1's l2: 0.128774\n",
      "[2800]\ttraining's l2: 0.00197118\tvalid_1's l2: 0.1288\n",
      "[2825]\ttraining's l2: 0.00193861\tvalid_1's l2: 0.128878\n",
      "[2850]\ttraining's l2: 0.00189411\tvalid_1's l2: 0.129007\n",
      "[2875]\ttraining's l2: 0.00185445\tvalid_1's l2: 0.128982\n",
      "[2900]\ttraining's l2: 0.00183445\tvalid_1's l2: 0.128964\n",
      "[2925]\ttraining's l2: 0.00180668\tvalid_1's l2: 0.129002\n",
      "[2950]\ttraining's l2: 0.00177636\tvalid_1's l2: 0.128869\n",
      "[2975]\ttraining's l2: 0.0017407\tvalid_1's l2: 0.128947\n",
      "[3000]\ttraining's l2: 0.00171016\tvalid_1's l2: 0.128759\n",
      "[3025]\ttraining's l2: 0.00169536\tvalid_1's l2: 0.128774\n",
      "[3050]\ttraining's l2: 0.00167662\tvalid_1's l2: 0.128694\n",
      "[3075]\ttraining's l2: 0.00165589\tvalid_1's l2: 0.128699\n",
      "[3100]\ttraining's l2: 0.00162429\tvalid_1's l2: 0.128769\n",
      "[3125]\ttraining's l2: 0.00160495\tvalid_1's l2: 0.128711\n",
      "[3150]\ttraining's l2: 0.00159076\tvalid_1's l2: 0.128732\n",
      "[3175]\ttraining's l2: 0.00157896\tvalid_1's l2: 0.128643\n",
      "[3200]\ttraining's l2: 0.00156015\tvalid_1's l2: 0.128631\n",
      "[3225]\ttraining's l2: 0.00153099\tvalid_1's l2: 0.128676\n",
      "[3250]\ttraining's l2: 0.00150961\tvalid_1's l2: 0.128572\n",
      "[3275]\ttraining's l2: 0.00149157\tvalid_1's l2: 0.128462\n",
      "[3300]\ttraining's l2: 0.00148159\tvalid_1's l2: 0.128481\n",
      "[3325]\ttraining's l2: 0.00146242\tvalid_1's l2: 0.128521\n",
      "[3350]\ttraining's l2: 0.00144163\tvalid_1's l2: 0.128474\n",
      "[3375]\ttraining's l2: 0.00141775\tvalid_1's l2: 0.128567\n",
      "[3400]\ttraining's l2: 0.00139819\tvalid_1's l2: 0.128468\n",
      "[3425]\ttraining's l2: 0.00139263\tvalid_1's l2: 0.1284\n",
      "[3450]\ttraining's l2: 0.00137808\tvalid_1's l2: 0.128353\n",
      "[3475]\ttraining's l2: 0.00135998\tvalid_1's l2: 0.128287\n",
      "[3500]\ttraining's l2: 0.0013364\tvalid_1's l2: 0.128284\n",
      "[3525]\ttraining's l2: 0.00131438\tvalid_1's l2: 0.128224\n",
      "[3550]\ttraining's l2: 0.00130802\tvalid_1's l2: 0.128215\n",
      "[3575]\ttraining's l2: 0.00129595\tvalid_1's l2: 0.128245\n",
      "[3600]\ttraining's l2: 0.00127281\tvalid_1's l2: 0.128144\n",
      "[3625]\ttraining's l2: 0.00125858\tvalid_1's l2: 0.128135\n",
      "[3650]\ttraining's l2: 0.00124477\tvalid_1's l2: 0.128184\n",
      "[3675]\ttraining's l2: 0.00123289\tvalid_1's l2: 0.128195\n",
      "[3700]\ttraining's l2: 0.00121765\tvalid_1's l2: 0.128297\n",
      "[3725]\ttraining's l2: 0.00120692\tvalid_1's l2: 0.128277\n",
      "[3750]\ttraining's l2: 0.0011912\tvalid_1's l2: 0.128146\n",
      "[3775]\ttraining's l2: 0.00117417\tvalid_1's l2: 0.128142\n",
      "[3800]\ttraining's l2: 0.00116237\tvalid_1's l2: 0.128125\n",
      "[3825]\ttraining's l2: 0.00115558\tvalid_1's l2: 0.128126\n",
      "[3850]\ttraining's l2: 0.00113821\tvalid_1's l2: 0.128093\n",
      "[3875]\ttraining's l2: 0.00111776\tvalid_1's l2: 0.127944\n",
      "[3900]\ttraining's l2: 0.00110472\tvalid_1's l2: 0.12793\n",
      "[3925]\ttraining's l2: 0.00109839\tvalid_1's l2: 0.128012\n",
      "[3950]\ttraining's l2: 0.00108341\tvalid_1's l2: 0.128038\n",
      "[3975]\ttraining's l2: 0.00107426\tvalid_1's l2: 0.12802\n",
      "[4000]\ttraining's l2: 0.00105832\tvalid_1's l2: 0.127935\n",
      "[4025]\ttraining's l2: 0.00104473\tvalid_1's l2: 0.128023\n",
      "[4050]\ttraining's l2: 0.00102968\tvalid_1's l2: 0.127997\n",
      "[4075]\ttraining's l2: 0.00102423\tvalid_1's l2: 0.127968\n",
      "[4100]\ttraining's l2: 0.00101588\tvalid_1's l2: 0.128013\n",
      "[4125]\ttraining's l2: 0.00100254\tvalid_1's l2: 0.128072\n",
      "[4150]\ttraining's l2: 0.000993117\tvalid_1's l2: 0.128052\n",
      "[4175]\ttraining's l2: 0.000980711\tvalid_1's l2: 0.12804\n",
      "[4200]\ttraining's l2: 0.000974008\tvalid_1's l2: 0.128067\n",
      "[4225]\ttraining's l2: 0.000967225\tvalid_1's l2: 0.12814\n",
      "[4250]\ttraining's l2: 0.000953224\tvalid_1's l2: 0.128129\n",
      "[4275]\ttraining's l2: 0.000945606\tvalid_1's l2: 0.128144\n",
      "[4300]\ttraining's l2: 0.000934794\tvalid_1's l2: 0.128135\n",
      "[4325]\ttraining's l2: 0.000930735\tvalid_1's l2: 0.1281\n",
      "[4350]\ttraining's l2: 0.00092533\tvalid_1's l2: 0.127998\n",
      "[4375]\ttraining's l2: 0.000913539\tvalid_1's l2: 0.128051\n",
      "[4400]\ttraining's l2: 0.000904016\tvalid_1's l2: 0.127987\n",
      "[4425]\ttraining's l2: 0.000891473\tvalid_1's l2: 0.127924\n",
      "[4450]\ttraining's l2: 0.0008847\tvalid_1's l2: 0.127829\n",
      "[4475]\ttraining's l2: 0.000872178\tvalid_1's l2: 0.127804\n",
      "[4500]\ttraining's l2: 0.000865429\tvalid_1's l2: 0.127798\n",
      "[4525]\ttraining's l2: 0.000856728\tvalid_1's l2: 0.12781\n",
      "[4550]\ttraining's l2: 0.000849213\tvalid_1's l2: 0.127789\n",
      "[4575]\ttraining's l2: 0.000846641\tvalid_1's l2: 0.127813\n",
      "[4600]\ttraining's l2: 0.000837799\tvalid_1's l2: 0.127833\n",
      "[4625]\ttraining's l2: 0.00083019\tvalid_1's l2: 0.127731\n",
      "[4650]\ttraining's l2: 0.000821466\tvalid_1's l2: 0.127695\n",
      "[4675]\ttraining's l2: 0.000812216\tvalid_1's l2: 0.127673\n",
      "[4700]\ttraining's l2: 0.000804361\tvalid_1's l2: 0.127642\n",
      "[4725]\ttraining's l2: 0.000802423\tvalid_1's l2: 0.127638\n",
      "[4750]\ttraining's l2: 0.000791233\tvalid_1's l2: 0.127519\n",
      "[4775]\ttraining's l2: 0.00078452\tvalid_1's l2: 0.127526\n",
      "[4800]\ttraining's l2: 0.000776786\tvalid_1's l2: 0.127535\n",
      "[4825]\ttraining's l2: 0.000768069\tvalid_1's l2: 0.127538\n",
      "[4850]\ttraining's l2: 0.000765962\tvalid_1's l2: 0.127514\n",
      "[4875]\ttraining's l2: 0.000762141\tvalid_1's l2: 0.127516\n",
      "[4900]\ttraining's l2: 0.000757542\tvalid_1's l2: 0.127494\n",
      "[4925]\ttraining's l2: 0.000751715\tvalid_1's l2: 0.127558\n",
      "[4950]\ttraining's l2: 0.00074511\tvalid_1's l2: 0.127565\n",
      "[4975]\ttraining's l2: 0.000743841\tvalid_1's l2: 0.127569\n",
      "[5000]\ttraining's l2: 0.000740316\tvalid_1's l2: 0.127562\n",
      "[5025]\ttraining's l2: 0.000734463\tvalid_1's l2: 0.127568\n",
      "[5050]\ttraining's l2: 0.000727982\tvalid_1's l2: 0.127578\n",
      "[5075]\ttraining's l2: 0.000724179\tvalid_1's l2: 0.12756\n",
      "[5100]\ttraining's l2: 0.000721016\tvalid_1's l2: 0.127545\n",
      "[5125]\ttraining's l2: 0.000717724\tvalid_1's l2: 0.12756\n",
      "[5150]\ttraining's l2: 0.000712657\tvalid_1's l2: 0.127526\n",
      "[5175]\ttraining's l2: 0.000707101\tvalid_1's l2: 0.127543\n",
      "[5200]\ttraining's l2: 0.000703636\tvalid_1's l2: 0.127559\n",
      "[5225]\ttraining's l2: 0.000698368\tvalid_1's l2: 0.127624\n",
      "[5250]\ttraining's l2: 0.000695638\tvalid_1's l2: 0.127657\n",
      "[5275]\ttraining's l2: 0.000689201\tvalid_1's l2: 0.127601\n",
      "[5300]\ttraining's l2: 0.000684804\tvalid_1's l2: 0.127583\n",
      "[5325]\ttraining's l2: 0.000682457\tvalid_1's l2: 0.127587\n",
      "[5350]\ttraining's l2: 0.000678318\tvalid_1's l2: 0.127588\n",
      "[5375]\ttraining's l2: 0.000676531\tvalid_1's l2: 0.127596\n",
      "[5400]\ttraining's l2: 0.000671473\tvalid_1's l2: 0.127565\n",
      "[5425]\ttraining's l2: 0.000667313\tvalid_1's l2: 0.127556\n",
      "[5450]\ttraining's l2: 0.000664229\tvalid_1's l2: 0.127571\n",
      "[5475]\ttraining's l2: 0.00065889\tvalid_1's l2: 0.12757\n",
      "[5500]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "[5525]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "[5550]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "[5575]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "[5600]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "[5625]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "[5650]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "[5675]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "[5700]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "[5725]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "[5750]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "[5775]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "[5800]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "[5825]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "[5850]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "[5875]\ttraining's l2: 0.000658751\tvalid_1's l2: 0.127574\n",
      "Early stopping, best iteration is:\n",
      "[4899]\ttraining's l2: 0.000757837\tvalid_1's l2: 0.127491\n",
      "fold 3\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.715377\tvalid_1's l2: 0.441106\n",
      "[50]\ttraining's l2: 0.486311\tvalid_1's l2: 0.290455\n",
      "[75]\ttraining's l2: 0.334327\tvalid_1's l2: 0.194951\n",
      "[100]\ttraining's l2: 0.243245\tvalid_1's l2: 0.138176\n",
      "[125]\ttraining's l2: 0.182428\tvalid_1's l2: 0.103246\n",
      "[150]\ttraining's l2: 0.145294\tvalid_1's l2: 0.083378\n",
      "[175]\ttraining's l2: 0.118212\tvalid_1's l2: 0.0687356\n",
      "[200]\ttraining's l2: 0.0979131\tvalid_1's l2: 0.0600843\n",
      "[225]\ttraining's l2: 0.0862453\tvalid_1's l2: 0.0545055\n",
      "[250]\ttraining's l2: 0.075944\tvalid_1's l2: 0.0514642\n",
      "[275]\ttraining's l2: 0.0696015\tvalid_1's l2: 0.0507918\n",
      "[300]\ttraining's l2: 0.0629225\tvalid_1's l2: 0.0501526\n",
      "[325]\ttraining's l2: 0.0583308\tvalid_1's l2: 0.0499817\n",
      "[350]\ttraining's l2: 0.0540415\tvalid_1's l2: 0.0500699\n",
      "[375]\ttraining's l2: 0.0506452\tvalid_1's l2: 0.0500187\n",
      "[400]\ttraining's l2: 0.0476613\tvalid_1's l2: 0.0503502\n",
      "[425]\ttraining's l2: 0.0451141\tvalid_1's l2: 0.050186\n",
      "[450]\ttraining's l2: 0.043202\tvalid_1's l2: 0.0496328\n",
      "[475]\ttraining's l2: 0.0410841\tvalid_1's l2: 0.0495966\n",
      "[500]\ttraining's l2: 0.0387076\tvalid_1's l2: 0.051455\n",
      "[525]\ttraining's l2: 0.0367067\tvalid_1's l2: 0.0522635\n",
      "[550]\ttraining's l2: 0.0349542\tvalid_1's l2: 0.0524544\n",
      "[575]\ttraining's l2: 0.0332036\tvalid_1's l2: 0.0525287\n",
      "[600]\ttraining's l2: 0.0317347\tvalid_1's l2: 0.0534275\n",
      "[625]\ttraining's l2: 0.0301342\tvalid_1's l2: 0.0531178\n",
      "[650]\ttraining's l2: 0.0288334\tvalid_1's l2: 0.0534317\n",
      "[675]\ttraining's l2: 0.0275167\tvalid_1's l2: 0.0536304\n",
      "[700]\ttraining's l2: 0.0264921\tvalid_1's l2: 0.0537403\n",
      "[725]\ttraining's l2: 0.025304\tvalid_1's l2: 0.054028\n",
      "[750]\ttraining's l2: 0.0241397\tvalid_1's l2: 0.0536784\n",
      "[775]\ttraining's l2: 0.0231036\tvalid_1's l2: 0.0541162\n",
      "[800]\ttraining's l2: 0.0220854\tvalid_1's l2: 0.0541499\n",
      "[825]\ttraining's l2: 0.0208723\tvalid_1's l2: 0.0534883\n",
      "[850]\ttraining's l2: 0.0199774\tvalid_1's l2: 0.0536647\n",
      "[875]\ttraining's l2: 0.0191333\tvalid_1's l2: 0.053905\n",
      "[900]\ttraining's l2: 0.018445\tvalid_1's l2: 0.0538522\n",
      "[925]\ttraining's l2: 0.0177824\tvalid_1's l2: 0.0541428\n",
      "[950]\ttraining's l2: 0.0169787\tvalid_1's l2: 0.0538051\n",
      "[975]\ttraining's l2: 0.0161635\tvalid_1's l2: 0.0542278\n",
      "[1000]\ttraining's l2: 0.0155878\tvalid_1's l2: 0.0543481\n",
      "[1025]\ttraining's l2: 0.0148676\tvalid_1's l2: 0.0540067\n",
      "[1050]\ttraining's l2: 0.0141221\tvalid_1's l2: 0.0542509\n",
      "[1075]\ttraining's l2: 0.0132538\tvalid_1's l2: 0.0544012\n",
      "[1100]\ttraining's l2: 0.0126057\tvalid_1's l2: 0.0542159\n",
      "[1125]\ttraining's l2: 0.0121835\tvalid_1's l2: 0.0542853\n",
      "[1150]\ttraining's l2: 0.0116511\tvalid_1's l2: 0.0546344\n",
      "[1175]\ttraining's l2: 0.0112755\tvalid_1's l2: 0.0547184\n",
      "[1200]\ttraining's l2: 0.0109303\tvalid_1's l2: 0.0548533\n",
      "[1225]\ttraining's l2: 0.0105511\tvalid_1's l2: 0.0547359\n",
      "[1250]\ttraining's l2: 0.0101573\tvalid_1's l2: 0.0548199\n",
      "[1275]\ttraining's l2: 0.00988538\tvalid_1's l2: 0.0550277\n",
      "[1300]\ttraining's l2: 0.00944535\tvalid_1's l2: 0.0553183\n",
      "[1325]\ttraining's l2: 0.00909371\tvalid_1's l2: 0.0553305\n",
      "[1350]\ttraining's l2: 0.00879706\tvalid_1's l2: 0.0553388\n",
      "[1375]\ttraining's l2: 0.00841265\tvalid_1's l2: 0.0548568\n",
      "[1400]\ttraining's l2: 0.00799097\tvalid_1's l2: 0.0544115\n",
      "[1425]\ttraining's l2: 0.0077062\tvalid_1's l2: 0.0546203\n",
      "[1450]\ttraining's l2: 0.00743407\tvalid_1's l2: 0.0548646\n",
      "Early stopping, best iteration is:\n",
      "[463]\ttraining's l2: 0.0419598\tvalid_1's l2: 0.0494287\n",
      "fold 4\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.727726\tvalid_1's l2: 0.412386\n",
      "[50]\ttraining's l2: 0.494219\tvalid_1's l2: 0.281579\n",
      "[75]\ttraining's l2: 0.339835\tvalid_1's l2: 0.1895\n",
      "[100]\ttraining's l2: 0.245974\tvalid_1's l2: 0.140584\n",
      "[125]\ttraining's l2: 0.183377\tvalid_1's l2: 0.108954\n",
      "[150]\ttraining's l2: 0.142997\tvalid_1's l2: 0.0876647\n",
      "[175]\ttraining's l2: 0.115287\tvalid_1's l2: 0.0696423\n",
      "[200]\ttraining's l2: 0.095009\tvalid_1's l2: 0.0606563\n",
      "[225]\ttraining's l2: 0.0814432\tvalid_1's l2: 0.0552584\n",
      "[250]\ttraining's l2: 0.0713504\tvalid_1's l2: 0.0531238\n",
      "[275]\ttraining's l2: 0.0636474\tvalid_1's l2: 0.0520131\n",
      "[300]\ttraining's l2: 0.0580021\tvalid_1's l2: 0.050719\n",
      "[325]\ttraining's l2: 0.0540241\tvalid_1's l2: 0.0505434\n",
      "[350]\ttraining's l2: 0.0499766\tvalid_1's l2: 0.0508555\n",
      "[375]\ttraining's l2: 0.0463987\tvalid_1's l2: 0.0515005\n",
      "[400]\ttraining's l2: 0.043522\tvalid_1's l2: 0.0514318\n",
      "[425]\ttraining's l2: 0.0408233\tvalid_1's l2: 0.0518228\n",
      "[450]\ttraining's l2: 0.0384847\tvalid_1's l2: 0.0527766\n",
      "[475]\ttraining's l2: 0.0361714\tvalid_1's l2: 0.0524784\n",
      "[500]\ttraining's l2: 0.0339169\tvalid_1's l2: 0.0526926\n",
      "[525]\ttraining's l2: 0.0322352\tvalid_1's l2: 0.0533474\n",
      "[550]\ttraining's l2: 0.0307102\tvalid_1's l2: 0.0536585\n",
      "[575]\ttraining's l2: 0.0293328\tvalid_1's l2: 0.053702\n",
      "[600]\ttraining's l2: 0.0278557\tvalid_1's l2: 0.0533941\n",
      "[625]\ttraining's l2: 0.0263181\tvalid_1's l2: 0.0536925\n",
      "[650]\ttraining's l2: 0.0248982\tvalid_1's l2: 0.053351\n",
      "[675]\ttraining's l2: 0.0236045\tvalid_1's l2: 0.0531537\n",
      "[700]\ttraining's l2: 0.0224361\tvalid_1's l2: 0.0534302\n",
      "[725]\ttraining's l2: 0.0212211\tvalid_1's l2: 0.0534997\n",
      "[750]\ttraining's l2: 0.0203093\tvalid_1's l2: 0.0541758\n",
      "[775]\ttraining's l2: 0.0193345\tvalid_1's l2: 0.0541107\n",
      "[800]\ttraining's l2: 0.0183846\tvalid_1's l2: 0.0543302\n",
      "[825]\ttraining's l2: 0.0176826\tvalid_1's l2: 0.0539074\n",
      "[850]\ttraining's l2: 0.0169641\tvalid_1's l2: 0.0537383\n",
      "[875]\ttraining's l2: 0.0162279\tvalid_1's l2: 0.0537796\n",
      "[900]\ttraining's l2: 0.0157392\tvalid_1's l2: 0.0540949\n",
      "[925]\ttraining's l2: 0.0150566\tvalid_1's l2: 0.0540959\n",
      "[950]\ttraining's l2: 0.0144037\tvalid_1's l2: 0.0541211\n",
      "[975]\ttraining's l2: 0.0138433\tvalid_1's l2: 0.0541385\n",
      "[1000]\ttraining's l2: 0.0132987\tvalid_1's l2: 0.054579\n",
      "[1025]\ttraining's l2: 0.0128055\tvalid_1's l2: 0.0548668\n",
      "[1050]\ttraining's l2: 0.0123001\tvalid_1's l2: 0.0545916\n",
      "[1075]\ttraining's l2: 0.0119328\tvalid_1's l2: 0.0548338\n",
      "[1100]\ttraining's l2: 0.0114838\tvalid_1's l2: 0.0554\n",
      "[1125]\ttraining's l2: 0.010948\tvalid_1's l2: 0.0550866\n",
      "[1150]\ttraining's l2: 0.01058\tvalid_1's l2: 0.0552171\n",
      "[1175]\ttraining's l2: 0.0101749\tvalid_1's l2: 0.0553331\n",
      "[1200]\ttraining's l2: 0.00966253\tvalid_1's l2: 0.0553692\n",
      "[1225]\ttraining's l2: 0.00942171\tvalid_1's l2: 0.0553628\n",
      "[1250]\ttraining's l2: 0.00913393\tvalid_1's l2: 0.0553802\n",
      "[1275]\ttraining's l2: 0.00874174\tvalid_1's l2: 0.0554251\n",
      "[1300]\ttraining's l2: 0.0084362\tvalid_1's l2: 0.0551193\n",
      "Early stopping, best iteration is:\n",
      "[319]\ttraining's l2: 0.0549441\tvalid_1's l2: 0.050424\n"
     ]
    }
   ],
   "source": [
    "feature_importance = get_feature_importance(5,X_train,y_train,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['RON_of_raw_material', 861.2],\n",
       "       ['density', 151.8],\n",
       "       ['S-ZORB.FT_9301.PV', 133.0],\n",
       "       ['S-ZORB.TE_5008.DACA', 116.2],\n",
       "       ['S-ZORB.AT_1001.DACA', 114.0],\n",
       "       ['S-ZORB.PDT_2606.DACA', 112.6],\n",
       "       ['S-ZORB.FT_1003.PV', 93.0],\n",
       "       ['S-ZORB.LT_1002.DACA', 88.8],\n",
       "       ['S-ZORB.FT_1504.DACA.PV', 86.8],\n",
       "       ['S-ZORB.TE_1105.PV', 84.8],\n",
       "       ['S-ZORB.AT-0009.DACA.PV', 81.0],\n",
       "       ['S-ZORB.PT_1604.DACA', 80.0],\n",
       "       ['S-ZORB.FT_3702.DACA', 78.8],\n",
       "       ['S-ZORB.LT_9001.DACA', 78.4],\n",
       "       ['S-ZORB.FC_1203.PV', 77.6],\n",
       "       ['S-ZORB.FT_2431.DACA', 75.6],\n",
       "       ['S-ZORB.TE_5102.PV', 75.2],\n",
       "       ['S-ZORB.FC_2702.DACA', 72.4],\n",
       "       ['S-ZORB.FT_1001.PV', 71.8],\n",
       "       ['S-ZORB.FC_1102.PV', 69.6],\n",
       "       ['S-ZORB.FC_5001.DACA', 68.6],\n",
       "       ['S-ZORB.FC_1201.PV', 67.4],\n",
       "       ['S-ZORB.PC_1001A.PV', 67.2],\n",
       "       ['S-ZORB.AT-0011.DACA.PV', 67.2],\n",
       "       ['S-ZORB.CAL_H2.PV', 65.4],\n",
       "       ['S-ZORB.TE_5202.PV', 65.4],\n",
       "       ['Substitute_S', 65.4],\n",
       "       ['S-ZORB.TE_1203.PV', 64.2],\n",
       "       ['S-ZORB.FT_5101.PV', 63.8],\n",
       "       ['S-ZORB.TE_1501.DACA', 63.2],\n",
       "       ['S-ZORB.LC_3301.DACA', 62.6],\n",
       "       ['S-ZORB.FT_9001.PV', 62.6],\n",
       "       ['S-ZORB.PT_9301.PV', 62.4],\n",
       "       ['S-ZORB.PT_6008.DACA', 62.4],\n",
       "       ['S-ZORB.AT_6201.DACA', 60.6],\n",
       "       ['S-ZORB.TC_2801.PV', 59.8],\n",
       "       ['S-ZORB.PT_9001.PV', 59.2],\n",
       "       ['S-ZORB.FT_9402.PV', 58.8],\n",
       "       ['S-ZORB.AT-0008.DACA.PV', 58.6],\n",
       "       ['S-ZORB.TE_9301.PV', 58.6],\n",
       "       ['S-ZORB.PC_3301.DACA', 57.4],\n",
       "       ['S-ZORB.TE_1601.PV', 57.2],\n",
       "       ['S-ZORB.PT_9401.PV', 56.6],\n",
       "       ['S-ZORB.FT_9002.DACA', 56.6],\n",
       "       ['S-ZORB.LT_2901.DACA', 55.2],\n",
       "       ['S-ZORB.TE_1104.DACA', 55.2],\n",
       "       ['S-ZORB.TE_2401.DACA', 54.2],\n",
       "       ['S-ZORB.FT_1004.PV', 52.8],\n",
       "       ['S-ZORB.TE_2603.DACA', 52.4],\n",
       "       ['Regenerated_coke', 52.2],\n",
       "       ['S-ZORB.TE_5004.DACA', 52.2],\n",
       "       ['Sulfur_content_of_raw_material', 51.2],\n",
       "       ['S-ZORB.FT_2001.DACA', 50.6],\n",
       "       ['S-ZORB.SIS_TE_2606.PV', 50.2],\n",
       "       ['S-ZORB.LC_1202.PV', 50.0],\n",
       "       ['S-ZORB.LI_9102.DACA', 50.0],\n",
       "       ['S-ZORB.LC_1203.DACA', 50.0],\n",
       "       ['S-ZORB.PDT_1003.DACA', 49.8],\n",
       "       ['Substitute_coke', 49.0],\n",
       "       ['S-ZORB.TE_9002.DACA', 48.0],\n",
       "       ['S-ZORB.LC_1201.PV', 47.2],\n",
       "       ['S-ZORB.TC_5005.PV', 47.2],\n",
       "       ['Saturated_hydrocarbon', 47.0],\n",
       "       ['S-ZORB.PT_1103.DACA', 46.4],\n",
       "       ['S-ZORB.FC_3101.PV', 44.6],\n",
       "       ['S-ZORB.TE_5002.DACA', 44.6],\n",
       "       ['S-ZORB.SIS_TE_2802', 43.8],\n",
       "       ['S-ZORB.TE_1106.DACA', 43.6],\n",
       "       ['S-ZORB.PDI_2703A.PV', 43.4],\n",
       "       ['S-ZORB.FC_2501.PV', 43.2],\n",
       "       ['S-ZORB.CAL_1.CANGLIANG.PV', 42.4],\n",
       "       ['S-ZORB.SIS_TE_2605.PV', 42.2],\n",
       "       ['S-ZORB.FT_9401.PV', 41.2],\n",
       "       ['S-ZORB.PT_1102.DACA', 41.0],\n",
       "       ['S-ZORB.PDT_3602.DACA', 41.0],\n",
       "       ['S-ZORB.TE_1604.DACA', 40.6],\n",
       "       ['S-ZORB.ZT_2533.DACA', 40.2],\n",
       "       ['S-ZORB.TE_1605.DACA', 39.0],\n",
       "       ['S-ZORB.FT_5204.DACA.PV', 38.6],\n",
       "       ['S-ZORB.PT_2603.DACA', 38.2],\n",
       "       ['S-ZORB.FT_2901.DACA', 37.6],\n",
       "       ['S-ZORB.TE_2604.DACA', 37.4],\n",
       "       ['S-ZORB.LT_1501.DACA', 36.8],\n",
       "       ['S-ZORB.SIS_FT_3202.PV', 36.8],\n",
       "       ['S-ZORB.PT_1201.PV', 36.6],\n",
       "       ['S-ZORB.FT_9101.PV', 35.2],\n",
       "       ['S-ZORB.FT_1301.DACA', 35.2],\n",
       "       ['S-ZORB.FT_3501.DACA', 34.6],\n",
       "       ['S-ZORB.PT_2101.PV', 34.2],\n",
       "       ['S-ZORB.TE_7106B.DACA', 34.0],\n",
       "       ['S-ZORB.PT_2901.DACA', 33.2],\n",
       "       ['S-ZORB.AT-0005.DACA.PV', 32.8],\n",
       "       ['S-ZORB.FC_5202.PV', 32.6],\n",
       "       ['S-ZORB.SIS_PT_2602.PV', 32.6],\n",
       "       ['S-ZORB.AT-0004.DACA.PV', 32.4],\n",
       "       ['S-ZORB.TE_7108B.DACA', 32.4],\n",
       "       ['S-ZORB.TE_1107.DACA', 32.2],\n",
       "       ['S-ZORB.FT_5201.PV', 32.0],\n",
       "       ['S-ZORB.AC_6001.PV', 31.6],\n",
       "       ['S-ZORB.LT_3801.DACA', 31.6],\n",
       "       ['olefin', 31.4],\n",
       "       ['S-ZORB.TC_1606.PV', 31.2],\n",
       "       ['S-ZORB.TE_5001.DACA', 31.0],\n",
       "       ['S-ZORB.CAL.LINE.PV', 31.0],\n",
       "       ['S-ZORB.FT_2502.DACA', 30.8],\n",
       "       ['S-ZORB.PC_3101.DACA', 30.6],\n",
       "       ['S-ZORB.PT_1501.PV', 30.2],\n",
       "       ['S-ZORB.PT_7103B.DACA', 30.0],\n",
       "       ['S-ZORB.TE_1102.DACA.PV', 29.8],\n",
       "       ['S-ZORB.AT-0006.DACA.PV', 29.8],\n",
       "       ['S-ZORB.PT_2502.DACA', 29.4],\n",
       "       ['S-ZORB.PDC_2702.DACA', 29.4],\n",
       "       ['S-ZORB.TXE_3202A.DACA', 29.0],\n",
       "       ['S-ZORB.BS_AT_2402.PV', 28.8],\n",
       "       ['S-ZORB.PDT_1002.DACA', 28.4],\n",
       "       ['S-ZORB.TC_3203.DACA', 28.4],\n",
       "       ['S-ZORB.SIS_TE_6010.PV', 27.6],\n",
       "       ['S-ZORB.TE_1001.PV', 27.4],\n",
       "       ['S-ZORB.TE_5006.DACA', 27.4],\n",
       "       ['S-ZORB.FC_5103.DACA', 27.0],\n",
       "       ['S-ZORB.PDT_2104.PV', 27.0],\n",
       "       ['S-ZORB.TE_2005.PV', 26.8],\n",
       "       ['S-ZORB.AT-0007.DACA.PV', 26.8],\n",
       "       ['Regenerated_S', 26.6],\n",
       "       ['S-ZORB.AT-0002.DACA.PV', 26.6],\n",
       "       ['S-ZORB.PT_9402.PV', 26.4],\n",
       "       ['S-ZORB.TC_1607.DACA', 26.2],\n",
       "       ['S-ZORB.PDT_2704.DACA', 26.0],\n",
       "       ['S-ZORB.LC_5001.PV', 26.0],\n",
       "       ['S-ZORB.PDT_2409.DACA', 25.6],\n",
       "       ['S-ZORB.FT_3701.DACA', 25.6],\n",
       "       ['S-ZORB.TE_2501.DACA', 25.4],\n",
       "       ['S-ZORB.TC_2101.PV', 25.4],\n",
       "       ['S-ZORB.LT_9101.DACA', 25.4],\n",
       "       ['S-ZORB.FT_3001.DACA', 25.2],\n",
       "       ['S-ZORB.FT_1204.DACA.PV', 25.0],\n",
       "       ['S-ZORB.BS_AT_2401.PV', 25.0],\n",
       "       ['S-ZORB.PDT_2906.DACA', 24.8],\n",
       "       ['S-ZORB.SIS_PT_2703', 24.8],\n",
       "       ['S-ZORB.PT_2607.DACA', 24.6],\n",
       "       ['S-ZORB.TE_1603.DACA', 24.6],\n",
       "       ['S-ZORB.TE_1103.DACA', 24.0],\n",
       "       ['S-ZORB.PC_2105.PV', 23.8],\n",
       "       ['S-ZORB.PC_2401B.PIDA.OP', 23.6],\n",
       "       ['S-ZORB.PT_6006.DACA', 23.6],\n",
       "       ['S-ZORB.FT_1204.PV', 23.6],\n",
       "       ['S-ZORB.TE_1201.PV', 23.2],\n",
       "       ['S-ZORB.RXL_0001.AUXCALCA.PV', 22.8],\n",
       "       ['S-ZORB.PDT_2001.DACA', 22.6],\n",
       "       ['S-ZORB.TE_3112.DACA', 22.6],\n",
       "       ['S-ZORB.PT_2801.PV', 22.6],\n",
       "       ['S-ZORB.FC_1101.PV', 22.4],\n",
       "       ['S-ZORB.TE_2002.DACA', 22.2],\n",
       "       ['S-ZORB.TC_2702.DACA', 22.0],\n",
       "       ['S-ZORB.SIS_TEX_3103B.PV', 21.8],\n",
       "       ['S-ZORB.LC_5101.PV', 21.8],\n",
       "       ['S-ZORB.TE_1101.DACA', 21.6],\n",
       "       ['S-ZORB.PDT_2605.DACA', 21.4],\n",
       "       ['S-ZORB.TE_2104.DACA', 21.4],\n",
       "       ['S-ZORB.PT_6002.PV', 21.4],\n",
       "       ['S-ZORB.PDT_3002.DACA', 21.2],\n",
       "       ['S-ZORB.FC_1005.PV', 20.8],\n",
       "       ['S-ZORB.AT-0003.DACA.PV', 20.8],\n",
       "       ['S-ZORB.PT_2106.DACA', 20.8],\n",
       "       ['S-ZORB.FT_9202.PV', 20.8],\n",
       "       ['S-ZORB.TE_1602.DACA', 20.6],\n",
       "       ['S-ZORB.LC_1203.PIDA.PV', 20.4],\n",
       "       ['S-ZORB.PC_6001.PV', 20.4],\n",
       "       ['S-ZORB.LC_2601.DACA', 20.4],\n",
       "       ['S-ZORB.PT_1601.DACA', 20.2],\n",
       "       ['S-ZORB.FT_5104.PV', 20.2],\n",
       "       ['S-ZORB.FT_2302.DACA', 20.0],\n",
       "       ['S-ZORB.PDC_2502.PV', 20.0],\n",
       "       ['S-ZORB.TC_2607.PV', 20.0],\n",
       "       ['S-ZORB.TE_5101.DACA', 19.6],\n",
       "       ['S-ZORB.AT-0013.DACA.PV', 19.4],\n",
       "       ['S-ZORB.FC_2801.PV', 19.4],\n",
       "       ['S-ZORB.FC_2601.PV', 19.4],\n",
       "       ['S-ZORB.FT_1006.DACA.PV', 19.2],\n",
       "       ['S-ZORB.LI_2107.DACA', 19.0],\n",
       "       ['S-ZORB.TE_2608.DACA', 19.0],\n",
       "       ['S-ZORB.AT-0001.DACA.PV', 18.8],\n",
       "       ['S-ZORB.LC_5002.DACA', 18.8],\n",
       "       ['S-ZORB.PT_1602A.PV', 18.6],\n",
       "       ['S-ZORB.PDI_2105.DACA', 18.6],\n",
       "       ['S-ZORB.TC_3102.DACA', 18.6],\n",
       "       ['S-ZORB.PDT_2503.DACA', 18.4],\n",
       "       ['S-ZORB.FT_3301.PV', 18.2],\n",
       "       ['S-ZORB.TE_1101.DACA.PV', 18.2],\n",
       "       ['S-ZORB.LT_1301.DACA', 18.0],\n",
       "       ['S-ZORB.FT_3303.DACA', 17.8],\n",
       "       ['S-ZORB.PDT_2604.PV', 17.2],\n",
       "       ['S-ZORB.PT_2301.PV', 17.2],\n",
       "       ['S-ZORB.TE_2901.DACA', 17.2],\n",
       "       ['S-ZORB.AT_1001.PV', 17.2],\n",
       "       ['S-ZORB.LT_3101.DACA', 17.0],\n",
       "       ['S-ZORB.PC_1202.PV', 16.8],\n",
       "       ['S-ZORB.PDT_3502.DACA', 16.6],\n",
       "       ['S-ZORB.PC_2601.PV', 16.4],\n",
       "       ['S-ZORB.PT_6005.DACA', 16.2],\n",
       "       ['S-ZORB.TE_2103.PV', 16.0],\n",
       "       ['S-ZORB.TE_6002.DACA', 16.0],\n",
       "       ['S-ZORB.PT_6009.DACA', 15.8],\n",
       "       ['S-ZORB.TE_7102B.DACA', 15.6],\n",
       "       ['S-ZORB.PT_7107B.DACA', 15.6],\n",
       "       ['S-ZORB.PC_2902.DACA', 15.4],\n",
       "       ['S-ZORB.PDI_2903.DACA', 15.2],\n",
       "       ['S-ZORB.DT_2001.DACA', 15.2],\n",
       "       ['S-ZORB.PT_6003.DACA', 15.2],\n",
       "       ['S-ZORB.PT_2501.DACA', 15.2],\n",
       "       ['S-ZORB.FT_9302.PV', 15.0],\n",
       "       ['S-ZORB.TE_5003.DACA', 15.0],\n",
       "       ['S-ZORB.FT_2701.DACA', 15.0],\n",
       "       ['S-ZORB.FT_2433.DACA', 15.0],\n",
       "       ['S-ZORB.TE_5009.DACA', 15.0],\n",
       "       ['S-ZORB.FT_9403.PV', 14.8],\n",
       "       ['S-ZORB.FT_1503.DACA.PV', 14.8],\n",
       "       ['S-ZORB.BS_LT_2401.PV', 14.8],\n",
       "       ['S-ZORB.PDT_1004.DACA', 14.6],\n",
       "       ['S-ZORB.FT_9102.PV', 14.6],\n",
       "       ['S-ZORB.FT_9201.PV', 14.4],\n",
       "       ['S-ZORB.TE_2004.DACA', 14.4],\n",
       "       ['S-ZORB.ZT_2634.DACA', 14.4],\n",
       "       ['S-ZORB.TE_5007.DACA', 13.8],\n",
       "       ['S-ZORB.TE_5201.DACA', 13.8],\n",
       "       ['S-ZORB.PDT_3503.DACA', 13.4],\n",
       "       ['S-ZORB.TE_2601.PV', 13.2],\n",
       "       ['S-ZORB.PT_7510B.DACA', 12.6],\n",
       "       ['S-ZORB.CAL.SPEED.PV', 12.2],\n",
       "       ['S-ZORB.AT-0010.DACA.PV', 12.0],\n",
       "       ['S-ZORB.LT_2101.DACA', 12.0],\n",
       "       ['S-ZORB.PDT_3601.DACA', 11.6],\n",
       "       ['S-ZORB.TXE_3201A.DACA', 11.0],\n",
       "       ['S-ZORB.FT_2303.DACA', 11.0],\n",
       "       ['S-ZORB.PT_9403.PV', 11.0],\n",
       "       ['S-ZORB.TE_6008.DACA', 11.0],\n",
       "       ['S-ZORB.TE_2902.DACA', 10.8],\n",
       "       ['S-ZORB.FC_2432.PIDA.SP', 10.8],\n",
       "       ['S-ZORB.TC_2201.OP', 10.8],\n",
       "       ['S-ZORB.PC_1603.PV', 10.6],\n",
       "       ['S-ZORB.TXE_2203A.DACA', 10.6],\n",
       "       ['Bromine', 10.6],\n",
       "       ['S-ZORB.PC_2401.DACA', 10.4],\n",
       "       ['S-ZORB.LC_5102.PIDA.PV', 10.2],\n",
       "       ['S-ZORB.PDC_2607.PV', 10.0],\n",
       "       ['S-ZORB.TE_2301.PV', 9.8],\n",
       "       ['S-ZORB.TE_2003.DACA', 9.2],\n",
       "       ['S-ZORB.PDI_2801.DACA', 9.0],\n",
       "       ['S-ZORB.PT_7505.DACA', 8.8],\n",
       "       ['S-ZORB.SIS_PDT_2103A.PV', 8.6],\n",
       "       ['S-ZORB.SIS_PT_6007.PV', 8.6],\n",
       "       ['S-ZORB.LC_5102.DACA', 8.6],\n",
       "       ['S-ZORB.LI_2104.DACA', 8.2],\n",
       "       ['S-ZORB.PT_7508B.DACA', 8.0],\n",
       "       ['S-ZORB.TE_1502.DACA', 8.0],\n",
       "       ['S-ZORB.FC_2432.DACA', 7.8],\n",
       "       ['S-ZORB.TE_1608.PV', 7.6],\n",
       "       ['S-ZORB.FT_5104.TOTAL', 7.6],\n",
       "       ['S-ZORB.PT_7508.DACA', 7.6],\n",
       "       ['S-ZORB.PT_7103.DACA', 7.4],\n",
       "       ['S-ZORB.TE_6001.DACA.PV', 7.2],\n",
       "       ['S-ZORB.TE_1104.DACA.PV', 6.8],\n",
       "       ['S-ZORB.PC_5101.PV', 6.6],\n",
       "       ['S-ZORB.FT_5102.DACA.PV', 6.6],\n",
       "       ['S-ZORB.PC_1301.PV', 6.6],\n",
       "       ['S-ZORB.TE_9003.DACA', 6.4],\n",
       "       ['S-ZORB.PT_2905.DACA', 6.2],\n",
       "       ['S-ZORB.PDI_2102.PV', 6.2],\n",
       "       ['S-ZORB.PC_9002.DACA', 6.0],\n",
       "       ['S-ZORB.TE_3101.DACA', 5.8],\n",
       "       ['S-ZORB.DT_2107.DACA', 5.6],\n",
       "       ['S-ZORB.FT_2002.DACA', 5.6],\n",
       "       ['S-ZORB.TE_1107.DACA.PV', 5.6],\n",
       "       ['S-ZORB.FC_1202.PV', 5.4],\n",
       "       ['S-ZORB.PDI_1102.PV', 5.4],\n",
       "       ['S-ZORB.PDI_2501.DACA', 5.2],\n",
       "       ['S-ZORB.TE_9001.PV', 5.2],\n",
       "       ['S-ZORB.PC_2401.PIDA.OP', 5.2],\n",
       "       ['S-ZORB.PDI_2301.DACA', 5.2],\n",
       "       ['S-ZORB.TE_7506B.DACA', 4.8],\n",
       "       ['S-ZORB.TE_7504B.DACA', 4.8],\n",
       "       ['S-ZORB.TE_7102.DACA', 4.4],\n",
       "       ['S-ZORB.TE_1504.DACA', 4.4],\n",
       "       ['S-ZORB.PDT_2703B.DACA', 4.2],\n",
       "       ['S-ZORB.PT_1101.DACA', 4.2],\n",
       "       ['S-ZORB.SIS_TE_6009.PV', 4.0],\n",
       "       ['S-ZORB.TE_6001.DACA', 4.0],\n",
       "       ['S-ZORB.PT_5201.DACA', 3.8],\n",
       "       ['S-ZORB.PC_3501.DACA', 3.8],\n",
       "       ['S-ZORB.PC_2401B.PIDA.SP', 3.6],\n",
       "       ['S-ZORB.PT_2106.DACA.PV', 3.4],\n",
       "       ['S-ZORB.TE_7508B.DACA', 3.4],\n",
       "       ['S-ZORB.PT_7503B.DACA', 3.2],\n",
       "       ['S-ZORB.TE_2104.DACA.PV', 3.2],\n",
       "       ['S-ZORB.CAL.CANGLIANG.PV', 3.2],\n",
       "       ['S-ZORB.FC_2301.PV', 3.2],\n",
       "       ['S-ZORB.TE_6008.DACA.PV', 2.8],\n",
       "       ['S-ZORB.TE_1103.DACA.PV', 2.8],\n",
       "       ['S-ZORB.FT_1503.TOTALIZERA.PV', 2.8],\n",
       "       ['S-ZORB.PT_7505B.DACA', 2.8],\n",
       "       ['S-ZORB.PC_2401B.DACA', 2.6],\n",
       "       ['S-ZORB.FT_5102.TOTAL', 2.6],\n",
       "       ['S-ZORB.HIC_2533.AUTOMANA.OP', 2.4],\n",
       "       ['S-ZORB.TE_1102.DACA', 2.4],\n",
       "       ['S-ZORB.SIS_PDT_2103B.PV', 2.2],\n",
       "       ['S-ZORB.TXE_2202A.DACA', 2.0],\n",
       "       ['S-ZORB.TE_1503.DACA', 2.0],\n",
       "       ['S-ZORB.TE_7502B.DACA', 1.6],\n",
       "       ['S-ZORB.FT_1504.TOTALIZERA.PV', 1.4],\n",
       "       ['S-ZORB.FT_3201.DACA', 1.4],\n",
       "       ['S-ZORB.PT_7107.DACA', 1.2],\n",
       "       ['S-ZORB.PC_2401.PIDA.SP', 1.2],\n",
       "       ['S-ZORB.FC_5203.DACA', 1.0],\n",
       "       ['S-ZORB.FT_9001.TOTAL', 1.0],\n",
       "       ['S-ZORB.FT_3302.DACA', 0.8],\n",
       "       ['S-ZORB.FT_3304.DACA', 0.6],\n",
       "       ['S-ZORB.TE_7106.DACA', 0.6],\n",
       "       ['S-ZORB.TE_1106.DACA.PV', 0.6],\n",
       "       ['S-ZORB.TC_2201.PV', 0.4],\n",
       "       ['S-ZORB.FT_5201.TOTAL', 0.4],\n",
       "       ['S-ZORB.FC_1202.TOTAL', 0.2],\n",
       "       ['S-ZORB.FC_3103.PV', 0.2],\n",
       "       ['S-ZORB.FT_5204.TOTALIZERA.PV', 0.2],\n",
       "       ['S-ZORB.PT_7510.DACA', 0.2],\n",
       "       ['S-ZORB.FT_1002.PV', 0.0],\n",
       "       ['S-ZORB.FT_1502.DACA', 0.0],\n",
       "       ['S-ZORB.FC_1104.DACA', 0.0],\n",
       "       ['S-ZORB.PC_3001.DACA', 0.0],\n",
       "       ['S-ZORB.FT_2803.DACA', 0.0],\n",
       "       ['S-ZORB.PT_7503.DACA', 0.0],\n",
       "       ['S-ZORB.FT_1006.TOTALIZERA.PV', 0.0],\n",
       "       ['S-ZORB.TE_7504.DACA', 0.0],\n",
       "       ['S-ZORB.TE_3111.DACA', 0.0],\n",
       "       ['S-ZORB.PT_7502.DACA', 0.0],\n",
       "       ['S-ZORB.FT_9201.TOTAL', 0.0],\n",
       "       ['S-ZORB.TEX_3103A.DACA', 0.0],\n",
       "       ['S-ZORB.FC_1101.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_9402.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_9401.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_9302.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_5102.PV', 0.0],\n",
       "       ['S-ZORB.FT_9301.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_9202.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_3301.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_1002.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_1003.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_1501.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_9101.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_5101.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_9102.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_1001.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_9403.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_1004.TOTAL', 0.0],\n",
       "       ['S-ZORB.FT_1501.PV', 0.0]], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.sort_values(by='importance',ascending=False).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.634143\tvalid_1's l2: 0.953833\n",
      "[50]\ttraining's l2: 0.425587\tvalid_1's l2: 0.70587\n",
      "[75]\ttraining's l2: 0.295418\tvalid_1's l2: 0.544858\n",
      "[100]\ttraining's l2: 0.212112\tvalid_1's l2: 0.433296\n",
      "[125]\ttraining's l2: 0.155098\tvalid_1's l2: 0.343604\n",
      "[150]\ttraining's l2: 0.12006\tvalid_1's l2: 0.288937\n",
      "[175]\ttraining's l2: 0.0970554\tvalid_1's l2: 0.254851\n",
      "[200]\ttraining's l2: 0.0808049\tvalid_1's l2: 0.225746\n",
      "[225]\ttraining's l2: 0.0690904\tvalid_1's l2: 0.201965\n",
      "[250]\ttraining's l2: 0.0604772\tvalid_1's l2: 0.180016\n",
      "[275]\ttraining's l2: 0.0549816\tvalid_1's l2: 0.168844\n",
      "[300]\ttraining's l2: 0.0504276\tvalid_1's l2: 0.160748\n",
      "[325]\ttraining's l2: 0.046484\tvalid_1's l2: 0.158205\n",
      "[350]\ttraining's l2: 0.0432415\tvalid_1's l2: 0.151281\n",
      "[375]\ttraining's l2: 0.0398983\tvalid_1's l2: 0.143997\n",
      "[400]\ttraining's l2: 0.0371471\tvalid_1's l2: 0.140179\n",
      "[425]\ttraining's l2: 0.0351035\tvalid_1's l2: 0.137066\n",
      "[450]\ttraining's l2: 0.0331765\tvalid_1's l2: 0.135891\n",
      "[475]\ttraining's l2: 0.0310216\tvalid_1's l2: 0.133178\n",
      "[500]\ttraining's l2: 0.0290677\tvalid_1's l2: 0.133698\n",
      "[525]\ttraining's l2: 0.0272457\tvalid_1's l2: 0.134445\n",
      "[550]\ttraining's l2: 0.0257393\tvalid_1's l2: 0.134018\n",
      "[575]\ttraining's l2: 0.0243277\tvalid_1's l2: 0.133811\n",
      "[600]\ttraining's l2: 0.0231026\tvalid_1's l2: 0.132163\n",
      "[625]\ttraining's l2: 0.0218794\tvalid_1's l2: 0.131009\n",
      "[650]\ttraining's l2: 0.020817\tvalid_1's l2: 0.130935\n",
      "[675]\ttraining's l2: 0.019716\tvalid_1's l2: 0.131179\n",
      "[700]\ttraining's l2: 0.0187584\tvalid_1's l2: 0.132569\n",
      "[725]\ttraining's l2: 0.0179764\tvalid_1's l2: 0.131428\n",
      "[750]\ttraining's l2: 0.0172575\tvalid_1's l2: 0.130376\n",
      "[775]\ttraining's l2: 0.016595\tvalid_1's l2: 0.129813\n",
      "[800]\ttraining's l2: 0.0158594\tvalid_1's l2: 0.129451\n",
      "[825]\ttraining's l2: 0.0149146\tvalid_1's l2: 0.129559\n",
      "[850]\ttraining's l2: 0.0143436\tvalid_1's l2: 0.130059\n",
      "[875]\ttraining's l2: 0.0137068\tvalid_1's l2: 0.129403\n",
      "[900]\ttraining's l2: 0.0130774\tvalid_1's l2: 0.127674\n",
      "[925]\ttraining's l2: 0.0124917\tvalid_1's l2: 0.12806\n",
      "[950]\ttraining's l2: 0.0118884\tvalid_1's l2: 0.127317\n",
      "[975]\ttraining's l2: 0.011395\tvalid_1's l2: 0.126943\n",
      "[1000]\ttraining's l2: 0.0109766\tvalid_1's l2: 0.126748\n",
      "[1025]\ttraining's l2: 0.0105918\tvalid_1's l2: 0.127572\n",
      "[1050]\ttraining's l2: 0.0102225\tvalid_1's l2: 0.12824\n",
      "[1075]\ttraining's l2: 0.00994051\tvalid_1's l2: 0.128635\n",
      "[1100]\ttraining's l2: 0.00961001\tvalid_1's l2: 0.129056\n",
      "[1125]\ttraining's l2: 0.00927535\tvalid_1's l2: 0.129204\n",
      "[1150]\ttraining's l2: 0.00896451\tvalid_1's l2: 0.128501\n",
      "[1175]\ttraining's l2: 0.00866441\tvalid_1's l2: 0.128312\n",
      "[1200]\ttraining's l2: 0.00834515\tvalid_1's l2: 0.128185\n",
      "[1225]\ttraining's l2: 0.00806095\tvalid_1's l2: 0.127638\n",
      "[1250]\ttraining's l2: 0.00776521\tvalid_1's l2: 0.127947\n",
      "[1275]\ttraining's l2: 0.00752041\tvalid_1's l2: 0.12846\n",
      "[1300]\ttraining's l2: 0.00725659\tvalid_1's l2: 0.12848\n",
      "[1325]\ttraining's l2: 0.00703548\tvalid_1's l2: 0.128381\n",
      "[1350]\ttraining's l2: 0.00684461\tvalid_1's l2: 0.128364\n",
      "[1375]\ttraining's l2: 0.00661048\tvalid_1's l2: 0.128718\n",
      "[1400]\ttraining's l2: 0.00643472\tvalid_1's l2: 0.128992\n",
      "[1425]\ttraining's l2: 0.00627644\tvalid_1's l2: 0.128139\n",
      "[1450]\ttraining's l2: 0.0059922\tvalid_1's l2: 0.127477\n",
      "[1475]\ttraining's l2: 0.00579006\tvalid_1's l2: 0.127029\n",
      "[1500]\ttraining's l2: 0.00556044\tvalid_1's l2: 0.126271\n",
      "[1525]\ttraining's l2: 0.00538012\tvalid_1's l2: 0.125941\n",
      "[1550]\ttraining's l2: 0.00522356\tvalid_1's l2: 0.125764\n",
      "[1575]\ttraining's l2: 0.00509726\tvalid_1's l2: 0.126489\n",
      "[1600]\ttraining's l2: 0.00499875\tvalid_1's l2: 0.126787\n",
      "[1625]\ttraining's l2: 0.00487378\tvalid_1's l2: 0.127154\n",
      "[1650]\ttraining's l2: 0.00475713\tvalid_1's l2: 0.127166\n",
      "[1675]\ttraining's l2: 0.0046527\tvalid_1's l2: 0.12706\n",
      "[1700]\ttraining's l2: 0.00456093\tvalid_1's l2: 0.126995\n",
      "[1725]\ttraining's l2: 0.00441238\tvalid_1's l2: 0.127536\n",
      "[1750]\ttraining's l2: 0.00429565\tvalid_1's l2: 0.127629\n",
      "[1775]\ttraining's l2: 0.0041786\tvalid_1's l2: 0.127404\n",
      "[1800]\ttraining's l2: 0.00409124\tvalid_1's l2: 0.12745\n",
      "[1825]\ttraining's l2: 0.00399992\tvalid_1's l2: 0.127365\n",
      "[1850]\ttraining's l2: 0.00392125\tvalid_1's l2: 0.12721\n",
      "[1875]\ttraining's l2: 0.00384463\tvalid_1's l2: 0.12689\n",
      "[1900]\ttraining's l2: 0.00375846\tvalid_1's l2: 0.126874\n",
      "[1925]\ttraining's l2: 0.00368414\tvalid_1's l2: 0.126812\n",
      "[1950]\ttraining's l2: 0.00360299\tvalid_1's l2: 0.126995\n",
      "[1975]\ttraining's l2: 0.0035178\tvalid_1's l2: 0.127056\n",
      "[2000]\ttraining's l2: 0.003448\tvalid_1's l2: 0.126924\n",
      "[2025]\ttraining's l2: 0.00338418\tvalid_1's l2: 0.12687\n",
      "[2050]\ttraining's l2: 0.00329195\tvalid_1's l2: 0.12702\n",
      "[2075]\ttraining's l2: 0.00320835\tvalid_1's l2: 0.126604\n",
      "[2100]\ttraining's l2: 0.00314849\tvalid_1's l2: 0.127032\n",
      "[2125]\ttraining's l2: 0.00309615\tvalid_1's l2: 0.127221\n",
      "[2150]\ttraining's l2: 0.00305218\tvalid_1's l2: 0.127462\n",
      "[2175]\ttraining's l2: 0.0030092\tvalid_1's l2: 0.127553\n",
      "[2200]\ttraining's l2: 0.00296321\tvalid_1's l2: 0.127488\n",
      "[2225]\ttraining's l2: 0.00291213\tvalid_1's l2: 0.127543\n",
      "[2250]\ttraining's l2: 0.00285923\tvalid_1's l2: 0.127416\n",
      "[2275]\ttraining's l2: 0.0028035\tvalid_1's l2: 0.127168\n",
      "[2300]\ttraining's l2: 0.00273537\tvalid_1's l2: 0.127081\n",
      "[2325]\ttraining's l2: 0.00268785\tvalid_1's l2: 0.126767\n",
      "[2350]\ttraining's l2: 0.00262223\tvalid_1's l2: 0.126726\n",
      "[2375]\ttraining's l2: 0.00258268\tvalid_1's l2: 0.12695\n",
      "[2400]\ttraining's l2: 0.00254652\tvalid_1's l2: 0.126773\n",
      "[2425]\ttraining's l2: 0.00250478\tvalid_1's l2: 0.126734\n",
      "[2450]\ttraining's l2: 0.00246161\tvalid_1's l2: 0.126892\n",
      "[2475]\ttraining's l2: 0.00241528\tvalid_1's l2: 0.126923\n",
      "[2500]\ttraining's l2: 0.00237431\tvalid_1's l2: 0.126899\n",
      "Early stopping, best iteration is:\n",
      "[1513]\ttraining's l2: 0.00548787\tvalid_1's l2: 0.125741\n",
      "fold 1\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.638722\tvalid_1's l2: 0.905722\n",
      "[50]\ttraining's l2: 0.428588\tvalid_1's l2: 0.597003\n",
      "[75]\ttraining's l2: 0.299995\tvalid_1's l2: 0.411222\n",
      "[100]\ttraining's l2: 0.220404\tvalid_1's l2: 0.295739\n",
      "[125]\ttraining's l2: 0.166659\tvalid_1's l2: 0.21562\n",
      "[150]\ttraining's l2: 0.132333\tvalid_1's l2: 0.165971\n",
      "[175]\ttraining's l2: 0.107448\tvalid_1's l2: 0.128234\n",
      "[200]\ttraining's l2: 0.0903734\tvalid_1's l2: 0.103674\n",
      "[225]\ttraining's l2: 0.0778254\tvalid_1's l2: 0.0864994\n",
      "[250]\ttraining's l2: 0.068978\tvalid_1's l2: 0.0758586\n",
      "[275]\ttraining's l2: 0.0628226\tvalid_1's l2: 0.0691609\n",
      "[300]\ttraining's l2: 0.0576347\tvalid_1's l2: 0.0644025\n",
      "[325]\ttraining's l2: 0.0534085\tvalid_1's l2: 0.062088\n",
      "[350]\ttraining's l2: 0.0500392\tvalid_1's l2: 0.0594983\n",
      "[375]\ttraining's l2: 0.0470808\tvalid_1's l2: 0.0585722\n",
      "[400]\ttraining's l2: 0.0440521\tvalid_1's l2: 0.0569526\n",
      "[425]\ttraining's l2: 0.041557\tvalid_1's l2: 0.056195\n",
      "[450]\ttraining's l2: 0.0396221\tvalid_1's l2: 0.0552978\n",
      "[475]\ttraining's l2: 0.0369707\tvalid_1's l2: 0.0555834\n",
      "[500]\ttraining's l2: 0.0348716\tvalid_1's l2: 0.0555139\n",
      "[525]\ttraining's l2: 0.033018\tvalid_1's l2: 0.0550832\n",
      "[550]\ttraining's l2: 0.0313067\tvalid_1's l2: 0.0551556\n",
      "[575]\ttraining's l2: 0.0295296\tvalid_1's l2: 0.0551006\n",
      "[600]\ttraining's l2: 0.0282744\tvalid_1's l2: 0.055531\n",
      "[625]\ttraining's l2: 0.0266068\tvalid_1's l2: 0.0555058\n",
      "[650]\ttraining's l2: 0.0254706\tvalid_1's l2: 0.0552832\n",
      "[675]\ttraining's l2: 0.0244113\tvalid_1's l2: 0.0548181\n",
      "[700]\ttraining's l2: 0.0233621\tvalid_1's l2: 0.0545809\n",
      "[725]\ttraining's l2: 0.0225724\tvalid_1's l2: 0.0548791\n",
      "[750]\ttraining's l2: 0.0214943\tvalid_1's l2: 0.0550598\n",
      "[775]\ttraining's l2: 0.0205234\tvalid_1's l2: 0.0545488\n",
      "[800]\ttraining's l2: 0.0195243\tvalid_1's l2: 0.0543237\n",
      "[825]\ttraining's l2: 0.0182252\tvalid_1's l2: 0.0558191\n",
      "[850]\ttraining's l2: 0.0172825\tvalid_1's l2: 0.055763\n",
      "[875]\ttraining's l2: 0.0165173\tvalid_1's l2: 0.0555517\n",
      "[900]\ttraining's l2: 0.0158307\tvalid_1's l2: 0.0561907\n",
      "[925]\ttraining's l2: 0.0150546\tvalid_1's l2: 0.0564211\n",
      "[950]\ttraining's l2: 0.0143953\tvalid_1's l2: 0.0563182\n",
      "[975]\ttraining's l2: 0.0137159\tvalid_1's l2: 0.0568861\n",
      "[1000]\ttraining's l2: 0.0132143\tvalid_1's l2: 0.0573697\n",
      "[1025]\ttraining's l2: 0.012587\tvalid_1's l2: 0.0576179\n",
      "[1050]\ttraining's l2: 0.0119674\tvalid_1's l2: 0.0568108\n",
      "[1075]\ttraining's l2: 0.0115003\tvalid_1's l2: 0.0564877\n",
      "[1100]\ttraining's l2: 0.0110305\tvalid_1's l2: 0.0561595\n",
      "[1125]\ttraining's l2: 0.0105768\tvalid_1's l2: 0.0557443\n",
      "[1150]\ttraining's l2: 0.0101413\tvalid_1's l2: 0.0562307\n",
      "[1175]\ttraining's l2: 0.00979579\tvalid_1's l2: 0.0558208\n",
      "[1200]\ttraining's l2: 0.00940135\tvalid_1's l2: 0.0563567\n",
      "[1225]\ttraining's l2: 0.00896545\tvalid_1's l2: 0.057036\n",
      "[1250]\ttraining's l2: 0.00860744\tvalid_1's l2: 0.0568432\n",
      "[1275]\ttraining's l2: 0.00827646\tvalid_1's l2: 0.056459\n",
      "[1300]\ttraining's l2: 0.00799992\tvalid_1's l2: 0.0562291\n",
      "[1325]\ttraining's l2: 0.00772134\tvalid_1's l2: 0.0560423\n",
      "[1350]\ttraining's l2: 0.00741876\tvalid_1's l2: 0.056214\n",
      "[1375]\ttraining's l2: 0.00715047\tvalid_1's l2: 0.0566914\n",
      "[1400]\ttraining's l2: 0.00687331\tvalid_1's l2: 0.0570082\n",
      "[1425]\ttraining's l2: 0.00667106\tvalid_1's l2: 0.0571226\n",
      "[1450]\ttraining's l2: 0.00643603\tvalid_1's l2: 0.0563458\n",
      "[1475]\ttraining's l2: 0.00623429\tvalid_1's l2: 0.0564972\n",
      "[1500]\ttraining's l2: 0.00606988\tvalid_1's l2: 0.0562342\n",
      "[1525]\ttraining's l2: 0.00586583\tvalid_1's l2: 0.0555256\n",
      "[1550]\ttraining's l2: 0.00569959\tvalid_1's l2: 0.0558538\n",
      "[1575]\ttraining's l2: 0.00552164\tvalid_1's l2: 0.0559507\n",
      "[1600]\ttraining's l2: 0.00532733\tvalid_1's l2: 0.0560426\n",
      "[1625]\ttraining's l2: 0.00519492\tvalid_1's l2: 0.0560093\n",
      "[1650]\ttraining's l2: 0.00498589\tvalid_1's l2: 0.0560385\n",
      "[1675]\ttraining's l2: 0.00476256\tvalid_1's l2: 0.0564754\n",
      "[1700]\ttraining's l2: 0.00458079\tvalid_1's l2: 0.0567854\n",
      "[1725]\ttraining's l2: 0.00445734\tvalid_1's l2: 0.0569477\n",
      "[1750]\ttraining's l2: 0.00432208\tvalid_1's l2: 0.0569546\n",
      "[1775]\ttraining's l2: 0.0041575\tvalid_1's l2: 0.0571402\n",
      "[1800]\ttraining's l2: 0.00404728\tvalid_1's l2: 0.0572968\n",
      "Early stopping, best iteration is:\n",
      "[800]\ttraining's l2: 0.0195243\tvalid_1's l2: 0.0543237\n",
      "fold 2\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.658089\tvalid_1's l2: 0.623649\n",
      "[50]\ttraining's l2: 0.440535\tvalid_1's l2: 0.422198\n",
      "[75]\ttraining's l2: 0.30353\tvalid_1's l2: 0.294598\n",
      "[100]\ttraining's l2: 0.218932\tvalid_1's l2: 0.216554\n",
      "[125]\ttraining's l2: 0.163524\tvalid_1's l2: 0.172703\n",
      "[150]\ttraining's l2: 0.127019\tvalid_1's l2: 0.142436\n",
      "[175]\ttraining's l2: 0.102369\tvalid_1's l2: 0.121759\n",
      "[200]\ttraining's l2: 0.0843794\tvalid_1's l2: 0.105714\n",
      "[225]\ttraining's l2: 0.0727051\tvalid_1's l2: 0.0954737\n",
      "[250]\ttraining's l2: 0.0642619\tvalid_1's l2: 0.0907613\n",
      "[275]\ttraining's l2: 0.0575535\tvalid_1's l2: 0.0861914\n",
      "[300]\ttraining's l2: 0.0530334\tvalid_1's l2: 0.083035\n",
      "[325]\ttraining's l2: 0.0489645\tvalid_1's l2: 0.0799822\n",
      "[350]\ttraining's l2: 0.0457093\tvalid_1's l2: 0.0776955\n",
      "[375]\ttraining's l2: 0.0429012\tvalid_1's l2: 0.0756843\n",
      "[400]\ttraining's l2: 0.0403547\tvalid_1's l2: 0.0734494\n",
      "[425]\ttraining's l2: 0.0380334\tvalid_1's l2: 0.0729669\n",
      "[450]\ttraining's l2: 0.0358398\tvalid_1's l2: 0.0727236\n",
      "[475]\ttraining's l2: 0.0336661\tvalid_1's l2: 0.0718273\n",
      "[500]\ttraining's l2: 0.0314573\tvalid_1's l2: 0.0715532\n",
      "[525]\ttraining's l2: 0.0296888\tvalid_1's l2: 0.0711825\n",
      "[550]\ttraining's l2: 0.0280172\tvalid_1's l2: 0.0711211\n",
      "[575]\ttraining's l2: 0.0265268\tvalid_1's l2: 0.0705476\n",
      "[600]\ttraining's l2: 0.0253748\tvalid_1's l2: 0.070138\n",
      "[625]\ttraining's l2: 0.0242089\tvalid_1's l2: 0.0704502\n",
      "[650]\ttraining's l2: 0.0232305\tvalid_1's l2: 0.0699813\n",
      "[675]\ttraining's l2: 0.0220861\tvalid_1's l2: 0.0702327\n",
      "[700]\ttraining's l2: 0.020891\tvalid_1's l2: 0.069677\n",
      "[725]\ttraining's l2: 0.0197344\tvalid_1's l2: 0.0704189\n",
      "[750]\ttraining's l2: 0.0190624\tvalid_1's l2: 0.0705213\n",
      "[775]\ttraining's l2: 0.0180837\tvalid_1's l2: 0.0705322\n",
      "[800]\ttraining's l2: 0.0172169\tvalid_1's l2: 0.0707584\n",
      "[825]\ttraining's l2: 0.0165312\tvalid_1's l2: 0.0709208\n",
      "[850]\ttraining's l2: 0.0159145\tvalid_1's l2: 0.0702215\n",
      "[875]\ttraining's l2: 0.0152825\tvalid_1's l2: 0.0703882\n",
      "[900]\ttraining's l2: 0.0147705\tvalid_1's l2: 0.0709404\n",
      "[925]\ttraining's l2: 0.0141675\tvalid_1's l2: 0.0704197\n",
      "[950]\ttraining's l2: 0.0135557\tvalid_1's l2: 0.0702123\n",
      "[975]\ttraining's l2: 0.0130899\tvalid_1's l2: 0.0702728\n",
      "[1000]\ttraining's l2: 0.0125867\tvalid_1's l2: 0.0695346\n",
      "[1025]\ttraining's l2: 0.0120324\tvalid_1's l2: 0.0703347\n",
      "[1050]\ttraining's l2: 0.0116404\tvalid_1's l2: 0.0701151\n",
      "[1075]\ttraining's l2: 0.0111741\tvalid_1's l2: 0.0704906\n",
      "[1100]\ttraining's l2: 0.0106906\tvalid_1's l2: 0.0702235\n",
      "[1125]\ttraining's l2: 0.01028\tvalid_1's l2: 0.0707841\n",
      "[1150]\ttraining's l2: 0.00996007\tvalid_1's l2: 0.070941\n",
      "[1175]\ttraining's l2: 0.00963932\tvalid_1's l2: 0.0708388\n",
      "[1200]\ttraining's l2: 0.00926928\tvalid_1's l2: 0.0710317\n",
      "[1225]\ttraining's l2: 0.00892787\tvalid_1's l2: 0.0710864\n",
      "[1250]\ttraining's l2: 0.00863714\tvalid_1's l2: 0.0710677\n",
      "[1275]\ttraining's l2: 0.00832201\tvalid_1's l2: 0.0711497\n",
      "[1300]\ttraining's l2: 0.00800357\tvalid_1's l2: 0.0715644\n",
      "[1325]\ttraining's l2: 0.00763197\tvalid_1's l2: 0.0718123\n",
      "[1350]\ttraining's l2: 0.00742047\tvalid_1's l2: 0.0719052\n",
      "[1375]\ttraining's l2: 0.00716811\tvalid_1's l2: 0.0718361\n",
      "[1400]\ttraining's l2: 0.00689541\tvalid_1's l2: 0.0722862\n",
      "[1425]\ttraining's l2: 0.00662704\tvalid_1's l2: 0.072214\n",
      "[1450]\ttraining's l2: 0.00646281\tvalid_1's l2: 0.0722587\n",
      "[1475]\ttraining's l2: 0.00626602\tvalid_1's l2: 0.0721738\n",
      "[1500]\ttraining's l2: 0.00608763\tvalid_1's l2: 0.0722238\n",
      "[1525]\ttraining's l2: 0.00589597\tvalid_1's l2: 0.0723145\n",
      "[1550]\ttraining's l2: 0.00573542\tvalid_1's l2: 0.072458\n",
      "[1575]\ttraining's l2: 0.00557221\tvalid_1's l2: 0.0725826\n",
      "[1600]\ttraining's l2: 0.00531778\tvalid_1's l2: 0.0730197\n",
      "[1625]\ttraining's l2: 0.00516738\tvalid_1's l2: 0.0733936\n",
      "[1650]\ttraining's l2: 0.00504262\tvalid_1's l2: 0.0734438\n",
      "[1675]\ttraining's l2: 0.00491192\tvalid_1's l2: 0.0737153\n",
      "[1700]\ttraining's l2: 0.00471741\tvalid_1's l2: 0.0739775\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's l2: 0.020713\tvalid_1's l2: 0.0694853\n",
      "fold 3\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.629787\tvalid_1's l2: 0.84932\n",
      "[50]\ttraining's l2: 0.421504\tvalid_1's l2: 0.539336\n",
      "[75]\ttraining's l2: 0.294845\tvalid_1's l2: 0.360326\n",
      "[100]\ttraining's l2: 0.216949\tvalid_1's l2: 0.257416\n",
      "[125]\ttraining's l2: 0.162526\tvalid_1's l2: 0.194925\n",
      "[150]\ttraining's l2: 0.125663\tvalid_1's l2: 0.159494\n",
      "[175]\ttraining's l2: 0.101727\tvalid_1's l2: 0.141385\n",
      "[200]\ttraining's l2: 0.084735\tvalid_1's l2: 0.132466\n",
      "[225]\ttraining's l2: 0.0732413\tvalid_1's l2: 0.131857\n",
      "[250]\ttraining's l2: 0.0641713\tvalid_1's l2: 0.131496\n",
      "[275]\ttraining's l2: 0.0576767\tvalid_1's l2: 0.131498\n",
      "[300]\ttraining's l2: 0.052903\tvalid_1's l2: 0.133756\n",
      "[325]\ttraining's l2: 0.0485687\tvalid_1's l2: 0.137524\n",
      "[350]\ttraining's l2: 0.0454626\tvalid_1's l2: 0.140231\n",
      "[375]\ttraining's l2: 0.0425327\tvalid_1's l2: 0.145215\n",
      "[400]\ttraining's l2: 0.0398434\tvalid_1's l2: 0.146869\n",
      "[425]\ttraining's l2: 0.0369703\tvalid_1's l2: 0.149607\n",
      "[450]\ttraining's l2: 0.0345941\tvalid_1's l2: 0.153909\n",
      "[475]\ttraining's l2: 0.0326032\tvalid_1's l2: 0.158586\n",
      "[500]\ttraining's l2: 0.030812\tvalid_1's l2: 0.159555\n",
      "[525]\ttraining's l2: 0.0291324\tvalid_1's l2: 0.158047\n",
      "[550]\ttraining's l2: 0.0274979\tvalid_1's l2: 0.160128\n",
      "[575]\ttraining's l2: 0.0261564\tvalid_1's l2: 0.157223\n",
      "[600]\ttraining's l2: 0.0249344\tvalid_1's l2: 0.158526\n",
      "[625]\ttraining's l2: 0.0233752\tvalid_1's l2: 0.162827\n",
      "[650]\ttraining's l2: 0.0221669\tvalid_1's l2: 0.161631\n",
      "[675]\ttraining's l2: 0.0211218\tvalid_1's l2: 0.162573\n",
      "[700]\ttraining's l2: 0.0200324\tvalid_1's l2: 0.165602\n",
      "[725]\ttraining's l2: 0.0191304\tvalid_1's l2: 0.168481\n",
      "[750]\ttraining's l2: 0.0182904\tvalid_1's l2: 0.172452\n",
      "[775]\ttraining's l2: 0.0174427\tvalid_1's l2: 0.174344\n",
      "[800]\ttraining's l2: 0.0166984\tvalid_1's l2: 0.172308\n",
      "[825]\ttraining's l2: 0.0159466\tvalid_1's l2: 0.173559\n",
      "[850]\ttraining's l2: 0.0150506\tvalid_1's l2: 0.174332\n",
      "[875]\ttraining's l2: 0.0143657\tvalid_1's l2: 0.174988\n",
      "[900]\ttraining's l2: 0.0137973\tvalid_1's l2: 0.176541\n",
      "[925]\ttraining's l2: 0.0132063\tvalid_1's l2: 0.176978\n",
      "[950]\ttraining's l2: 0.0126326\tvalid_1's l2: 0.176004\n",
      "[975]\ttraining's l2: 0.0121568\tvalid_1's l2: 0.177098\n",
      "[1000]\ttraining's l2: 0.0114776\tvalid_1's l2: 0.178046\n",
      "[1025]\ttraining's l2: 0.0110189\tvalid_1's l2: 0.179524\n",
      "[1050]\ttraining's l2: 0.0105181\tvalid_1's l2: 0.180041\n",
      "[1075]\ttraining's l2: 0.0100005\tvalid_1's l2: 0.181377\n",
      "[1100]\ttraining's l2: 0.0096273\tvalid_1's l2: 0.18113\n",
      "[1125]\ttraining's l2: 0.00918245\tvalid_1's l2: 0.182328\n",
      "[1150]\ttraining's l2: 0.00880737\tvalid_1's l2: 0.18288\n",
      "[1175]\ttraining's l2: 0.00854416\tvalid_1's l2: 0.183065\n",
      "[1200]\ttraining's l2: 0.00821148\tvalid_1's l2: 0.185067\n",
      "[1225]\ttraining's l2: 0.00796964\tvalid_1's l2: 0.185843\n",
      "Early stopping, best iteration is:\n",
      "[240]\ttraining's l2: 0.0676099\tvalid_1's l2: 0.130791\n",
      "fold 4\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.61508\tvalid_1's l2: 1.13598\n",
      "[50]\ttraining's l2: 0.413341\tvalid_1's l2: 0.812942\n",
      "[75]\ttraining's l2: 0.287134\tvalid_1's l2: 0.601328\n",
      "[100]\ttraining's l2: 0.212252\tvalid_1's l2: 0.476802\n",
      "[125]\ttraining's l2: 0.15513\tvalid_1's l2: 0.373116\n",
      "[150]\ttraining's l2: 0.121996\tvalid_1's l2: 0.320381\n",
      "[175]\ttraining's l2: 0.0992214\tvalid_1's l2: 0.280003\n",
      "[200]\ttraining's l2: 0.0818601\tvalid_1's l2: 0.249895\n",
      "[225]\ttraining's l2: 0.0696723\tvalid_1's l2: 0.22596\n",
      "[250]\ttraining's l2: 0.0608681\tvalid_1's l2: 0.212179\n",
      "[275]\ttraining's l2: 0.0543156\tvalid_1's l2: 0.200831\n",
      "[300]\ttraining's l2: 0.0496134\tvalid_1's l2: 0.191915\n",
      "[325]\ttraining's l2: 0.0459318\tvalid_1's l2: 0.187673\n",
      "[350]\ttraining's l2: 0.043214\tvalid_1's l2: 0.18826\n",
      "[375]\ttraining's l2: 0.0401247\tvalid_1's l2: 0.183906\n",
      "[400]\ttraining's l2: 0.0375772\tvalid_1's l2: 0.181542\n",
      "[425]\ttraining's l2: 0.0354405\tvalid_1's l2: 0.178322\n",
      "[450]\ttraining's l2: 0.0333565\tvalid_1's l2: 0.178441\n",
      "[475]\ttraining's l2: 0.0315365\tvalid_1's l2: 0.17769\n",
      "[500]\ttraining's l2: 0.0298057\tvalid_1's l2: 0.178412\n",
      "[525]\ttraining's l2: 0.0283933\tvalid_1's l2: 0.177738\n",
      "[550]\ttraining's l2: 0.0268925\tvalid_1's l2: 0.177661\n",
      "[575]\ttraining's l2: 0.0254793\tvalid_1's l2: 0.17507\n",
      "[600]\ttraining's l2: 0.0243359\tvalid_1's l2: 0.174356\n",
      "[625]\ttraining's l2: 0.0230387\tvalid_1's l2: 0.175907\n",
      "[650]\ttraining's l2: 0.021744\tvalid_1's l2: 0.176076\n",
      "[675]\ttraining's l2: 0.0207643\tvalid_1's l2: 0.175143\n",
      "[700]\ttraining's l2: 0.0197654\tvalid_1's l2: 0.174915\n",
      "[725]\ttraining's l2: 0.0189764\tvalid_1's l2: 0.176009\n",
      "[750]\ttraining's l2: 0.0180129\tvalid_1's l2: 0.17638\n",
      "[775]\ttraining's l2: 0.0171125\tvalid_1's l2: 0.178229\n",
      "[800]\ttraining's l2: 0.0163769\tvalid_1's l2: 0.178485\n",
      "[825]\ttraining's l2: 0.0155852\tvalid_1's l2: 0.177501\n",
      "[850]\ttraining's l2: 0.0147909\tvalid_1's l2: 0.177981\n",
      "[875]\ttraining's l2: 0.0142902\tvalid_1's l2: 0.177958\n",
      "[900]\ttraining's l2: 0.0136836\tvalid_1's l2: 0.177628\n",
      "[925]\ttraining's l2: 0.013066\tvalid_1's l2: 0.176791\n",
      "[950]\ttraining's l2: 0.0125449\tvalid_1's l2: 0.178177\n",
      "[975]\ttraining's l2: 0.0118787\tvalid_1's l2: 0.179322\n",
      "[1000]\ttraining's l2: 0.0113625\tvalid_1's l2: 0.180028\n",
      "[1025]\ttraining's l2: 0.0109053\tvalid_1's l2: 0.179744\n",
      "[1050]\ttraining's l2: 0.0105566\tvalid_1's l2: 0.178366\n",
      "[1075]\ttraining's l2: 0.0101059\tvalid_1's l2: 0.178998\n",
      "[1100]\ttraining's l2: 0.00970441\tvalid_1's l2: 0.178588\n",
      "[1125]\ttraining's l2: 0.00935856\tvalid_1's l2: 0.178591\n",
      "[1150]\ttraining's l2: 0.00903352\tvalid_1's l2: 0.17853\n",
      "[1175]\ttraining's l2: 0.00875289\tvalid_1's l2: 0.177408\n",
      "[1200]\ttraining's l2: 0.00840916\tvalid_1's l2: 0.177737\n",
      "[1225]\ttraining's l2: 0.00808928\tvalid_1's l2: 0.178136\n",
      "[1250]\ttraining's l2: 0.00782529\tvalid_1's l2: 0.178254\n",
      "[1275]\ttraining's l2: 0.00752441\tvalid_1's l2: 0.177836\n",
      "[1300]\ttraining's l2: 0.00725433\tvalid_1's l2: 0.177658\n",
      "[1325]\ttraining's l2: 0.00704025\tvalid_1's l2: 0.177735\n",
      "[1350]\ttraining's l2: 0.00677909\tvalid_1's l2: 0.178372\n",
      "[1375]\ttraining's l2: 0.00651107\tvalid_1's l2: 0.178289\n",
      "[1400]\ttraining's l2: 0.00624019\tvalid_1's l2: 0.17914\n",
      "[1425]\ttraining's l2: 0.00603891\tvalid_1's l2: 0.179496\n",
      "[1450]\ttraining's l2: 0.00584529\tvalid_1's l2: 0.179746\n",
      "[1475]\ttraining's l2: 0.0056405\tvalid_1's l2: 0.180196\n",
      "[1500]\ttraining's l2: 0.00546445\tvalid_1's l2: 0.180448\n",
      "[1525]\ttraining's l2: 0.00527232\tvalid_1's l2: 0.180369\n",
      "[1550]\ttraining's l2: 0.00511724\tvalid_1's l2: 0.180499\n",
      "[1575]\ttraining's l2: 0.00497116\tvalid_1's l2: 0.180548\n",
      "Early stopping, best iteration is:\n",
      "[593]\ttraining's l2: 0.0247399\tvalid_1's l2: 0.174072\n",
      "fold 5\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670918\tvalid_1's l2: 0.546546\n",
      "[50]\ttraining's l2: 0.445738\tvalid_1's l2: 0.379901\n",
      "[75]\ttraining's l2: 0.310601\tvalid_1's l2: 0.279455\n",
      "[100]\ttraining's l2: 0.224741\tvalid_1's l2: 0.224535\n",
      "[125]\ttraining's l2: 0.16541\tvalid_1's l2: 0.179645\n",
      "[150]\ttraining's l2: 0.128788\tvalid_1's l2: 0.153375\n",
      "[175]\ttraining's l2: 0.103692\tvalid_1's l2: 0.136137\n",
      "[200]\ttraining's l2: 0.0856111\tvalid_1's l2: 0.12447\n",
      "[225]\ttraining's l2: 0.0727324\tvalid_1's l2: 0.117169\n",
      "[250]\ttraining's l2: 0.0635957\tvalid_1's l2: 0.110695\n",
      "[275]\ttraining's l2: 0.057688\tvalid_1's l2: 0.105321\n",
      "[300]\ttraining's l2: 0.0530239\tvalid_1's l2: 0.101436\n",
      "[325]\ttraining's l2: 0.0488639\tvalid_1's l2: 0.0991343\n",
      "[350]\ttraining's l2: 0.0452647\tvalid_1's l2: 0.0967823\n",
      "[375]\ttraining's l2: 0.0422868\tvalid_1's l2: 0.0946595\n",
      "[400]\ttraining's l2: 0.0397837\tvalid_1's l2: 0.0926184\n",
      "[425]\ttraining's l2: 0.0371437\tvalid_1's l2: 0.0930058\n",
      "[450]\ttraining's l2: 0.0351998\tvalid_1's l2: 0.0913991\n",
      "[475]\ttraining's l2: 0.033164\tvalid_1's l2: 0.0893813\n",
      "[500]\ttraining's l2: 0.031432\tvalid_1's l2: 0.0890126\n",
      "[525]\ttraining's l2: 0.0296321\tvalid_1's l2: 0.0879968\n",
      "[550]\ttraining's l2: 0.0280947\tvalid_1's l2: 0.0874145\n",
      "[575]\ttraining's l2: 0.0264133\tvalid_1's l2: 0.0862925\n",
      "[600]\ttraining's l2: 0.0249077\tvalid_1's l2: 0.0851597\n",
      "[625]\ttraining's l2: 0.023697\tvalid_1's l2: 0.0842573\n",
      "[650]\ttraining's l2: 0.0226506\tvalid_1's l2: 0.0842956\n",
      "[675]\ttraining's l2: 0.0216328\tvalid_1's l2: 0.0837028\n",
      "[700]\ttraining's l2: 0.0206984\tvalid_1's l2: 0.0838077\n",
      "[725]\ttraining's l2: 0.0197486\tvalid_1's l2: 0.0839666\n",
      "[750]\ttraining's l2: 0.0186675\tvalid_1's l2: 0.0838258\n",
      "[775]\ttraining's l2: 0.0178918\tvalid_1's l2: 0.0832469\n",
      "[800]\ttraining's l2: 0.0170958\tvalid_1's l2: 0.0834695\n",
      "[825]\ttraining's l2: 0.0163523\tvalid_1's l2: 0.0825706\n",
      "[850]\ttraining's l2: 0.0156419\tvalid_1's l2: 0.0830493\n",
      "[875]\ttraining's l2: 0.015082\tvalid_1's l2: 0.0823386\n",
      "[900]\ttraining's l2: 0.0144934\tvalid_1's l2: 0.0820081\n",
      "[925]\ttraining's l2: 0.0138839\tvalid_1's l2: 0.0819566\n",
      "[950]\ttraining's l2: 0.0132285\tvalid_1's l2: 0.0808274\n",
      "[975]\ttraining's l2: 0.012665\tvalid_1's l2: 0.0802885\n",
      "[1000]\ttraining's l2: 0.0122828\tvalid_1's l2: 0.0804345\n",
      "[1025]\ttraining's l2: 0.0117311\tvalid_1's l2: 0.0798715\n",
      "[1050]\ttraining's l2: 0.0112725\tvalid_1's l2: 0.0801745\n",
      "[1075]\ttraining's l2: 0.0107792\tvalid_1's l2: 0.0802561\n",
      "[1100]\ttraining's l2: 0.0103444\tvalid_1's l2: 0.080323\n",
      "[1125]\ttraining's l2: 0.00992346\tvalid_1's l2: 0.0806176\n",
      "[1150]\ttraining's l2: 0.00964684\tvalid_1's l2: 0.0804004\n",
      "[1175]\ttraining's l2: 0.00933325\tvalid_1's l2: 0.0800447\n",
      "[1200]\ttraining's l2: 0.00901847\tvalid_1's l2: 0.0800451\n",
      "[1225]\ttraining's l2: 0.00872724\tvalid_1's l2: 0.0798427\n",
      "[1250]\ttraining's l2: 0.00847809\tvalid_1's l2: 0.0800027\n",
      "[1275]\ttraining's l2: 0.00823463\tvalid_1's l2: 0.0796933\n",
      "[1300]\ttraining's l2: 0.00785617\tvalid_1's l2: 0.0796795\n",
      "[1325]\ttraining's l2: 0.00754049\tvalid_1's l2: 0.0794535\n",
      "[1350]\ttraining's l2: 0.00732381\tvalid_1's l2: 0.0793588\n",
      "[1375]\ttraining's l2: 0.00710769\tvalid_1's l2: 0.0794911\n",
      "[1400]\ttraining's l2: 0.00691675\tvalid_1's l2: 0.0794424\n",
      "[1425]\ttraining's l2: 0.00665416\tvalid_1's l2: 0.0794718\n",
      "[1450]\ttraining's l2: 0.0064412\tvalid_1's l2: 0.079748\n",
      "[1475]\ttraining's l2: 0.0061563\tvalid_1's l2: 0.0801128\n",
      "[1500]\ttraining's l2: 0.00592927\tvalid_1's l2: 0.0803754\n",
      "[1525]\ttraining's l2: 0.00574271\tvalid_1's l2: 0.0806182\n",
      "[1550]\ttraining's l2: 0.00556908\tvalid_1's l2: 0.0809439\n",
      "[1575]\ttraining's l2: 0.00540361\tvalid_1's l2: 0.0813671\n",
      "[1600]\ttraining's l2: 0.0052265\tvalid_1's l2: 0.0812953\n",
      "[1625]\ttraining's l2: 0.00509862\tvalid_1's l2: 0.0810372\n",
      "[1650]\ttraining's l2: 0.00494064\tvalid_1's l2: 0.0810763\n",
      "[1675]\ttraining's l2: 0.00480431\tvalid_1's l2: 0.0807788\n",
      "[1700]\ttraining's l2: 0.00463305\tvalid_1's l2: 0.0808804\n",
      "[1725]\ttraining's l2: 0.00449036\tvalid_1's l2: 0.080812\n",
      "[1750]\ttraining's l2: 0.00431811\tvalid_1's l2: 0.0808487\n",
      "[1775]\ttraining's l2: 0.0041774\tvalid_1's l2: 0.0810475\n",
      "[1800]\ttraining's l2: 0.00406921\tvalid_1's l2: 0.0810583\n",
      "[1825]\ttraining's l2: 0.00396237\tvalid_1's l2: 0.0812746\n",
      "[1850]\ttraining's l2: 0.00386226\tvalid_1's l2: 0.0810956\n",
      "[1875]\ttraining's l2: 0.00375329\tvalid_1's l2: 0.0808659\n",
      "[1900]\ttraining's l2: 0.00362173\tvalid_1's l2: 0.080892\n",
      "[1925]\ttraining's l2: 0.0035108\tvalid_1's l2: 0.0806939\n",
      "[1950]\ttraining's l2: 0.0034383\tvalid_1's l2: 0.0808983\n",
      "[1975]\ttraining's l2: 0.00332656\tvalid_1's l2: 0.0811596\n",
      "[2000]\ttraining's l2: 0.00323548\tvalid_1's l2: 0.0809989\n",
      "[2025]\ttraining's l2: 0.00316966\tvalid_1's l2: 0.0806437\n",
      "[2050]\ttraining's l2: 0.00309236\tvalid_1's l2: 0.0804939\n",
      "[2075]\ttraining's l2: 0.00300352\tvalid_1's l2: 0.0805925\n",
      "[2100]\ttraining's l2: 0.00292472\tvalid_1's l2: 0.0809167\n",
      "[2125]\ttraining's l2: 0.00286165\tvalid_1's l2: 0.080962\n",
      "[2150]\ttraining's l2: 0.00280095\tvalid_1's l2: 0.080891\n",
      "[2175]\ttraining's l2: 0.00273822\tvalid_1's l2: 0.0806837\n",
      "[2200]\ttraining's l2: 0.00266645\tvalid_1's l2: 0.0807613\n",
      "[2225]\ttraining's l2: 0.00258991\tvalid_1's l2: 0.0807847\n",
      "[2250]\ttraining's l2: 0.00251158\tvalid_1's l2: 0.0807904\n",
      "[2275]\ttraining's l2: 0.00246488\tvalid_1's l2: 0.0806315\n",
      "[2300]\ttraining's l2: 0.00241149\tvalid_1's l2: 0.0806302\n",
      "[2325]\ttraining's l2: 0.00236895\tvalid_1's l2: 0.0805606\n",
      "[2350]\ttraining's l2: 0.00231686\tvalid_1's l2: 0.080646\n",
      "[2375]\ttraining's l2: 0.00225463\tvalid_1's l2: 0.0806601\n",
      "[2400]\ttraining's l2: 0.00220114\tvalid_1's l2: 0.0806621\n",
      "Early stopping, best iteration is:\n",
      "[1408]\ttraining's l2: 0.00678857\tvalid_1's l2: 0.0793013\n",
      "fold 6\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.675692\tvalid_1's l2: 0.47592\n",
      "[50]\ttraining's l2: 0.449631\tvalid_1's l2: 0.301025\n",
      "[75]\ttraining's l2: 0.313458\tvalid_1's l2: 0.200539\n",
      "[100]\ttraining's l2: 0.229574\tvalid_1's l2: 0.140045\n",
      "[125]\ttraining's l2: 0.168496\tvalid_1's l2: 0.0997705\n",
      "[150]\ttraining's l2: 0.13072\tvalid_1's l2: 0.075079\n",
      "[175]\ttraining's l2: 0.105514\tvalid_1's l2: 0.0636434\n",
      "[200]\ttraining's l2: 0.0877263\tvalid_1's l2: 0.0528936\n",
      "[225]\ttraining's l2: 0.0756812\tvalid_1's l2: 0.0458856\n",
      "[250]\ttraining's l2: 0.067019\tvalid_1's l2: 0.0424021\n",
      "[275]\ttraining's l2: 0.0594463\tvalid_1's l2: 0.0399934\n",
      "[300]\ttraining's l2: 0.0547367\tvalid_1's l2: 0.0391092\n",
      "[325]\ttraining's l2: 0.0505698\tvalid_1's l2: 0.0384792\n",
      "[350]\ttraining's l2: 0.0471925\tvalid_1's l2: 0.0389903\n",
      "[375]\ttraining's l2: 0.0438546\tvalid_1's l2: 0.0387983\n",
      "[400]\ttraining's l2: 0.0405627\tvalid_1's l2: 0.0401376\n",
      "[425]\ttraining's l2: 0.0379902\tvalid_1's l2: 0.0397586\n",
      "[450]\ttraining's l2: 0.0358145\tvalid_1's l2: 0.0392518\n",
      "[475]\ttraining's l2: 0.0339624\tvalid_1's l2: 0.0387505\n",
      "[500]\ttraining's l2: 0.0320697\tvalid_1's l2: 0.0391371\n",
      "[525]\ttraining's l2: 0.0303978\tvalid_1's l2: 0.0390576\n",
      "[550]\ttraining's l2: 0.0289604\tvalid_1's l2: 0.0389283\n",
      "[575]\ttraining's l2: 0.027388\tvalid_1's l2: 0.0401277\n",
      "[600]\ttraining's l2: 0.0260331\tvalid_1's l2: 0.0396731\n",
      "[625]\ttraining's l2: 0.0241123\tvalid_1's l2: 0.0395554\n",
      "[650]\ttraining's l2: 0.0229244\tvalid_1's l2: 0.0398886\n",
      "[675]\ttraining's l2: 0.0218214\tvalid_1's l2: 0.0401245\n",
      "[700]\ttraining's l2: 0.0207904\tvalid_1's l2: 0.0405442\n",
      "[725]\ttraining's l2: 0.0197887\tvalid_1's l2: 0.0403699\n",
      "[750]\ttraining's l2: 0.0187552\tvalid_1's l2: 0.0404747\n",
      "[775]\ttraining's l2: 0.0177513\tvalid_1's l2: 0.040346\n",
      "[800]\ttraining's l2: 0.0167587\tvalid_1's l2: 0.0404377\n",
      "[825]\ttraining's l2: 0.0159886\tvalid_1's l2: 0.0406987\n",
      "[850]\ttraining's l2: 0.0151364\tvalid_1's l2: 0.0402968\n",
      "[875]\ttraining's l2: 0.0143376\tvalid_1's l2: 0.0400355\n",
      "[900]\ttraining's l2: 0.0137085\tvalid_1's l2: 0.0401923\n",
      "[925]\ttraining's l2: 0.0131397\tvalid_1's l2: 0.0405972\n",
      "[950]\ttraining's l2: 0.012541\tvalid_1's l2: 0.0410337\n",
      "[975]\ttraining's l2: 0.0120433\tvalid_1's l2: 0.0412333\n",
      "[1000]\ttraining's l2: 0.0115505\tvalid_1's l2: 0.0410398\n",
      "[1025]\ttraining's l2: 0.0110252\tvalid_1's l2: 0.0410821\n",
      "[1050]\ttraining's l2: 0.010658\tvalid_1's l2: 0.0414099\n",
      "[1075]\ttraining's l2: 0.0102383\tvalid_1's l2: 0.0414917\n",
      "[1100]\ttraining's l2: 0.00989785\tvalid_1's l2: 0.041715\n",
      "[1125]\ttraining's l2: 0.00957865\tvalid_1's l2: 0.0416328\n",
      "[1150]\ttraining's l2: 0.0092214\tvalid_1's l2: 0.0418802\n",
      "[1175]\ttraining's l2: 0.00888194\tvalid_1's l2: 0.0419939\n",
      "[1200]\ttraining's l2: 0.00852459\tvalid_1's l2: 0.042244\n",
      "[1225]\ttraining's l2: 0.00815133\tvalid_1's l2: 0.0423487\n",
      "[1250]\ttraining's l2: 0.00790886\tvalid_1's l2: 0.0423754\n",
      "[1275]\ttraining's l2: 0.007622\tvalid_1's l2: 0.0425394\n",
      "[1300]\ttraining's l2: 0.00738548\tvalid_1's l2: 0.0421747\n",
      "Early stopping, best iteration is:\n",
      "[321]\ttraining's l2: 0.0511912\tvalid_1's l2: 0.0383128\n",
      "fold 7\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.683202\tvalid_1's l2: 0.378661\n",
      "[50]\ttraining's l2: 0.455224\tvalid_1's l2: 0.244471\n",
      "[75]\ttraining's l2: 0.315724\tvalid_1's l2: 0.166297\n",
      "[100]\ttraining's l2: 0.228431\tvalid_1's l2: 0.120663\n",
      "[125]\ttraining's l2: 0.166164\tvalid_1's l2: 0.0909709\n",
      "[150]\ttraining's l2: 0.127849\tvalid_1's l2: 0.0727324\n",
      "[175]\ttraining's l2: 0.103198\tvalid_1's l2: 0.0621042\n",
      "[200]\ttraining's l2: 0.0848648\tvalid_1's l2: 0.0546292\n",
      "[225]\ttraining's l2: 0.0729009\tvalid_1's l2: 0.0513356\n",
      "[250]\ttraining's l2: 0.0627528\tvalid_1's l2: 0.0475044\n",
      "[275]\ttraining's l2: 0.0558888\tvalid_1's l2: 0.0443869\n",
      "[300]\ttraining's l2: 0.0507478\tvalid_1's l2: 0.0429096\n",
      "[325]\ttraining's l2: 0.0466974\tvalid_1's l2: 0.041428\n",
      "[350]\ttraining's l2: 0.0432708\tvalid_1's l2: 0.0410391\n",
      "[375]\ttraining's l2: 0.0402816\tvalid_1's l2: 0.0403928\n",
      "[400]\ttraining's l2: 0.0377154\tvalid_1's l2: 0.0405161\n",
      "[425]\ttraining's l2: 0.0354221\tvalid_1's l2: 0.0407146\n",
      "[450]\ttraining's l2: 0.0334741\tvalid_1's l2: 0.0411517\n",
      "[475]\ttraining's l2: 0.0315215\tvalid_1's l2: 0.0417477\n",
      "[500]\ttraining's l2: 0.0294454\tvalid_1's l2: 0.0420313\n",
      "[525]\ttraining's l2: 0.0278219\tvalid_1's l2: 0.0426598\n",
      "[550]\ttraining's l2: 0.026119\tvalid_1's l2: 0.0429958\n",
      "[575]\ttraining's l2: 0.0249577\tvalid_1's l2: 0.0431778\n",
      "[600]\ttraining's l2: 0.0237535\tvalid_1's l2: 0.042752\n",
      "[625]\ttraining's l2: 0.0224435\tvalid_1's l2: 0.0433963\n",
      "[650]\ttraining's l2: 0.021403\tvalid_1's l2: 0.043667\n",
      "[675]\ttraining's l2: 0.0203708\tvalid_1's l2: 0.043923\n",
      "[700]\ttraining's l2: 0.0192352\tvalid_1's l2: 0.0440052\n",
      "[725]\ttraining's l2: 0.0182612\tvalid_1's l2: 0.0440004\n",
      "[750]\ttraining's l2: 0.0173776\tvalid_1's l2: 0.0441114\n",
      "[775]\ttraining's l2: 0.016653\tvalid_1's l2: 0.0442015\n",
      "[800]\ttraining's l2: 0.015796\tvalid_1's l2: 0.0442866\n",
      "[825]\ttraining's l2: 0.0149006\tvalid_1's l2: 0.0442027\n",
      "[850]\ttraining's l2: 0.0142017\tvalid_1's l2: 0.0440582\n",
      "[875]\ttraining's l2: 0.0135992\tvalid_1's l2: 0.0446402\n",
      "[900]\ttraining's l2: 0.0129957\tvalid_1's l2: 0.0448202\n",
      "[925]\ttraining's l2: 0.0123097\tvalid_1's l2: 0.0451731\n",
      "[950]\ttraining's l2: 0.0118263\tvalid_1's l2: 0.0452957\n",
      "[975]\ttraining's l2: 0.0112931\tvalid_1's l2: 0.0454385\n",
      "[1000]\ttraining's l2: 0.0108119\tvalid_1's l2: 0.0451341\n",
      "[1025]\ttraining's l2: 0.0102374\tvalid_1's l2: 0.045025\n",
      "[1050]\ttraining's l2: 0.00982845\tvalid_1's l2: 0.0455254\n",
      "[1075]\ttraining's l2: 0.00943594\tvalid_1's l2: 0.0450531\n",
      "[1100]\ttraining's l2: 0.00910484\tvalid_1's l2: 0.0448232\n",
      "[1125]\ttraining's l2: 0.0087129\tvalid_1's l2: 0.0447204\n",
      "[1150]\ttraining's l2: 0.00836212\tvalid_1's l2: 0.044903\n",
      "[1175]\ttraining's l2: 0.00805158\tvalid_1's l2: 0.0449012\n",
      "[1200]\ttraining's l2: 0.00768657\tvalid_1's l2: 0.0449837\n",
      "[1225]\ttraining's l2: 0.00745986\tvalid_1's l2: 0.0451728\n",
      "[1250]\ttraining's l2: 0.00721476\tvalid_1's l2: 0.0452658\n",
      "[1275]\ttraining's l2: 0.00691716\tvalid_1's l2: 0.0455931\n",
      "[1300]\ttraining's l2: 0.00670291\tvalid_1's l2: 0.0458485\n",
      "[1325]\ttraining's l2: 0.00651361\tvalid_1's l2: 0.0457444\n",
      "[1350]\ttraining's l2: 0.00629891\tvalid_1's l2: 0.0456588\n",
      "[1375]\ttraining's l2: 0.00605978\tvalid_1's l2: 0.0458086\n",
      "Early stopping, best iteration is:\n",
      "[384]\ttraining's l2: 0.039419\tvalid_1's l2: 0.0401461\n",
      "fold 8\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.691855\tvalid_1's l2: 0.317604\n",
      "[50]\ttraining's l2: 0.463627\tvalid_1's l2: 0.205708\n",
      "[75]\ttraining's l2: 0.321555\tvalid_1's l2: 0.139402\n",
      "[100]\ttraining's l2: 0.232657\tvalid_1's l2: 0.101896\n",
      "[125]\ttraining's l2: 0.170289\tvalid_1's l2: 0.0771099\n",
      "[150]\ttraining's l2: 0.129883\tvalid_1's l2: 0.0660416\n",
      "[175]\ttraining's l2: 0.103499\tvalid_1's l2: 0.0603446\n",
      "[200]\ttraining's l2: 0.0857254\tvalid_1's l2: 0.0546928\n",
      "[225]\ttraining's l2: 0.0730746\tvalid_1's l2: 0.0531583\n",
      "[250]\ttraining's l2: 0.0640111\tvalid_1's l2: 0.0532444\n",
      "[275]\ttraining's l2: 0.0565985\tvalid_1's l2: 0.0535072\n",
      "[300]\ttraining's l2: 0.0516164\tvalid_1's l2: 0.0545483\n",
      "[325]\ttraining's l2: 0.0476025\tvalid_1's l2: 0.0549237\n",
      "[350]\ttraining's l2: 0.0442875\tvalid_1's l2: 0.0571285\n",
      "[375]\ttraining's l2: 0.0415783\tvalid_1's l2: 0.0589182\n",
      "[400]\ttraining's l2: 0.0392322\tvalid_1's l2: 0.0594617\n",
      "[425]\ttraining's l2: 0.0366722\tvalid_1's l2: 0.0602932\n",
      "[450]\ttraining's l2: 0.0346412\tvalid_1's l2: 0.0611839\n",
      "[475]\ttraining's l2: 0.032204\tvalid_1's l2: 0.0616833\n",
      "[500]\ttraining's l2: 0.0305341\tvalid_1's l2: 0.0620469\n",
      "[525]\ttraining's l2: 0.0288754\tvalid_1's l2: 0.062755\n",
      "[550]\ttraining's l2: 0.0272295\tvalid_1's l2: 0.062444\n",
      "[575]\ttraining's l2: 0.0256069\tvalid_1's l2: 0.0619365\n",
      "[600]\ttraining's l2: 0.0243084\tvalid_1's l2: 0.0628224\n",
      "[625]\ttraining's l2: 0.0228882\tvalid_1's l2: 0.0622267\n",
      "[650]\ttraining's l2: 0.0217513\tvalid_1's l2: 0.0616169\n",
      "[675]\ttraining's l2: 0.0206671\tvalid_1's l2: 0.0620552\n",
      "[700]\ttraining's l2: 0.0194758\tvalid_1's l2: 0.0622073\n",
      "[725]\ttraining's l2: 0.0185212\tvalid_1's l2: 0.0623768\n",
      "[750]\ttraining's l2: 0.0175714\tvalid_1's l2: 0.0628735\n",
      "[775]\ttraining's l2: 0.0167091\tvalid_1's l2: 0.0622531\n",
      "[800]\ttraining's l2: 0.0158364\tvalid_1's l2: 0.0627252\n",
      "[825]\ttraining's l2: 0.0150967\tvalid_1's l2: 0.0627623\n",
      "[850]\ttraining's l2: 0.0143048\tvalid_1's l2: 0.0629155\n",
      "[875]\ttraining's l2: 0.0136082\tvalid_1's l2: 0.0624737\n",
      "[900]\ttraining's l2: 0.0130283\tvalid_1's l2: 0.061971\n",
      "[925]\ttraining's l2: 0.0124426\tvalid_1's l2: 0.0617329\n",
      "[950]\ttraining's l2: 0.0119441\tvalid_1's l2: 0.0614673\n",
      "[975]\ttraining's l2: 0.0114264\tvalid_1's l2: 0.0614499\n",
      "[1000]\ttraining's l2: 0.0109197\tvalid_1's l2: 0.0618427\n",
      "[1025]\ttraining's l2: 0.0105711\tvalid_1's l2: 0.0615941\n",
      "[1050]\ttraining's l2: 0.0101094\tvalid_1's l2: 0.0622582\n",
      "[1075]\ttraining's l2: 0.00963921\tvalid_1's l2: 0.061963\n",
      "[1100]\ttraining's l2: 0.00929728\tvalid_1's l2: 0.062067\n",
      "[1125]\ttraining's l2: 0.00893017\tvalid_1's l2: 0.0619247\n",
      "[1150]\ttraining's l2: 0.0085391\tvalid_1's l2: 0.0623887\n",
      "[1175]\ttraining's l2: 0.00824832\tvalid_1's l2: 0.0626705\n",
      "[1200]\ttraining's l2: 0.00794333\tvalid_1's l2: 0.0629485\n",
      "[1225]\ttraining's l2: 0.00757997\tvalid_1's l2: 0.0632427\n",
      "[1250]\ttraining's l2: 0.00729172\tvalid_1's l2: 0.0633575\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's l2: 0.0617486\tvalid_1's l2: 0.0529648\n",
      "fold 9\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.677407\tvalid_1's l2: 0.520936\n",
      "[50]\ttraining's l2: 0.455713\tvalid_1's l2: 0.352005\n",
      "[75]\ttraining's l2: 0.316638\tvalid_1's l2: 0.242397\n",
      "[100]\ttraining's l2: 0.228504\tvalid_1's l2: 0.178584\n",
      "[125]\ttraining's l2: 0.169589\tvalid_1's l2: 0.13013\n",
      "[150]\ttraining's l2: 0.13108\tvalid_1's l2: 0.0999303\n",
      "[175]\ttraining's l2: 0.104496\tvalid_1's l2: 0.0805202\n",
      "[200]\ttraining's l2: 0.0864462\tvalid_1's l2: 0.0688245\n",
      "[225]\ttraining's l2: 0.0738819\tvalid_1's l2: 0.0610993\n",
      "[250]\ttraining's l2: 0.0640875\tvalid_1's l2: 0.0542042\n",
      "[275]\ttraining's l2: 0.0574197\tvalid_1's l2: 0.0505373\n",
      "[300]\ttraining's l2: 0.052508\tvalid_1's l2: 0.0490507\n",
      "[325]\ttraining's l2: 0.0485255\tvalid_1's l2: 0.0465755\n",
      "[350]\ttraining's l2: 0.0449711\tvalid_1's l2: 0.0456872\n",
      "[375]\ttraining's l2: 0.0419359\tvalid_1's l2: 0.0446539\n",
      "[400]\ttraining's l2: 0.038966\tvalid_1's l2: 0.0447259\n",
      "[425]\ttraining's l2: 0.036693\tvalid_1's l2: 0.0444427\n",
      "[450]\ttraining's l2: 0.0349152\tvalid_1's l2: 0.0437343\n",
      "[475]\ttraining's l2: 0.0330311\tvalid_1's l2: 0.0440292\n",
      "[500]\ttraining's l2: 0.0310934\tvalid_1's l2: 0.0442815\n",
      "[525]\ttraining's l2: 0.0294625\tvalid_1's l2: 0.0448078\n",
      "[550]\ttraining's l2: 0.0278726\tvalid_1's l2: 0.0452764\n",
      "[575]\ttraining's l2: 0.0263092\tvalid_1's l2: 0.0459021\n",
      "[600]\ttraining's l2: 0.0248088\tvalid_1's l2: 0.0461654\n",
      "[625]\ttraining's l2: 0.0239378\tvalid_1's l2: 0.0461119\n",
      "[650]\ttraining's l2: 0.0226622\tvalid_1's l2: 0.0458661\n",
      "[675]\ttraining's l2: 0.0214692\tvalid_1's l2: 0.0462278\n",
      "[700]\ttraining's l2: 0.0201836\tvalid_1's l2: 0.0462552\n",
      "[725]\ttraining's l2: 0.0193435\tvalid_1's l2: 0.0467243\n",
      "[750]\ttraining's l2: 0.0183669\tvalid_1's l2: 0.0467443\n",
      "[775]\ttraining's l2: 0.0175344\tvalid_1's l2: 0.0468454\n",
      "[800]\ttraining's l2: 0.016679\tvalid_1's l2: 0.0466907\n",
      "[825]\ttraining's l2: 0.0157616\tvalid_1's l2: 0.0469705\n",
      "[850]\ttraining's l2: 0.0150052\tvalid_1's l2: 0.0469765\n",
      "[875]\ttraining's l2: 0.0143524\tvalid_1's l2: 0.0472641\n",
      "[900]\ttraining's l2: 0.0138792\tvalid_1's l2: 0.0470212\n",
      "[925]\ttraining's l2: 0.013331\tvalid_1's l2: 0.0472158\n",
      "[950]\ttraining's l2: 0.0128471\tvalid_1's l2: 0.0475521\n",
      "[975]\ttraining's l2: 0.0123409\tvalid_1's l2: 0.0472265\n",
      "[1000]\ttraining's l2: 0.0119175\tvalid_1's l2: 0.0472167\n",
      "[1025]\ttraining's l2: 0.0114136\tvalid_1's l2: 0.047465\n",
      "[1050]\ttraining's l2: 0.0109926\tvalid_1's l2: 0.0474991\n",
      "[1075]\ttraining's l2: 0.0105093\tvalid_1's l2: 0.0472192\n",
      "[1100]\ttraining's l2: 0.0101319\tvalid_1's l2: 0.0471967\n",
      "[1125]\ttraining's l2: 0.00978333\tvalid_1's l2: 0.0470456\n",
      "[1150]\ttraining's l2: 0.00941526\tvalid_1's l2: 0.0470157\n",
      "[1175]\ttraining's l2: 0.00909615\tvalid_1's l2: 0.0469805\n",
      "[1200]\ttraining's l2: 0.00875038\tvalid_1's l2: 0.0470277\n",
      "[1225]\ttraining's l2: 0.00840003\tvalid_1's l2: 0.0468881\n",
      "[1250]\ttraining's l2: 0.00812497\tvalid_1's l2: 0.0466686\n",
      "[1275]\ttraining's l2: 0.0078212\tvalid_1's l2: 0.0466191\n",
      "[1300]\ttraining's l2: 0.00763246\tvalid_1's l2: 0.0466188\n",
      "[1325]\ttraining's l2: 0.00735579\tvalid_1's l2: 0.0466255\n",
      "[1350]\ttraining's l2: 0.0071662\tvalid_1's l2: 0.0466154\n",
      "[1375]\ttraining's l2: 0.00688502\tvalid_1's l2: 0.0466173\n",
      "[1400]\ttraining's l2: 0.00662671\tvalid_1's l2: 0.0466235\n",
      "[1425]\ttraining's l2: 0.00641475\tvalid_1's l2: 0.046737\n",
      "[1450]\ttraining's l2: 0.0062235\tvalid_1's l2: 0.0468501\n",
      "Early stopping, best iteration is:\n",
      "[453]\ttraining's l2: 0.0346944\tvalid_1's l2: 0.0436758\n"
     ]
    }
   ],
   "source": [
    "feature_importances = get_feature_importance(10,X_train,y_train,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RON_of_raw_material</td>\n",
       "      <td>861.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>density</td>\n",
       "      <td>151.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>S-ZORB.FT_9301.PV</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>S-ZORB.TE_5008.DACA</td>\n",
       "      <td>116.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>S-ZORB.AT_1001.DACA</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>S-ZORB.FT_9102.TOTAL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>S-ZORB.FT_1001.TOTAL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>S-ZORB.FT_9403.TOTAL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>S-ZORB.FT_1004.TOTAL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>S-ZORB.FT_1501.PV</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   column  importance\n",
       "1     RON_of_raw_material       861.2\n",
       "5                 density       151.8\n",
       "32      S-ZORB.FT_9301.PV       133.0\n",
       "305   S-ZORB.TE_5008.DACA       116.2\n",
       "190   S-ZORB.AT_1001.DACA       114.0\n",
       "..                    ...         ...\n",
       "118  S-ZORB.FT_9102.TOTAL         0.0\n",
       "119  S-ZORB.FT_1001.TOTAL         0.0\n",
       "111  S-ZORB.FT_9403.TOTAL         0.0\n",
       "96   S-ZORB.FT_1004.TOTAL         0.0\n",
       "33      S-ZORB.FT_1501.PV         0.0\n",
       "\n",
       "[354 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance.sort_values(by='importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RON_of_raw_material</td>\n",
       "      <td>861.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>density</td>\n",
       "      <td>151.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>S-ZORB.FT_9301.PV</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>S-ZORB.TE_5008.DACA</td>\n",
       "      <td>116.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>S-ZORB.AT_1001.DACA</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>S-ZORB.PDT_2606.DACA</td>\n",
       "      <td>112.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>S-ZORB.FT_1003.PV</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>S-ZORB.LT_1002.DACA</td>\n",
       "      <td>88.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>S-ZORB.FT_1504.DACA.PV</td>\n",
       "      <td>86.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>S-ZORB.TE_1105.PV</td>\n",
       "      <td>84.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>S-ZORB.AT-0009.DACA.PV</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>S-ZORB.PT_1604.DACA</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>S-ZORB.FT_3702.DACA</td>\n",
       "      <td>78.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>S-ZORB.LT_9001.DACA</td>\n",
       "      <td>78.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>S-ZORB.FC_1203.PV</td>\n",
       "      <td>77.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>S-ZORB.FT_2431.DACA</td>\n",
       "      <td>75.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>S-ZORB.TE_5102.PV</td>\n",
       "      <td>75.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>S-ZORB.FC_2702.DACA</td>\n",
       "      <td>72.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>S-ZORB.FT_1001.PV</td>\n",
       "      <td>71.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>S-ZORB.FC_1102.PV</td>\n",
       "      <td>69.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>S-ZORB.FC_5001.DACA</td>\n",
       "      <td>68.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>S-ZORB.FC_1201.PV</td>\n",
       "      <td>67.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>S-ZORB.PC_1001A.PV</td>\n",
       "      <td>67.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>S-ZORB.AT-0011.DACA.PV</td>\n",
       "      <td>67.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S-ZORB.CAL_H2.PV</td>\n",
       "      <td>65.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S-ZORB.TE_5202.PV</td>\n",
       "      <td>65.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Substitute_S</td>\n",
       "      <td>65.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>S-ZORB.TE_1203.PV</td>\n",
       "      <td>64.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>S-ZORB.FT_5101.PV</td>\n",
       "      <td>63.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>S-ZORB.TE_1501.DACA</td>\n",
       "      <td>63.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     column  importance\n",
       "1       RON_of_raw_material       861.2\n",
       "5                   density       151.8\n",
       "32        S-ZORB.FT_9301.PV       133.0\n",
       "305     S-ZORB.TE_5008.DACA       116.2\n",
       "190     S-ZORB.AT_1001.DACA       114.0\n",
       "232    S-ZORB.PDT_2606.DACA       112.6\n",
       "55        S-ZORB.FT_1003.PV        93.0\n",
       "171     S-ZORB.LT_1002.DACA        88.8\n",
       "351  S-ZORB.FT_1504.DACA.PV        86.8\n",
       "62        S-ZORB.TE_1105.PV        84.8\n",
       "321  S-ZORB.AT-0009.DACA.PV        81.0\n",
       "286     S-ZORB.PT_1604.DACA        80.0\n",
       "227     S-ZORB.FT_3702.DACA        78.8\n",
       "132     S-ZORB.LT_9001.DACA        78.4\n",
       "80        S-ZORB.FC_1203.PV        77.6\n",
       "179     S-ZORB.FT_2431.DACA        75.6\n",
       "28        S-ZORB.TE_5102.PV        75.2\n",
       "151     S-ZORB.FC_2702.DACA        72.4\n",
       "53        S-ZORB.FT_1001.PV        71.8\n",
       "60        S-ZORB.FC_1102.PV        69.6\n",
       "307     S-ZORB.FC_5001.DACA        68.6\n",
       "76        S-ZORB.FC_1201.PV        67.4\n",
       "353      S-ZORB.PC_1001A.PV        67.2\n",
       "323  S-ZORB.AT-0011.DACA.PV        67.2\n",
       "10         S-ZORB.CAL_H2.PV        65.4\n",
       "29        S-ZORB.TE_5202.PV        65.4\n",
       "7              Substitute_S        65.4\n",
       "78        S-ZORB.TE_1203.PV        64.2\n",
       "35        S-ZORB.FT_5101.PV        63.8\n",
       "144     S-ZORB.TE_1501.DACA        63.2"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:30,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RON_of_raw_material</td>\n",
       "      <td>860.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>S-ZORB.FT_1504.DACA.PV</td>\n",
       "      <td>60.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>S-ZORB.PDT_2606.DACA</td>\n",
       "      <td>53.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>S-ZORB.FT_9301.PV</td>\n",
       "      <td>48.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>S-ZORB.TC_2801.PV</td>\n",
       "      <td>41.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>S-ZORB.FC_1203.PV</td>\n",
       "      <td>41.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>S-ZORB.LT_1002.DACA</td>\n",
       "      <td>41.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>S-ZORB.SIS_TE_2802</td>\n",
       "      <td>37.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>S-ZORB.FT_1003.PV</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>S-ZORB.FT_3702.DACA</td>\n",
       "      <td>35.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>S-ZORB.TE_1501.DACA</td>\n",
       "      <td>34.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>S-ZORB.TE_5008.DACA</td>\n",
       "      <td>34.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>S-ZORB.FC_5001.DACA</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>S-ZORB.LC_1203.DACA</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>S-ZORB.LT_3801.DACA</td>\n",
       "      <td>31.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sulfur_content_of_raw_material</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>S-ZORB.LC_1201.PV</td>\n",
       "      <td>28.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>S-ZORB.PT_1103.DACA</td>\n",
       "      <td>27.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>S-ZORB.TE_1601.PV</td>\n",
       "      <td>26.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>S-ZORB.LI_9102.DACA</td>\n",
       "      <td>25.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>S-ZORB.TE_1105.PV</td>\n",
       "      <td>25.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>S-ZORB.FT_1001.PV</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saturated_hydrocarbon</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>S-ZORB.PT_1604.DACA</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>S-ZORB.FT_2901.DACA</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>S-ZORB.PC_1001A.PV</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S-ZORB.TE_5202.PV</td>\n",
       "      <td>23.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>S-ZORB.TE_5004.DACA</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>S-ZORB.FC_1201.PV</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>S-ZORB.TE_1102.DACA.PV</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             column  importance\n",
       "1               RON_of_raw_material       860.9\n",
       "351          S-ZORB.FT_1504.DACA.PV        60.8\n",
       "232            S-ZORB.PDT_2606.DACA        53.6\n",
       "32                S-ZORB.FT_9301.PV        48.8\n",
       "83                S-ZORB.TC_2801.PV        41.9\n",
       "80                S-ZORB.FC_1203.PV        41.3\n",
       "171             S-ZORB.LT_1002.DACA        41.2\n",
       "170              S-ZORB.SIS_TE_2802        37.4\n",
       "55                S-ZORB.FT_1003.PV        37.2\n",
       "227             S-ZORB.FT_3702.DACA        35.7\n",
       "144             S-ZORB.TE_1501.DACA        34.6\n",
       "305             S-ZORB.TE_5008.DACA        34.3\n",
       "307             S-ZORB.FC_5001.DACA        33.5\n",
       "146             S-ZORB.LC_1203.DACA        33.5\n",
       "135             S-ZORB.LT_3801.DACA        31.3\n",
       "0    Sulfur_content_of_raw_material        28.7\n",
       "75                S-ZORB.LC_1201.PV        28.1\n",
       "122             S-ZORB.PT_1103.DACA        27.6\n",
       "64                S-ZORB.TE_1601.PV        26.4\n",
       "127             S-ZORB.LI_9102.DACA        25.9\n",
       "62                S-ZORB.TE_1105.PV        25.8\n",
       "53                S-ZORB.FT_1001.PV        25.6\n",
       "2             Saturated_hydrocarbon        25.5\n",
       "286             S-ZORB.PT_1604.DACA        24.2\n",
       "155             S-ZORB.FT_2901.DACA        24.2\n",
       "353              S-ZORB.PC_1001A.PV        24.2\n",
       "29                S-ZORB.TE_5202.PV        23.2\n",
       "173             S-ZORB.TE_5004.DACA        23.1\n",
       "76                S-ZORB.FC_1201.PV        23.0\n",
       "336          S-ZORB.TE_1102.DACA.PV        22.6"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = feature_importances.sort_values(by='importance',ascending=False)\n",
    "dfs.iloc[:30,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_1 = df.iloc[:30,:]['column'].values\n",
    "columns_2 = dfs.iloc[:30,:]['column'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S-ZORB.PC_1001A.PV',\n",
       " 'S-ZORB.FC_1201.PV',\n",
       " 'S-ZORB.PT_1604.DACA',\n",
       " 'S-ZORB.FT_1001.PV',\n",
       " 'S-ZORB.FT_3702.DACA',\n",
       " 'S-ZORB.LT_1002.DACA',\n",
       " 'S-ZORB.TE_1501.DACA',\n",
       " 'S-ZORB.TE_5008.DACA',\n",
       " 'RON_of_raw_material',\n",
       " 'S-ZORB.TE_1105.PV',\n",
       " 'S-ZORB.FT_1504.DACA.PV',\n",
       " 'S-ZORB.PDT_2606.DACA',\n",
       " 'S-ZORB.FC_1203.PV',\n",
       " 'S-ZORB.TE_5202.PV',\n",
       " 'S-ZORB.FC_5001.DACA',\n",
       " 'S-ZORB.FT_1003.PV',\n",
       " 'S-ZORB.FT_9301.PV']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(columns_1).intersection(set(columns_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['S-ZORB.LT_1002.DACA',\n",
    " 'RON_of_raw_material',\n",
    " 'S-ZORB.FT_1504.DACA.PV',\n",
    " 'S-ZORB.PDT_2606.DACA',\n",
    " 'S-ZORB.FT_1003.PV',\n",
    " 'S-ZORB.FT_9301.PV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.655256\tvalid_1's l2: 0.563855\n",
      "[50]\ttraining's l2: 0.448924\tvalid_1's l2: 0.388061\n",
      "[75]\ttraining's l2: 0.315777\tvalid_1's l2: 0.276304\n",
      "[100]\ttraining's l2: 0.225206\tvalid_1's l2: 0.199105\n",
      "[125]\ttraining's l2: 0.162195\tvalid_1's l2: 0.148396\n",
      "[150]\ttraining's l2: 0.125184\tvalid_1's l2: 0.119751\n",
      "[175]\ttraining's l2: 0.099887\tvalid_1's l2: 0.0984244\n",
      "[200]\ttraining's l2: 0.0831099\tvalid_1's l2: 0.0861992\n",
      "[225]\ttraining's l2: 0.0714436\tvalid_1's l2: 0.0778355\n",
      "[250]\ttraining's l2: 0.0633596\tvalid_1's l2: 0.0719615\n",
      "[275]\ttraining's l2: 0.0571631\tvalid_1's l2: 0.0678692\n",
      "[300]\ttraining's l2: 0.0530895\tvalid_1's l2: 0.0665469\n",
      "[325]\ttraining's l2: 0.049793\tvalid_1's l2: 0.0643434\n",
      "[350]\ttraining's l2: 0.046853\tvalid_1's l2: 0.0630545\n",
      "[375]\ttraining's l2: 0.044133\tvalid_1's l2: 0.062164\n",
      "[400]\ttraining's l2: 0.0418425\tvalid_1's l2: 0.0609886\n",
      "[425]\ttraining's l2: 0.0395311\tvalid_1's l2: 0.0600771\n",
      "[450]\ttraining's l2: 0.0377904\tvalid_1's l2: 0.0594398\n",
      "[475]\ttraining's l2: 0.036041\tvalid_1's l2: 0.0587046\n",
      "[500]\ttraining's l2: 0.0345231\tvalid_1's l2: 0.0586296\n",
      "[525]\ttraining's l2: 0.0331363\tvalid_1's l2: 0.0581666\n",
      "[550]\ttraining's l2: 0.0321929\tvalid_1's l2: 0.0579599\n",
      "[575]\ttraining's l2: 0.0307667\tvalid_1's l2: 0.0575717\n",
      "[600]\ttraining's l2: 0.0294846\tvalid_1's l2: 0.0571543\n",
      "[625]\ttraining's l2: 0.0282855\tvalid_1's l2: 0.0567353\n",
      "[650]\ttraining's l2: 0.0274508\tvalid_1's l2: 0.0564526\n",
      "[675]\ttraining's l2: 0.0264195\tvalid_1's l2: 0.0560128\n",
      "[700]\ttraining's l2: 0.0254397\tvalid_1's l2: 0.0557599\n",
      "[725]\ttraining's l2: 0.024504\tvalid_1's l2: 0.0561322\n",
      "[750]\ttraining's l2: 0.0236761\tvalid_1's l2: 0.0563207\n",
      "[775]\ttraining's l2: 0.0229712\tvalid_1's l2: 0.0559809\n",
      "[800]\ttraining's l2: 0.02234\tvalid_1's l2: 0.0559317\n",
      "[825]\ttraining's l2: 0.0213992\tvalid_1's l2: 0.0560083\n",
      "[850]\ttraining's l2: 0.020616\tvalid_1's l2: 0.0558895\n",
      "[875]\ttraining's l2: 0.0199272\tvalid_1's l2: 0.0559355\n",
      "[900]\ttraining's l2: 0.0192637\tvalid_1's l2: 0.0558889\n",
      "[925]\ttraining's l2: 0.0187207\tvalid_1's l2: 0.056182\n",
      "[950]\ttraining's l2: 0.01824\tvalid_1's l2: 0.0563572\n",
      "[975]\ttraining's l2: 0.0176129\tvalid_1's l2: 0.0566153\n",
      "[1000]\ttraining's l2: 0.0170154\tvalid_1's l2: 0.056468\n",
      "[1025]\ttraining's l2: 0.0165718\tvalid_1's l2: 0.0566439\n",
      "[1050]\ttraining's l2: 0.0161615\tvalid_1's l2: 0.0567906\n",
      "[1075]\ttraining's l2: 0.0157191\tvalid_1's l2: 0.0568718\n",
      "[1100]\ttraining's l2: 0.0152669\tvalid_1's l2: 0.0566983\n",
      "[1125]\ttraining's l2: 0.0148595\tvalid_1's l2: 0.0568017\n",
      "[1150]\ttraining's l2: 0.0144228\tvalid_1's l2: 0.0567358\n",
      "[1175]\ttraining's l2: 0.0140233\tvalid_1's l2: 0.0567085\n",
      "[1200]\ttraining's l2: 0.0136447\tvalid_1's l2: 0.0565589\n",
      "[1225]\ttraining's l2: 0.0133266\tvalid_1's l2: 0.0565728\n",
      "[1250]\ttraining's l2: 0.013079\tvalid_1's l2: 0.0566638\n",
      "[1275]\ttraining's l2: 0.0128327\tvalid_1's l2: 0.056767\n",
      "[1300]\ttraining's l2: 0.012557\tvalid_1's l2: 0.0565646\n",
      "[1325]\ttraining's l2: 0.012232\tvalid_1's l2: 0.0568338\n",
      "[1350]\ttraining's l2: 0.0119127\tvalid_1's l2: 0.0565833\n",
      "[1375]\ttraining's l2: 0.011592\tvalid_1's l2: 0.0567323\n",
      "[1400]\ttraining's l2: 0.0113148\tvalid_1's l2: 0.0566732\n",
      "[1425]\ttraining's l2: 0.0110001\tvalid_1's l2: 0.0566928\n",
      "[1450]\ttraining's l2: 0.010706\tvalid_1's l2: 0.0566995\n",
      "[1475]\ttraining's l2: 0.010475\tvalid_1's l2: 0.0566097\n",
      "[1500]\ttraining's l2: 0.0103225\tvalid_1's l2: 0.05688\n",
      "[1525]\ttraining's l2: 0.0101186\tvalid_1's l2: 0.0568015\n",
      "[1550]\ttraining's l2: 0.00983336\tvalid_1's l2: 0.0567065\n",
      "[1575]\ttraining's l2: 0.00962892\tvalid_1's l2: 0.0563313\n",
      "[1600]\ttraining's l2: 0.00944837\tvalid_1's l2: 0.056478\n",
      "[1625]\ttraining's l2: 0.00916332\tvalid_1's l2: 0.0565516\n",
      "[1650]\ttraining's l2: 0.00893805\tvalid_1's l2: 0.0565108\n",
      "[1675]\ttraining's l2: 0.00876873\tvalid_1's l2: 0.0564892\n",
      "[1700]\ttraining's l2: 0.00852274\tvalid_1's l2: 0.0563753\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's l2: 0.0252557\tvalid_1's l2: 0.0556766\n"
     ]
    }
   ],
   "source": [
    "x = X_train[['S-ZORB.PC_1001A.PV',\n",
    " 'S-ZORB.FC_1201.PV',\n",
    " 'S-ZORB.PT_1604.DACA',\n",
    " 'S-ZORB.FT_1001.PV',\n",
    " 'S-ZORB.FT_3702.DACA',\n",
    " 'S-ZORB.LT_1002.DACA',\n",
    " 'S-ZORB.TE_1501.DACA',\n",
    " 'S-ZORB.TE_5008.DACA',\n",
    " 'RON_of_raw_material',\n",
    " 'S-ZORB.TE_1105.PV',\n",
    " 'S-ZORB.FT_1504.DACA.PV',\n",
    " 'S-ZORB.PDT_2606.DACA',\n",
    " 'S-ZORB.FC_1203.PV',\n",
    " 'S-ZORB.TE_5202.PV',\n",
    " 'S-ZORB.FC_5001.DACA',\n",
    " 'S-ZORB.FT_1003.PV',\n",
    " 'S-ZORB.FT_9301.PV']]\n",
    "x1 = X_valid[['S-ZORB.PC_1001A.PV',\n",
    " 'S-ZORB.FC_1201.PV',\n",
    " 'S-ZORB.PT_1604.DACA',\n",
    " 'S-ZORB.FT_1001.PV',\n",
    " 'S-ZORB.FT_3702.DACA',\n",
    " 'S-ZORB.LT_1002.DACA',\n",
    " 'S-ZORB.TE_1501.DACA',\n",
    " 'S-ZORB.TE_5008.DACA',\n",
    " 'RON_of_raw_material',\n",
    " 'S-ZORB.TE_1105.PV',\n",
    " 'S-ZORB.FT_1504.DACA.PV',\n",
    " 'S-ZORB.PDT_2606.DACA',\n",
    " 'S-ZORB.FC_1203.PV',\n",
    " 'S-ZORB.TE_5202.PV',\n",
    " 'S-ZORB.FC_5001.DACA',\n",
    " 'S-ZORB.FT_1003.PV',\n",
    " 'S-ZORB.FT_9301.PV']]\n",
    "trn_data = lgb.Dataset(x, label=y_train)\n",
    "val_data = lgb.Dataset(x1, label=y_valid)\n",
    "model = lgb.train(param,trn_data,valid_sets=[trn_data,val_data],\\\n",
    "                  num_boost_round = 100000,early_stopping_rounds=1000,verbose_eval=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(feature_importance,x_train,y_train,x_val,y_val):\n",
    "    importance = feature_importance['importance'].values\n",
    "    Loss = []\n",
    "    for i in range(1,31):\n",
    "        column = feature_importance['column'][:i].values\n",
    "        a = x_train[columns]\n",
    "        b = x_val[columns]\n",
    "        trn_data = lgb.Dataset(a, label=y_train)\n",
    "        val_data = lgb.Dataset(b, label=y_val)\n",
    "        model = lgb.train(param,trn_data,valid_sets=[trn_data,val_data],\\\n",
    "                  num_boost_round = 100000,early_stopping_rounds=1000,verbose_eval=25)\n",
    "        loss = list(model.best_score['valid_1'].items())[0][1]\n",
    "        Loss.append(loss)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\tvalid_0's l2: 0.58738\n",
      "[50]\tvalid_0's l2: 0.412365\n",
      "[75]\tvalid_0's l2: 0.296564\n",
      "[100]\tvalid_0's l2: 0.218539\n",
      "[125]\tvalid_0's l2: 0.168525\n",
      "[150]\tvalid_0's l2: 0.135905\n",
      "[175]\tvalid_0's l2: 0.115203\n",
      "[200]\tvalid_0's l2: 0.101726\n",
      "[225]\tvalid_0's l2: 0.0913761\n",
      "[250]\tvalid_0's l2: 0.0840688\n",
      "[275]\tvalid_0's l2: 0.0795088\n",
      "[300]\tvalid_0's l2: 0.0770386\n",
      "[325]\tvalid_0's l2: 0.0749748\n",
      "[350]\tvalid_0's l2: 0.0732486\n",
      "[375]\tvalid_0's l2: 0.0718352\n",
      "[400]\tvalid_0's l2: 0.070946\n",
      "[425]\tvalid_0's l2: 0.0697162\n",
      "[450]\tvalid_0's l2: 0.0686863\n",
      "[475]\tvalid_0's l2: 0.0677853\n",
      "[500]\tvalid_0's l2: 0.0676794\n",
      "[525]\tvalid_0's l2: 0.0674591\n",
      "[550]\tvalid_0's l2: 0.0674169\n",
      "[575]\tvalid_0's l2: 0.0665503\n",
      "[600]\tvalid_0's l2: 0.0657651\n",
      "[625]\tvalid_0's l2: 0.0651051\n",
      "[650]\tvalid_0's l2: 0.0650964\n",
      "[675]\tvalid_0's l2: 0.0648784\n",
      "[700]\tvalid_0's l2: 0.0648222\n",
      "[725]\tvalid_0's l2: 0.0644033\n",
      "[750]\tvalid_0's l2: 0.0645886\n",
      "[775]\tvalid_0's l2: 0.0643832\n",
      "[800]\tvalid_0's l2: 0.064224\n",
      "[825]\tvalid_0's l2: 0.0641936\n",
      "[850]\tvalid_0's l2: 0.0639738\n",
      "[875]\tvalid_0's l2: 0.0636109\n",
      "[900]\tvalid_0's l2: 0.0632709\n",
      "[925]\tvalid_0's l2: 0.0631749\n",
      "[950]\tvalid_0's l2: 0.0631023\n",
      "[975]\tvalid_0's l2: 0.0630731\n",
      "[1000]\tvalid_0's l2: 0.0629788\n",
      "[1025]\tvalid_0's l2: 0.0633913\n",
      "[1050]\tvalid_0's l2: 0.0634552\n",
      "[1075]\tvalid_0's l2: 0.0637067\n",
      "[1100]\tvalid_0's l2: 0.0637254\n",
      "[1125]\tvalid_0's l2: 0.0639235\n",
      "[1150]\tvalid_0's l2: 0.0639363\n",
      "[1175]\tvalid_0's l2: 0.0639658\n",
      "[1200]\tvalid_0's l2: 0.0640388\n",
      "[1225]\tvalid_0's l2: 0.0640877\n",
      "[1250]\tvalid_0's l2: 0.0641497\n",
      "[1275]\tvalid_0's l2: 0.0642764\n",
      "[1300]\tvalid_0's l2: 0.0642989\n",
      "[1325]\tvalid_0's l2: 0.06436\n",
      "[1350]\tvalid_0's l2: 0.0643505\n",
      "[1375]\tvalid_0's l2: 0.0642474\n",
      "[1400]\tvalid_0's l2: 0.064038\n",
      "[1425]\tvalid_0's l2: 0.0640121\n",
      "[1450]\tvalid_0's l2: 0.0644145\n",
      "[1475]\tvalid_0's l2: 0.0643995\n",
      "[1500]\tvalid_0's l2: 0.0642723\n",
      "[1525]\tvalid_0's l2: 0.0642927\n",
      "[1550]\tvalid_0's l2: 0.0643845\n",
      "[1575]\tvalid_0's l2: 0.0642655\n",
      "[1600]\tvalid_0's l2: 0.0642928\n",
      "[1625]\tvalid_0's l2: 0.0641239\n",
      "[1650]\tvalid_0's l2: 0.0640315\n",
      "[1675]\tvalid_0's l2: 0.0641047\n",
      "[1700]\tvalid_0's l2: 0.0640027\n",
      "[1725]\tvalid_0's l2: 0.0639437\n",
      "[1750]\tvalid_0's l2: 0.0640059\n",
      "[1775]\tvalid_0's l2: 0.0641392\n",
      "[1800]\tvalid_0's l2: 0.0641356\n",
      "[1825]\tvalid_0's l2: 0.0640493\n",
      "[1850]\tvalid_0's l2: 0.0640734\n",
      "[1875]\tvalid_0's l2: 0.064347\n",
      "[1900]\tvalid_0's l2: 0.0642465\n",
      "[1925]\tvalid_0's l2: 0.0644127\n",
      "[1950]\tvalid_0's l2: 0.0645642\n",
      "[1975]\tvalid_0's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\tvalid_0's l2: 0.0628139\n"
     ]
    }
   ],
   "source": [
    "column = feature_importance['column'][:17].values\n",
    "a = X_train[columns]\n",
    "b = X_valid[columns]\n",
    "trn_data = lgb.Dataset(a, label=y_train)\n",
    "val_data = lgb.Dataset(b, label=y_valid)\n",
    "model = lgb.train(param,trn_data,valid_sets=[val_data],\\\n",
    "                  num_boost_round = 100000,early_stopping_rounds=1000,verbose_eval=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sulfur_content_of_raw_material', 'RON_of_raw_material',\n",
       "       'Saturated_hydrocarbon', 'olefin'], dtype=object)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[25]\ttraining's l2: 0.670927\tvalid_1's l2: 0.58738\n",
      "[50]\ttraining's l2: 0.462914\tvalid_1's l2: 0.412365\n",
      "[75]\ttraining's l2: 0.324266\tvalid_1's l2: 0.296564\n",
      "[100]\ttraining's l2: 0.232438\tvalid_1's l2: 0.218539\n",
      "[125]\ttraining's l2: 0.170285\tvalid_1's l2: 0.168525\n",
      "[150]\ttraining's l2: 0.130602\tvalid_1's l2: 0.135905\n",
      "[175]\ttraining's l2: 0.104982\tvalid_1's l2: 0.115203\n",
      "[200]\ttraining's l2: 0.088014\tvalid_1's l2: 0.101726\n",
      "[225]\ttraining's l2: 0.075542\tvalid_1's l2: 0.0913761\n",
      "[250]\ttraining's l2: 0.0666617\tvalid_1's l2: 0.0840688\n",
      "[275]\ttraining's l2: 0.0598698\tvalid_1's l2: 0.0795088\n",
      "[300]\ttraining's l2: 0.0551357\tvalid_1's l2: 0.0770386\n",
      "[325]\ttraining's l2: 0.051238\tvalid_1's l2: 0.0749748\n",
      "[350]\ttraining's l2: 0.048011\tvalid_1's l2: 0.0732486\n",
      "[375]\ttraining's l2: 0.0452335\tvalid_1's l2: 0.0718352\n",
      "[400]\ttraining's l2: 0.0426275\tvalid_1's l2: 0.070946\n",
      "[425]\ttraining's l2: 0.0403484\tvalid_1's l2: 0.0697162\n",
      "[450]\ttraining's l2: 0.0384299\tvalid_1's l2: 0.0686863\n",
      "[475]\ttraining's l2: 0.0369312\tvalid_1's l2: 0.0677853\n",
      "[500]\ttraining's l2: 0.0352552\tvalid_1's l2: 0.0676794\n",
      "[525]\ttraining's l2: 0.0337758\tvalid_1's l2: 0.0674591\n",
      "[550]\ttraining's l2: 0.0329325\tvalid_1's l2: 0.0674169\n",
      "[575]\ttraining's l2: 0.0316148\tvalid_1's l2: 0.0665503\n",
      "[600]\ttraining's l2: 0.030122\tvalid_1's l2: 0.0657651\n",
      "[625]\ttraining's l2: 0.028859\tvalid_1's l2: 0.0651051\n",
      "[650]\ttraining's l2: 0.0280415\tvalid_1's l2: 0.0650964\n",
      "[675]\ttraining's l2: 0.0270365\tvalid_1's l2: 0.0648784\n",
      "[700]\ttraining's l2: 0.0260776\tvalid_1's l2: 0.0648222\n",
      "[725]\ttraining's l2: 0.0251403\tvalid_1's l2: 0.0644033\n",
      "[750]\ttraining's l2: 0.02438\tvalid_1's l2: 0.0645886\n",
      "[775]\ttraining's l2: 0.023596\tvalid_1's l2: 0.0643832\n",
      "[800]\ttraining's l2: 0.0228729\tvalid_1's l2: 0.064224\n",
      "[825]\ttraining's l2: 0.0219029\tvalid_1's l2: 0.0641936\n",
      "[850]\ttraining's l2: 0.0211679\tvalid_1's l2: 0.0639738\n",
      "[875]\ttraining's l2: 0.0204767\tvalid_1's l2: 0.0636109\n",
      "[900]\ttraining's l2: 0.0198421\tvalid_1's l2: 0.0632709\n",
      "[925]\ttraining's l2: 0.0192431\tvalid_1's l2: 0.0631749\n",
      "[950]\ttraining's l2: 0.0187128\tvalid_1's l2: 0.0631023\n",
      "[975]\ttraining's l2: 0.0181879\tvalid_1's l2: 0.0630731\n",
      "[1000]\ttraining's l2: 0.0174776\tvalid_1's l2: 0.0629788\n",
      "[1025]\ttraining's l2: 0.0169882\tvalid_1's l2: 0.0633913\n",
      "[1050]\ttraining's l2: 0.0165706\tvalid_1's l2: 0.0634552\n",
      "[1075]\ttraining's l2: 0.0160285\tvalid_1's l2: 0.0637067\n",
      "[1100]\ttraining's l2: 0.0154679\tvalid_1's l2: 0.0637254\n",
      "[1125]\ttraining's l2: 0.0150048\tvalid_1's l2: 0.0639235\n",
      "[1150]\ttraining's l2: 0.0146285\tvalid_1's l2: 0.0639363\n",
      "[1175]\ttraining's l2: 0.014088\tvalid_1's l2: 0.0639658\n",
      "[1200]\ttraining's l2: 0.0137035\tvalid_1's l2: 0.0640388\n",
      "[1225]\ttraining's l2: 0.0133751\tvalid_1's l2: 0.0640877\n",
      "[1250]\ttraining's l2: 0.0130807\tvalid_1's l2: 0.0641497\n",
      "[1275]\ttraining's l2: 0.0128434\tvalid_1's l2: 0.0642764\n",
      "[1300]\ttraining's l2: 0.0125294\tvalid_1's l2: 0.0642989\n",
      "[1325]\ttraining's l2: 0.0121951\tvalid_1's l2: 0.06436\n",
      "[1350]\ttraining's l2: 0.0118773\tvalid_1's l2: 0.0643505\n",
      "[1375]\ttraining's l2: 0.0116009\tvalid_1's l2: 0.0642474\n",
      "[1400]\ttraining's l2: 0.011282\tvalid_1's l2: 0.064038\n",
      "[1425]\ttraining's l2: 0.0109328\tvalid_1's l2: 0.0640121\n",
      "[1450]\ttraining's l2: 0.0106347\tvalid_1's l2: 0.0644145\n",
      "[1475]\ttraining's l2: 0.0104092\tvalid_1's l2: 0.0643995\n",
      "[1500]\ttraining's l2: 0.0102108\tvalid_1's l2: 0.0642723\n",
      "[1525]\ttraining's l2: 0.00995929\tvalid_1's l2: 0.0642927\n",
      "[1550]\ttraining's l2: 0.00966154\tvalid_1's l2: 0.0643845\n",
      "[1575]\ttraining's l2: 0.00944683\tvalid_1's l2: 0.0642655\n",
      "[1600]\ttraining's l2: 0.00921855\tvalid_1's l2: 0.0642928\n",
      "[1625]\ttraining's l2: 0.0089702\tvalid_1's l2: 0.0641239\n",
      "[1650]\ttraining's l2: 0.00875895\tvalid_1's l2: 0.0640315\n",
      "[1675]\ttraining's l2: 0.00855513\tvalid_1's l2: 0.0641047\n",
      "[1700]\ttraining's l2: 0.00835228\tvalid_1's l2: 0.0640027\n",
      "[1725]\ttraining's l2: 0.00817532\tvalid_1's l2: 0.0639437\n",
      "[1750]\ttraining's l2: 0.00803194\tvalid_1's l2: 0.0640059\n",
      "[1775]\ttraining's l2: 0.00783483\tvalid_1's l2: 0.0641392\n",
      "[1800]\ttraining's l2: 0.00769139\tvalid_1's l2: 0.0641356\n",
      "[1825]\ttraining's l2: 0.00752044\tvalid_1's l2: 0.0640493\n",
      "[1850]\ttraining's l2: 0.00732983\tvalid_1's l2: 0.0640734\n",
      "[1875]\ttraining's l2: 0.00716527\tvalid_1's l2: 0.064347\n",
      "[1900]\ttraining's l2: 0.00700022\tvalid_1's l2: 0.0642465\n",
      "[1925]\ttraining's l2: 0.00684779\tvalid_1's l2: 0.0644127\n",
      "[1950]\ttraining's l2: 0.00670859\tvalid_1's l2: 0.0645642\n",
      "[1975]\ttraining's l2: 0.00658755\tvalid_1's l2: 0.0647002\n",
      "Early stopping, best iteration is:\n",
      "[983]\ttraining's l2: 0.0179749\tvalid_1's l2: 0.0628139\n"
     ]
    }
   ],
   "source": [
    "index = get_feature(feature_importance,X_train,y_train,X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06281392841050108"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.best_score['valid_1'].items())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
